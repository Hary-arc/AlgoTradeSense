{"file_contents":{"app.py":{"content":"import streamlit as st\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nimport os\nfrom utils.database import init_database\nfrom utils.binance_client import BinanceClient\n\n# Page configuration\nst.set_page_config(\n    page_title=\"AI Trading Platform\",\n    page_icon=\"📈\",\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\"\n)\n\n# Initialize database on startup\ninit_database()\n\n# Initialize Binance client\n@st.cache_resource\ndef get_binance_client():\n    api_key = os.getenv(\"BINANCE_API_KEY\", \"\")\n    api_secret = os.getenv(\"BINANCE_API_SECRET\", \"\")\n    testnet = os.getenv(\"BINANCE_TESTNET\", \"true\").lower() == \"true\"\n    \n    if not api_key or not api_secret:\n        st.error(\"⚠️ Binance API credentials not found in environment variables.\")\n        st.info(\"Please set BINANCE_API_KEY and BINANCE_API_SECRET environment variables.\")\n        return None\n    \n    try:\n        client = BinanceClient(api_key, api_secret, testnet=testnet)\n        return client\n    except Exception as e:\n        st.error(f\"Failed to initialize Binance client: {str(e)}\")\n        return None\n\n# Main page\ndef main():\n    st.title(\"🤖 AI-Powered Trading Platform\")\n    st.markdown(\"---\")\n    \n    # Sidebar for global settings\n    with st.sidebar:\n        st.header(\"🔧 Global Settings\")\n        \n        # Trading mode selection\n        trading_mode = st.selectbox(\n            \"Trading Mode\",\n            [\"Paper Trading\", \"Live Trading\"],\n            help=\"Paper trading uses simulated funds for testing\"\n        )\n        \n        # Risk management settings\n        st.subheader(\"Risk Management\")\n        max_position_size = st.slider(\"Max Position Size (%)\", 1, 50, 10)\n        stop_loss_pct = st.slider(\"Stop Loss (%)\", 1, 20, 5)\n        take_profit_pct = st.slider(\"Take Profit (%)\", 1, 50, 15)\n        \n        # Store settings in session state\n        st.session_state.trading_mode = trading_mode\n        st.session_state.max_position_size = max_position_size\n        st.session_state.stop_loss_pct = stop_loss_pct\n        st.session_state.take_profit_pct = take_profit_pct\n        \n        st.markdown(\"---\")\n        \n        # Connection status\n        st.subheader(\"🔗 Connection Status\")\n        client = get_binance_client()\n        if client and client.test_connection():\n            st.success(\"✅ Binance API Connected\")\n            account_info = client.get_account_info()\n            if account_info:\n                st.info(f\"Account Type: {account_info.get('accountType', 'Unknown')}\")\n        else:\n            st.error(\"❌ Binance API Disconnected\")\n    \n    # Main content area\n    col1, col2, col3 = st.columns(3)\n    \n    with col1:\n        st.metric(\n            label=\"Active Models\",\n            value=\"3\",\n            delta=\"1 new today\"\n        )\n    \n    with col2:\n        st.metric(\n            label=\"Portfolio Value\",\n            value=\"$10,000\",\n            delta=\"2.5%\"\n        )\n    \n    with col3:\n        st.metric(\n            label=\"Win Rate\",\n            value=\"68.5%\",\n            delta=\"5.2%\"\n        )\n    \n    # Quick overview\n    st.subheader(\"📊 Platform Overview\")\n    \n    tab1, tab2, tab3 = st.tabs([\"📈 Recent Signals\", \"🎯 Model Performance\", \"📰 Market Status\"])\n    \n    with tab1:\n        st.info(\"Recent trading signals will appear here based on ML model predictions.\")\n        st.write(\"Navigate to the Signal Generation page to view and generate new signals.\")\n    \n    with tab2:\n        st.info(\"Model performance metrics and accuracy tracking will be displayed here.\")\n        st.write(\"Navigate to the Analytics page for detailed performance analysis.\")\n    \n    with tab3:\n        st.info(\"Current market status and trending assets will be shown here.\")\n        st.write(\"Navigate to the Dashboard page for real-time market data and charts.\")\n    \n    # Getting started guide\n    st.subheader(\"🚀 Getting Started\")\n    \n    steps = [\n        \"1. **Dashboard**: View real-time market data and professional trading charts\",\n        \"2. **Model Training**: Train ML models on historical data with various algorithms\",\n        \"3. **Signal Generation**: Generate trading signals based on trained models\",\n        \"4. **Backtesting**: Test your strategies on historical data\",\n        \"5. **Analytics**: Monitor performance and model accuracy\",\n        \"6. **Model Comparison**: Compare different ML models and strategies\"\n    ]\n    \n    for step in steps:\n        st.markdown(step)\n    \n    st.markdown(\"---\")\n    st.info(\"💡 **Tip**: Start with paper trading mode to test your strategies before using real funds.\")\n\nif __name__ == \"__main__\":\n    main()\n","size_bytes":4660},"pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"joblib>=1.5.1\",\n    \"numpy>=2.3.2\",\n    \"pandas>=2.3.1\",\n    \"plotly>=6.3.0\",\n    \"requests>=2.32.4\",\n    \"scikit-learn>=1.7.1\",\n    \"streamlit>=1.48.1\",\n    \"ta>=0.11.0\",\n    \"tensorflow>=2.20.0\",\n    \"websocket-client>=1.8.0\",\n]\n","size_bytes":378},"replit.md":{"content":"# AI Trading Platform\n\n## Overview\n\nThis is a comprehensive AI-powered trading platform built with Streamlit that provides machine learning-based cryptocurrency trading signals and analysis. The platform integrates with Binance API to fetch real-time market data and uses multiple ML models (LSTM, Random Forest, SVM) to generate trading signals, perform backtesting, and provide detailed analytics.\n\n## User Preferences\n\nPreferred communication style: Simple, everyday language.\n\n## Recent Changes\n\n**August 18, 2025:**\n- Fixed critical pandas deprecation errors (fillna method='forward' → method='ffill')\n- Fixed ta.volume.volume_sma function (replaced with manual volume moving average)\n- Fixed variable scope issues in Model Training page (n_estimators, lstm_units, etc.)\n- Reduced LSP diagnostic errors from 136 to 108 (28 errors fixed)\n- Binance API credentials securely stored in environment variables\n- All required packages successfully installed and working\n- **NEW**: Implemented TradingView-style live charts with advanced pattern recognition\n- **NEW**: Added 8 candlestick pattern types: channels, triangles, wedges with trend lines\n- **NEW**: Created professional dark theme matching TradingView aesthetics\n- **NEW**: Live pattern detection with trading signals and confidence scoring\n\n## System Architecture\n\n### Frontend Architecture\n- **Framework**: Streamlit-based multi-page application\n- **UI Structure**: Main dashboard with 6 specialized pages:\n  - Dashboard: Real-time market data and charts\n  - Model Training: ML model creation and training interface\n  - Signal Generation: AI-powered trading signal creation\n  - Backtesting: Strategy performance testing\n  - Analytics: Comprehensive performance metrics\n  - Model Comparison: Side-by-side model evaluation\n- **Visualization**: Plotly for interactive charts and TradingView-style candlestick charts\n- **Layout**: Wide layout with sidebar navigation for global settings\n\n### Backend Architecture\n- **Core Language**: Python\n- **ML Framework**: Hybrid approach using both scikit-learn and TensorFlow/Keras\n- **Model Types**: \n  - LSTM neural networks for time series prediction\n  - Random Forest for ensemble learning\n  - Support Vector Machines for pattern recognition\n- **Data Processing**: Custom DataProcessor class with technical indicator integration\n- **Signal Generation**: Real-time AI signal generation with confidence scoring\n- **Backtesting Engine**: Comprehensive strategy testing with risk metrics\n\n### Data Storage Solutions\n- **Primary Database**: SQLite for local data persistence\n- **Database Schema**: \n  - Models table: Stores trained ML models with metadata and performance metrics\n  - Market data table: Historical and real-time price data\n  - Signals table: Generated trading signals with timestamps\n  - Trading history: Backtest results and performance data\n- **Model Serialization**: Binary storage of trained models and scalers in database\n- **Data Processing**: Pandas for data manipulation with technical analysis integration\n\n### Authentication and Authorization\n- **API Authentication**: Environment variable-based Binance API key management\n- **Security**: HMAC SHA256 signature generation for secure API communication\n- **Configuration**: Environment-based testnet/mainnet switching\n\n## External Dependencies\n\n### Trading APIs\n- **Binance API**: Primary cryptocurrency exchange integration\n  - REST API for historical data and account management\n  - WebSocket API for real-time market data streaming\n  - Testnet support for safe development and testing\n\n### Machine Learning Libraries\n- **TensorFlow/Keras**: Deep learning framework for LSTM neural networks\n- **scikit-learn**: Traditional ML algorithms and preprocessing utilities\n- **Technical Analysis Library (ta)**: Comprehensive technical indicator calculations\n\n### Data Visualization\n- **Plotly**: Interactive charting library for financial data visualization\n- **Streamlit**: Web application framework with built-in visualization components\n\n### Data Processing\n- **Pandas**: Primary data manipulation and analysis library\n- **NumPy**: Numerical computing foundation\n- **SQLite3**: Embedded database for local data storage\n\n### Development Tools\n- **Joblib**: Model serialization and parallel processing\n- **Requests**: HTTP client for API communications\n- **WebSocket**: Real-time data streaming capabilities\n\n### Environment Management\n- Environment variables for secure API credential storage\n- Configurable testnet/production mode switching\n- Modular utility structure for maintainable code organization","size_bytes":4572},"pages/1_Dashboard.py":{"content":"import streamlit as st\nimport pandas as pd\nimport numpy as np\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport time\nfrom datetime import datetime, timedelta\nfrom utils.binance_client import BinanceClient\nfrom utils.pattern_recognition import PatternRecognizer\nimport os\n\nst.set_page_config(page_title=\"Trading Dashboard\", page_icon=\"📈\", layout=\"wide\")\n\n# Initialize Binance client\n@st.cache_resource\ndef get_binance_client():\n    api_key = os.getenv(\"BINANCE_API_KEY\", \"\")\n    api_secret = os.getenv(\"BINANCE_API_SECRET\", \"\")\n    testnet = os.getenv(\"BINANCE_TESTNET\", \"true\").lower() == \"true\"\n    \n    if not api_key or not api_secret:\n        return None\n    \n    try:\n        client = BinanceClient(api_key, api_secret, testnet=testnet)\n        return client\n    except Exception as e:\n        st.error(f\"Failed to initialize Binance client: {str(e)}\")\n        return None\n\ndef create_tradingview_chart(df, symbol, patterns=None, current_price=None, price_change_pct=None):\n    \"\"\"Create professional TradingView-style candlestick chart matching the reference design.\"\"\"\n    \n    # Create subplot with volume at bottom (matching TradingView layout)\n    fig = make_subplots(\n        rows=2, cols=1,\n        shared_xaxes=True,\n        vertical_spacing=0.02,\n        row_heights=[0.75, 0.25],\n        specs=[[{\"secondary_y\": False}], [{\"secondary_y\": False}]]\n    )\n    \n    # Add candlestick chart with TradingView colors\n    fig.add_trace(\n        go.Candlestick(\n            x=df.index,\n            open=df['open'],\n            high=df['high'],\n            low=df['low'],\n            close=df['close'],\n            name=symbol,\n            increasing_line_color='#089981',  # TradingView green\n            decreasing_line_color='#F23645',  # TradingView red\n            increasing_fillcolor='#089981',\n            decreasing_fillcolor='#F23645',\n            line=dict(width=1)\n        ),\n        row=1, col=1\n    )\n    \n    # Add volume bars with TradingView styling\n    volume_colors = []\n    for i in range(len(df)):\n        if i == 0:\n            # First candle - use close vs open\n            color = '#089981' if df['close'].iloc[i] >= df['open'].iloc[i] else '#F23645'\n        else:\n            # Compare close to previous close (TradingView style)\n            color = '#089981' if df['close'].iloc[i] >= df['close'].iloc[i-1] else '#F23645'\n        volume_colors.append(color)\n    \n    fig.add_trace(\n        go.Bar(\n            x=df.index,\n            y=df['volume'],\n            marker_color=volume_colors,\n            name='Volume',\n            opacity=0.6,\n            showlegend=False\n        ),\n        row=2, col=1\n    )\n    \n    # Add pattern overlays if available\n    if patterns:\n        for pattern_name, pattern_data in patterns.items():\n            if pattern_name == 'support_resistance':\n                # Add support/resistance lines\n                sr_data = pattern_data\n                current_time = df.index[-1]\n                start_time = df.index[0]\n                \n                for level in sr_data.get('resistance_levels', []):\n                    fig.add_shape(\n                        type=\"line\",\n                        x0=start_time, y0=level, x1=current_time, y1=level,\n                        line=dict(color=\"red\", width=2, dash=\"dash\"),\n                        row=1, col=1\n                    )\n                    fig.add_annotation(\n                        x=current_time, y=level,\n                        text=f\"R: {level:.2f}\",\n                        showarrow=True,\n                        arrowhead=2,\n                        arrowsize=1,\n                        arrowwidth=2,\n                        arrowcolor=\"red\",\n                        bgcolor=\"red\",\n                        bordercolor=\"red\",\n                        font=dict(color=\"white\", size=10),\n                        row=1, col=1\n                    )\n                \n                for level in sr_data.get('support_levels', []):\n                    fig.add_shape(\n                        type=\"line\",\n                        x0=start_time, y0=level, x1=current_time, y1=level,\n                        line=dict(color=\"green\", width=2, dash=\"dash\"),\n                        row=1, col=1\n                    )\n                    fig.add_annotation(\n                        x=current_time, y=level,\n                        text=f\"S: {level:.2f}\",\n                        showarrow=True,\n                        arrowhead=2,\n                        arrowsize=1,\n                        arrowwidth=2,\n                        arrowcolor=\"green\",\n                        bgcolor=\"green\",\n                        bordercolor=\"green\",\n                        font=dict(color=\"white\", size=10),\n                        row=1, col=1\n                    )\n            \n            else:\n                # Add trend lines for patterns\n                if 'upper_line' in pattern_data and 'lower_line' in pattern_data:\n                    upper_line = pattern_data['upper_line']\n                    lower_line = pattern_data['lower_line']\n                    \n                    # Calculate line points\n                    x_start = df.index[upper_line['start_point'][0]]\n                    x_end = df.index[min(upper_line['end_point'][0], len(df)-1)]\n                    \n                    # Upper trend line\n                    y_start_upper = upper_line['start_point'][1]\n                    y_end_upper = upper_line['end_point'][1]\n                    \n                    fig.add_shape(\n                        type=\"line\",\n                        x0=x_start, y0=y_start_upper,\n                        x1=x_end, y1=y_end_upper,\n                        line=dict(color=\"#2196F3\", width=2, dash=\"dot\"),\n                        row=1, col=1\n                    )\n                    \n                    # Lower trend line\n                    y_start_lower = lower_line['start_point'][1]\n                    y_end_lower = lower_line['end_point'][1]\n                    \n                    fig.add_shape(\n                        type=\"line\",\n                        x0=x_start, y0=y_start_lower,\n                        x1=x_end, y1=y_end_lower,\n                        line=dict(color=\"#2196F3\", width=2, dash=\"dot\"),\n                        row=1, col=1\n                    )\n                    \n                    # Add pattern label\n                    mid_x = x_start + (x_end - x_start) / 2\n                    mid_y = y_start_upper + (y_start_lower - y_start_upper) / 2\n                    \n                    fig.add_annotation(\n                        x=mid_x, y=mid_y,\n                        text=pattern_data['type'],\n                        showarrow=False,\n                        bgcolor=\"rgba(33, 150, 243, 0.8)\",\n                        bordercolor=\"#2196F3\",\n                        font=dict(color=\"white\", size=12, family=\"Arial Black\"),\n                        row=1, col=1\n                    )\n    \n    # Update layout to match TradingView exactly\n    fig.update_layout(\n        template='plotly_dark',\n        paper_bgcolor='#131722',  # TradingView background\n        plot_bgcolor='#131722',\n        font=dict(color='#D1D4DC', family='Arial', size=12),\n        xaxis_rangeslider_visible=False,\n        height=600,\n        showlegend=False,\n        margin=dict(l=0, r=0, t=0, b=0),\n        hovermode='x unified'\n    )\n    \n    # Update axes to match TradingView\n    fig.update_xaxes(\n        showgrid=True,\n        gridwidth=1,\n        gridcolor='rgba(54, 58, 79, 0.5)',\n        showline=True,\n        linewidth=1,\n        linecolor='rgba(54, 58, 79, 0.8)',\n        tickfont=dict(color='#868B93', size=10),\n        showticklabels=True,\n        row=2, col=1\n    )\n    \n    fig.update_yaxes(\n        showgrid=True,\n        gridwidth=1,\n        gridcolor='rgba(54, 58, 79, 0.5)',\n        showline=False,\n        tickfont=dict(color='#868B93', size=10),\n        side='right',\n        showticklabels=True,\n        row=1, col=1\n    )\n    \n    fig.update_yaxes(\n        showgrid=True,\n        gridwidth=1,\n        gridcolor='rgba(54, 58, 79, 0.5)',\n        showline=False,\n        tickfont=dict(color='#868B93', size=10),\n        side='right',\n        showticklabels=True,\n        row=2, col=1\n    )\n    \n    fig.update_xaxes(\n        showgrid=True,\n        gridwidth=1,\n        gridcolor='rgba(54, 58, 79, 0.5)',\n        showline=False,\n        showticklabels=False,\n        row=1, col=1\n    )\n    \n    return fig\n\ndef main():\n    st.title(\"📈 Live Trading Dashboard with Pattern Recognition\")\n    st.markdown(\"---\")\n    \n    client = get_binance_client()\n    if not client:\n        st.error(\"⚠️ Unable to connect to Binance API. Please check your credentials.\")\n        return\n    \n    # Initialize pattern recognizer\n    pattern_recognizer = PatternRecognizer(min_pattern_length=20, confidence_threshold=0.7)\n    \n    # Symbol selection\n    col1, col2, col3, col4 = st.columns([2, 1, 1, 1])\n    \n    with col1:\n        symbol = st.selectbox(\n            \"Select Trading Pair\",\n            [\"BTCUSDT\", \"ETHUSDT\", \"ADAUSDT\", \"DOTUSDT\", \"LINKUSDT\", \"BNBUSDT\"],\n            index=0\n        )\n    \n    with col2:\n        # Note: Binance doesn't support sub-minute intervals like 5s, 10s\n        # Available intervals: 1s, 1m, 3m, 5m, 15m, 30m, 1h, 2h, 4h, 6h, 8h, 12h, 1d, 3d, 1w, 1M\n        interval = st.selectbox(\n            \"Timeframe\",\n            [\"1s\", \"1m\", \"3m\", \"5m\", \"15m\", \"30m\", \"1h\", \"2h\", \"4h\", \"6h\", \"8h\", \"12h\", \"1d\", \"3d\", \"1w\", \"1M\"],\n            index=6,  # Default to 1h\n            help=\"Note: Ultra-short intervals (1s) may have limited historical data\"\n        )\n    \n    with col3:\n        limit = st.selectbox(\n            \"Data Points\",\n            [100, 200, 500, 1000],\n            index=1\n        )\n    \n    with col4:\n        auto_refresh = st.checkbox(\"Auto Refresh\", value=True)\n    \n    # Fetch and display data\n    try:\n        # Get market data\n        klines = client.get_klines(symbol, interval, limit)\n        if not klines:\n            st.error(\"Unable to fetch market data\")\n            return\n        \n        # Convert to DataFrame\n        df = pd.DataFrame(klines, columns=[\n            'timestamp', 'open', 'high', 'low', 'close', 'volume',\n            'close_time', 'quote_asset_volume', 'number_of_trades',\n            'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'\n        ])\n        \n        # Process data\n        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n        df.set_index('timestamp', inplace=True)\n        df = df[['open', 'high', 'low', 'close', 'volume']].astype(float)\n        \n        # Detect patterns\n        patterns = pattern_recognizer.detect_all_patterns(df)\n        trading_signals = pattern_recognizer.get_trading_signals(patterns)\n        \n        # Calculate market metrics\n        current_price = float(df['close'].iloc[-1])\n        price_change = float(df['close'].iloc[-1]) - float(df['close'].iloc[-2])\n        price_change_pct = (price_change / float(df['close'].iloc[-2])) * 100\n        high_24h = float(df['high'].max())\n        low_24h = float(df['low'].min())\n        volume = float(df['volume'].iloc[-1])\n        \n        # Create TradingView-style metrics bar\n        st.markdown(f\"\"\"\n        <div style='background-color: #131722; padding: 12px; border-radius: 6px; margin-bottom: 15px; border: 1px solid #363A4E;'>\n            <div style='display: flex; align-items: center; justify-content: space-between; flex-wrap: wrap; gap: 20px;'>\n                <div style='display: flex; align-items: center; gap: 15px;'>\n                    <span style='color: #868B93; font-size: 12px;'>O</span>\n                    <span style='color: #D1D4DC; font-size: 12px; font-weight: 500;'>{df[\"open\"].iloc[-1]:.4f}</span>\n                    <span style='color: #868B93; font-size: 12px;'>H</span>\n                    <span style='color: #089981; font-size: 12px; font-weight: 500;'>{high_24h:.4f}</span>\n                    <span style='color: #868B93; font-size: 12px;'>L</span>\n                    <span style='color: #F23645; font-size: 12px; font-weight: 500;'>{low_24h:.4f}</span>\n                    <span style='color: #868B93; font-size: 12px;'>C</span>\n                    <span style='color: #D1D4DC; font-size: 12px; font-weight: 500;'>{current_price:.4f}</span>\n                    <span style='color: #868B93; font-size: 12px;'>Volume</span>\n                    <span style='color: #D1D4DC; font-size: 12px; font-weight: 500;'>{volume:,.0f}</span>\n                </div>\n                <div style='display: flex; align-items: center; gap: 10px;'>\n                    <span style='color: #868B93; font-size: 12px;'>Patterns</span>\n                    <span style='color: #2962FF; font-size: 12px; font-weight: 500;'>{len([p for p in patterns.keys() if p != \"support_resistance\"])}</span>\n                </div>\n            </div>\n        </div>\n        \"\"\", unsafe_allow_html=True)\n        \n        # Create TradingView-style header\n        st.markdown(f\"\"\"\n        <div style='background-color: #131722; padding: 16px; border-radius: 8px; margin-bottom: 10px; border: 1px solid #363A4E;'>\n            <div style='display: flex; align-items: center; justify-content: space-between;'>\n                <div style='display: flex; align-items: center; gap: 15px;'>\n                    <h2 style='color: #D1D4DC; margin: 0; font-size: 22px; font-weight: 600;'>{symbol}</h2>\n                    <span style='background-color: #363A4E; color: #868B93; font-size: 11px; padding: 3px 6px; border-radius: 3px;'>BINANCE</span>\n                    <span style='color: {\"#089981\" if price_change_pct >= 0 else \"#F23645\"}; font-size: 24px; font-weight: 600; font-family: monospace;'>\n                        {current_price:.4f}\n                    </span>\n                    <span style='color: {\"#089981\" if price_change_pct >= 0 else \"#F23645\"}; font-size: 14px; font-weight: 500;'>\n                        {\"+\" if price_change >= 0 else \"\"}{price_change:.4f} ({price_change_pct:+.2f}%)\n                    </span>\n                </div>\n                <div style='display: flex; align-items: center; gap: 15px;'>\n                    <span style='background-color: #2962FF; color: white; font-size: 11px; padding: 2px 8px; border-radius: 12px; font-weight: 500;'>{interval}</span>\n                    <span style='color: #089981; font-size: 12px; font-weight: 500;'>● LIVE</span>\n                </div>\n            </div>\n        </div>\n        \"\"\", unsafe_allow_html=True)\n        \n        # Create and display chart\n        chart_fig = create_tradingview_chart(df, symbol, patterns, current_price, price_change_pct)\n        st.plotly_chart(chart_fig, use_container_width=True, config={'displayModeBar': False})\n        \n        # Display pattern analysis\n        if patterns:\n            st.subheader(\"🔍 Pattern Analysis\")\n            \n            # Create pattern summary cards\n            pattern_keys = [p for p in patterns.keys() if p != 'support_resistance']\n            if pattern_keys:\n                pattern_cols = st.columns(min(3, len(pattern_keys)))\n                \n                for pattern_idx, pattern_name in enumerate(pattern_keys):\n                    if pattern_idx < len(pattern_cols):\n                        pattern_data = patterns[pattern_name]\n                        with pattern_cols[pattern_idx]:\n                            signal_color = {\n                                'BULLISH': '🟢',\n                                'BEARISH': '🔴', \n                                'NEUTRAL': '🟡',\n                                'VOLATILE': '🟠'\n                            }.get(pattern_data['signal'], '⚪')\n                            \n                            st.markdown(f\"\"\"\n                            <div style='padding: 1rem; border: 1px solid #ddd; border-radius: 0.5rem; margin: 0.5rem 0;'>\n                                <h4>{signal_color} {pattern_data['type']}</h4>\n                                <p><strong>Signal:</strong> {pattern_data['signal']}</p>\n                                <p><strong>Confidence:</strong> {pattern_data['confidence']:.1%}</p>\n                                <p style='font-size: 0.9em;'>{pattern_data['description']}</p>\n                            </div>\n                            \"\"\", unsafe_allow_html=True)\n        \n        # Display trading signals\n        if trading_signals:\n            st.subheader(\"🎯 Trading Signals\")\n            \n            signal_df = pd.DataFrame(trading_signals)\n            st.dataframe(\n                signal_df[['pattern', 'signal', 'strength', 'description']],\n                use_container_width=True,\n                hide_index=True\n            )\n        \n        # Support and Resistance levels\n        if 'support_resistance' in patterns:\n            st.subheader(\"📊 Key Levels\")\n            \n            sr_data = patterns['support_resistance']\n            \n            col1, col2 = st.columns(2)\n            \n            with col1:\n                st.write(\"**Resistance Levels:**\")\n                for level in sr_data.get('resistance_levels', []):\n                    distance = ((level - current_price) / current_price) * 100\n                    st.write(f\"🔴 ${level:.2f} ({distance:+.1f}%)\")\n            \n            with col2:\n                st.write(\"**Support Levels:**\")\n                for level in sr_data.get('support_levels', []):\n                    distance = ((level - current_price) / current_price) * 100\n                    st.write(f\"🟢 ${level:.2f} ({distance:+.1f}%)\")\n        \n        # Auto-refresh mechanism\n        if auto_refresh:\n            time.sleep(30)\n            st.rerun()\n    \n    except Exception as e:\n        st.error(f\"Error loading market data: {str(e)}\")\n\nif __name__ == \"__main__\":\n    main()","size_bytes":17879},"pages/2_Model_Training.py":{"content":"import streamlit as st\nimport pandas as pd\nimport numpy as np\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom datetime import datetime, timedelta\nfrom utils.ml_models import LSTMModel, RandomForestModel, SVMModel\nfrom utils.data_processor import DataProcessor\nfrom utils.database import get_historical_data, store_model, get_models\nfrom utils.binance_client import BinanceClient\nimport os\nimport joblib\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nimport time\n\nst.set_page_config(page_title=\"Model Training\", page_icon=\"🧠\", layout=\"wide\")\n\ndef main():\n    st.title(\"🧠 ML Model Training\")\n    st.markdown(\"---\")\n    \n    # Sidebar for model configuration\n    with st.sidebar:\n        st.header(\"🔧 Training Configuration\")\n        \n        # Model selection\n        model_type = st.selectbox(\n            \"Select Model Type\",\n            [\"LSTM\", \"Random Forest\", \"SVM\"],\n            help=\"Choose the machine learning algorithm to train\"\n        )\n        \n        # Data configuration\n        st.subheader(\"📊 Data Configuration\")\n        symbol = st.selectbox(\n            \"Trading Pair\",\n            [\"BTCUSDT\", \"ETHUSDT\", \"ADAUSDT\", \"DOTUSDT\", \"LINKUSDT\", \"BNBUSDT\"]\n        )\n        \n        interval = st.selectbox(\n            \"Timeframe\",\n            [\"1h\", \"4h\", \"1d\"],\n            index=1\n        )\n        \n        lookback_days = st.slider(\"Training Data (days)\", 30, 365, 90)\n        \n        # Feature selection\n        st.subheader(\"🎯 Features\")\n        include_technical = st.checkbox(\"Technical Indicators\", value=True)\n        include_volume = st.checkbox(\"Volume Data\", value=True)\n        include_price_changes = st.checkbox(\"Price Changes\", value=True)\n        \n        # Model hyperparameters\n        st.subheader(\"⚙️ Hyperparameters\")\n        \n        # Initialize default values\n        lstm_units, dropout_rate, epochs, batch_size = 128, 0.2, 50, 32\n        n_estimators, max_depth, min_samples_split = 100, 15, 5\n        C, kernel, gamma = 1.0, \"rbf\", \"scale\"\n        \n        if model_type == \"LSTM\":\n            lstm_units = st.slider(\"LSTM Units\", 32, 256, 128)\n            dropout_rate = st.slider(\"Dropout Rate\", 0.1, 0.5, 0.2)\n            epochs = st.slider(\"Epochs\", 10, 200, 50)\n            batch_size = st.slider(\"Batch Size\", 16, 128, 32)\n            \n        elif model_type == \"Random Forest\":\n            n_estimators = st.slider(\"Number of Trees\", 50, 500, 100)\n            max_depth = st.slider(\"Max Depth\", 5, 50, 15)\n            min_samples_split = st.slider(\"Min Samples Split\", 2, 20, 5)\n            \n        elif model_type == \"SVM\":\n            C = st.slider(\"C Parameter\", 0.1, 10.0, 1.0)\n            kernel = st.selectbox(\"Kernel\", [\"rbf\", \"linear\", \"poly\"])\n            gamma = st.selectbox(\"Gamma\", [\"scale\", \"auto\"])\n    \n    # Main content area\n    col1, col2 = st.columns([2, 1])\n    \n    with col1:\n        st.subheader(\"📈 Training Data Preview\")\n        \n        # Data loading and preprocessing\n        try:\n            # Initialize Binance client\n            api_key = os.getenv(\"BINANCE_API_KEY\", \"\")\n            api_secret = os.getenv(\"BINANCE_API_SECRET\", \"\")\n            testnet = os.getenv(\"BINANCE_TESTNET\", \"true\").lower() == \"true\"\n            \n            if api_key and api_secret:\n                client = BinanceClient(api_key, api_secret, testnet=testnet)\n                \n                # Fetch historical data\n                end_time = datetime.now()\n                start_time = end_time - timedelta(days=lookback_days)\n                \n                # Calculate limit based on interval\n                interval_minutes = {\n                    \"1h\": 60,\n                    \"4h\": 240,\n                    \"1d\": 1440\n                }\n                \n                limit = min(1000, (lookback_days * 1440) // interval_minutes[interval])\n                \n                klines = client.get_klines(symbol, interval, limit)\n                \n                if klines:\n                    df = pd.DataFrame(klines, columns=[\n                        'timestamp', 'open', 'high', 'low', 'close', 'volume',\n                        'close_time', 'quote_asset_volume', 'number_of_trades',\n                        'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'\n                    ])\n                    \n                    for col in ['open', 'high', 'low', 'close', 'volume']:\n                        df[col] = pd.to_numeric(df[col])\n                    \n                    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n                    df.set_index('timestamp', inplace=True)\n                    \n                    # Display data info\n                    st.info(f\"📊 Loaded {len(df)} data points from {start_time.date()} to {end_time.date()}\")\n                    \n                    # Show data preview\n                    st.dataframe(df[['open', 'high', 'low', 'close', 'volume']].tail(10))\n                    \n                    # Data visualization\n                    fig = go.Figure()\n                    fig.add_trace(go.Scatter(\n                        x=df.index,\n                        y=df['close'],\n                        mode='lines',\n                        name='Close Price',\n                        line=dict(color='#00D4AA')\n                    ))\n                    \n                    fig.update_layout(\n                        title=f\"{symbol} Price Data\",\n                        xaxis_title=\"Time\",\n                        yaxis_title=\"Price\",\n                        height=400\n                    )\n                    \n                    st.plotly_chart(fig, use_container_width=True)\n                    \n                else:\n                    st.error(\"No data available for the selected parameters\")\n                    df = None\n            else:\n                st.error(\"Binance API credentials not found\")\n                df = None\n                \n        except Exception as e:\n            st.error(f\"Error loading data: {str(e)}\")\n            df = None\n    \n    with col2:\n        st.subheader(\"🎯 Training Status\")\n        \n        # Training button\n        if st.button(\"🚀 Start Training\", type=\"primary\"):\n            if df is not None and len(df) > 50:\n                \n                # Create progress bar\n                progress_bar = st.progress(0)\n                status_text = st.empty()\n                \n                try:\n                    # Initialize data processor\n                    processor = DataProcessor()\n                    \n                    # Prepare features\n                    status_text.text(\"Preparing features...\")\n                    progress_bar.progress(10)\n                    \n                    features = processor.prepare_features(\n                        df,\n                        include_technical=include_technical,\n                        include_volume=include_volume,\n                        include_price_changes=include_price_changes\n                    )\n                    \n                    status_text.text(\"Splitting data...\")\n                    progress_bar.progress(20)\n                    \n                    # Prepare training data\n                    X_train, X_test, y_train, y_test, scaler = processor.prepare_training_data(\n                        features, \n                        target_col='close',\n                        test_size=0.2,\n                        sequence_length=60 if model_type == \"LSTM\" else None\n                    )\n                    \n                    status_text.text(f\"Training {model_type} model...\")\n                    progress_bar.progress(30)\n                    \n                    # Initialize and train model\n                    if model_type == \"LSTM\":\n                        model = LSTMModel(\n                            input_shape=(X_train.shape[1], X_train.shape[2]),\n                            units=lstm_units,\n                            dropout_rate=dropout_rate\n                        )\n                        \n                        # Train with progress updates\n                        history = model.train(\n                            X_train, y_train,\n                            validation_data=(X_test, y_test),\n                            epochs=epochs,\n                            batch_size=batch_size,\n                            verbose=0\n                        )\n                        \n                        # Update progress during training\n                        for i in range(30, 80, 10):\n                            progress_bar.progress(i)\n                            time.sleep(0.1)\n                    \n                    elif model_type == \"Random Forest\":\n                        model = RandomForestModel(\n                            n_estimators=n_estimators,\n                            max_depth=max_depth,\n                            min_samples_split=min_samples_split\n                        )\n                        model.train(X_train, y_train)\n                    \n                    elif model_type == \"SVM\":\n                        model = SVMModel(\n                            C=C,\n                            kernel=kernel,\n                            gamma=gamma\n                        )\n                        model.train(X_train, y_train)\n                    \n                    progress_bar.progress(80)\n                    status_text.text(\"Evaluating model...\")\n                    \n                    # Make predictions\n                    train_pred = model.predict(X_train)\n                    test_pred = model.predict(X_test)\n                    \n                    # Calculate metrics\n                    train_mse = mean_squared_error(y_train, train_pred)\n                    test_mse = mean_squared_error(y_test, test_pred)\n                    train_mae = mean_absolute_error(y_train, train_pred)\n                    test_mae = mean_absolute_error(y_test, test_pred)\n                    train_r2 = r2_score(y_train, train_pred)\n                    test_r2 = r2_score(y_test, test_pred)\n                    \n                    progress_bar.progress(90)\n                    status_text.text(\"Saving model...\")\n                    \n                    # Save model\n                    model_name = f\"{model_type}_{symbol}_{interval}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n                    model_data = {\n                        'name': model_name,\n                        'type': model_type,\n                        'symbol': symbol,\n                        'interval': interval,\n                        'created_at': datetime.now(),\n                        'train_mse': train_mse,\n                        'test_mse': test_mse,\n                        'train_mae': train_mae,\n                        'test_mae': test_mae,\n                        'train_r2': train_r2,\n                        'test_r2': test_r2,\n                        'features': list(features.columns),\n                        'hyperparameters': {\n                            'LSTM': {'units': lstm_units, 'dropout': dropout_rate, 'epochs': epochs, 'batch_size': batch_size},\n                            'Random Forest': {'n_estimators': n_estimators, 'max_depth': max_depth, 'min_samples_split': min_samples_split},\n                            'SVM': {'C': C, 'kernel': kernel, 'gamma': gamma}\n                        }[model_type]\n                    }\n                    \n                    # Store model in database\n                    store_model(model_name, model, scaler, model_data)\n                    \n                    progress_bar.progress(100)\n                    status_text.text(\"Training completed!\")\n                    \n                    # Display results\n                    st.success(\"✅ Model training completed!\")\n                    \n                    st.metric(\"Test R² Score\", f\"{test_r2:.4f}\")\n                    st.metric(\"Test MSE\", f\"{test_mse:.6f}\")\n                    st.metric(\"Test MAE\", f\"{test_mae:.6f}\")\n                    \n                    # Plot predictions vs actual\n                    st.subheader(\"📊 Model Performance\")\n                    \n                    fig = go.Figure()\n                    \n                    # Plot actual vs predicted for test set\n                    test_indices = range(len(y_test))\n                    \n                    fig.add_trace(go.Scatter(\n                        x=test_indices,\n                        y=y_test.flatten() if hasattr(y_test, 'flatten') else y_test,\n                        mode='lines',\n                        name='Actual',\n                        line=dict(color='blue')\n                    ))\n                    \n                    fig.add_trace(go.Scatter(\n                        x=test_indices,\n                        y=test_pred.flatten() if hasattr(test_pred, 'flatten') else test_pred,\n                        mode='lines',\n                        name='Predicted',\n                        line=dict(color='red')\n                    ))\n                    \n                    fig.update_layout(\n                        title=\"Actual vs Predicted Prices\",\n                        xaxis_title=\"Time Steps\",\n                        yaxis_title=\"Price\",\n                        height=400\n                    )\n                    \n                    st.plotly_chart(fig, use_container_width=True)\n                    \n                except Exception as e:\n                    st.error(f\"Training failed: {str(e)}\")\n                    progress_bar.progress(0)\n                    status_text.text(\"Training failed\")\n            \n            else:\n                st.error(\"Insufficient data for training. Please load more data.\")\n        \n        # Display existing models\n        st.subheader(\"📚 Trained Models\")\n        \n        try:\n            models = get_models()\n            if models:\n                for model_info in models[-5:]:  # Show last 5 models\n                    with st.expander(f\"{model_info['name']}\"):\n                        st.write(f\"**Type**: {model_info['type']}\")\n                        st.write(f\"**Symbol**: {model_info['symbol']}\")\n                        st.write(f\"**Test R²**: {model_info.get('test_r2', 'N/A'):.4f}\")\n                        st.write(f\"**Created**: {model_info['created_at']}\")\n            else:\n                st.info(\"No trained models found. Train your first model!\")\n                \n        except Exception as e:\n            st.error(f\"Error loading models: {str(e)}\")\n\nif __name__ == \"__main__\":\n    main()\n","size_bytes":14642},"pages/3_Signal_Generation.py":{"content":"import streamlit as st\nimport pandas as pd\nimport numpy as np\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom datetime import datetime, timedelta\nfrom utils.signal_generator import SignalGenerator\nfrom utils.database import get_models, get_historical_data, store_signal\nfrom utils.binance_client import BinanceClient\nfrom utils.data_processor import DataProcessor\nimport os\n\nst.set_page_config(page_title=\"Signal Generation\", page_icon=\"🎯\", layout=\"wide\")\n\ndef main():\n    st.title(\"🎯 AI Signal Generation\")\n    st.markdown(\"---\")\n    \n    # Sidebar for signal configuration\n    with st.sidebar:\n        st.header(\"⚙️ Signal Configuration\")\n        \n        # Model selection\n        try:\n            models = get_models()\n            if models:\n                model_names = [model['name'] for model in models]\n                selected_model = st.selectbox(\n                    \"Select Model\",\n                    model_names,\n                    help=\"Choose a trained model for signal generation\"\n                )\n                \n                # Find selected model info\n                model_info = next((m for m in models if m['name'] == selected_model), None)\n                \n                if model_info:\n                    st.info(f\"**Type**: {model_info['type']}\")\n                    st.info(f\"**Symbol**: {model_info['symbol']}\")\n                    st.info(f\"**Test R²**: {model_info.get('test_r2', 'N/A'):.4f}\")\n            else:\n                st.error(\"No trained models found. Please train a model first.\")\n                return\n                \n        except Exception as e:\n            st.error(f\"Error loading models: {str(e)}\")\n            return\n        \n        # Signal parameters\n        st.subheader(\"📊 Signal Parameters\")\n        \n        confidence_threshold = st.slider(\n            \"Confidence Threshold\",\n            0.5, 0.95, 0.7,\n            help=\"Minimum confidence required for signal generation\"\n        )\n        \n        prediction_horizon = st.selectbox(\n            \"Prediction Horizon\",\n            [\"1 hour\", \"4 hours\", \"1 day\", \"3 days\"],\n            index=1\n        )\n        \n        signal_strength = st.selectbox(\n            \"Signal Strength Filter\",\n            [\"All Signals\", \"Strong Only\", \"Medium+\", \"Weak Only\"],\n            index=1\n        )\n        \n        # Risk management\n        st.subheader(\"⚠️ Risk Management\")\n        \n        position_size = st.slider(\n            \"Position Size (%)\",\n            1, 50, 10,\n            help=\"Percentage of portfolio to allocate\"\n        )\n        \n        stop_loss = st.slider(\n            \"Stop Loss (%)\",\n            1, 20, 5,\n            help=\"Maximum loss tolerance\"\n        )\n        \n        take_profit = st.slider(\n            \"Take Profit (%)\",\n            1, 50, 15,\n            help=\"Target profit level\"\n        )\n    \n    # Main content area\n    tab1, tab2, tab3 = st.tabs([\"🎯 Live Signals\", \"📈 Signal History\", \"⚙️ Signal Analysis\"])\n    \n    with tab1:\n        st.subheader(\"🎯 Real-Time Signal Generation\")\n        \n        col1, col2 = st.columns([2, 1])\n        \n        with col1:\n            # Generate signal button\n            if st.button(\"🚀 Generate Signal\", type=\"primary\"):\n                try:\n                    # Initialize components\n                    api_key = os.getenv(\"BINANCE_API_KEY\", \"\")\n                    api_secret = os.getenv(\"BINANCE_API_SECRET\", \"\")\n                    testnet = os.getenv(\"BINANCE_TESTNET\", \"true\").lower() == \"true\"\n                    \n                    if not api_key or not api_secret:\n                        st.error(\"Binance API credentials not found\")\n                        return\n                    \n                    client = BinanceClient(api_key, api_secret, testnet=testnet)\n                    signal_gen = SignalGenerator()\n                    processor = DataProcessor()\n                    \n                    # Get recent data for the model's symbol\n                    symbol = model_info['symbol']\n                    interval = model_info['interval']\n                    \n                    # Fetch recent data\n                    klines = client.get_klines(symbol, interval, 100)\n                    \n                    if klines:\n                        df = pd.DataFrame(klines, columns=[\n                            'timestamp', 'open', 'high', 'low', 'close', 'volume',\n                            'close_time', 'quote_asset_volume', 'number_of_trades',\n                            'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'\n                        ])\n                        \n                        for col in ['open', 'high', 'low', 'close', 'volume']:\n                            df[col] = pd.to_numeric(df[col])\n                        \n                        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n                        df.set_index('timestamp', inplace=True)\n                        \n                        # Generate signal\n                        with st.spinner(\"Generating signal...\"):\n                            signal = signal_gen.generate_signal(\n                                model_name=selected_model,\n                                data=df,\n                                confidence_threshold=confidence_threshold\n                            )\n                        \n                        if signal:\n                            # Display signal\n                            signal_type = signal['signal_type']\n                            confidence = signal['confidence']\n                            predicted_price = signal['predicted_price']\n                            current_price = signal['current_price']\n                            \n                            # Color coding for signal type\n                            if signal_type == 'BUY':\n                                signal_color = '🟢'\n                                signal_emoji = '📈'\n                            elif signal_type == 'SELL':\n                                signal_color = '🔴'\n                                signal_emoji = '📉'\n                            else:\n                                signal_color = '🟡'\n                                signal_emoji = '➡️'\n                            \n                            st.success(f\"✅ Signal Generated Successfully!\")\n                            \n                            # Signal display box\n                            signal_container = st.container()\n                            with signal_container:\n                                st.markdown(f\"\"\"\n                                <div style=\"border: 2px solid {'#00ff00' if signal_type == 'BUY' else '#ff0000' if signal_type == 'SELL' else '#ffff00'}; \n                                           border-radius: 10px; padding: 20px; margin: 10px 0;\">\n                                    <h3>{signal_color} {signal_type} SIGNAL {signal_emoji}</h3>\n                                    <p><strong>Symbol:</strong> {symbol}</p>\n                                    <p><strong>Confidence:</strong> {confidence:.2%}</p>\n                                    <p><strong>Current Price:</strong> ${current_price:.6f}</p>\n                                    <p><strong>Predicted Price:</strong> ${predicted_price:.6f}</p>\n                                    <p><strong>Expected Change:</strong> {((predicted_price - current_price) / current_price * 100):+.2f}%</p>\n                                </div>\n                                \"\"\", unsafe_allow_html=True)\n                            \n                            # Risk management recommendations\n                            if signal_type in ['BUY', 'SELL']:\n                                st.subheader(\"💼 Position Recommendations\")\n                                \n                                col1, col2, col3 = st.columns(3)\n                                \n                                with col1:\n                                    st.metric(\n                                        \"Recommended Position\",\n                                        f\"{position_size}% of portfolio\"\n                                    )\n                                \n                                with col2:\n                                    if signal_type == 'BUY':\n                                        stop_price = current_price * (1 - stop_loss/100)\n                                        take_profit_price = current_price * (1 + take_profit/100)\n                                    else:\n                                        stop_price = current_price * (1 + stop_loss/100)\n                                        take_profit_price = current_price * (1 - take_profit/100)\n                                    \n                                    st.metric(\n                                        \"Stop Loss\",\n                                        f\"${stop_price:.6f}\"\n                                    )\n                                \n                                with col3:\n                                    st.metric(\n                                        \"Take Profit\",\n                                        f\"${take_profit_price:.6f}\"\n                                    )\n                                \n                                # Store signal in database\n                                signal_data = {\n                                    'model_name': selected_model,\n                                    'symbol': symbol,\n                                    'signal_type': signal_type,\n                                    'confidence': confidence,\n                                    'current_price': current_price,\n                                    'predicted_price': predicted_price,\n                                    'position_size': position_size,\n                                    'stop_loss': stop_price,\n                                    'take_profit': take_profit_price,\n                                    'timestamp': datetime.now()\n                                }\n                                \n                                try:\n                                    store_signal(signal_data)\n                                    st.info(\"📝 Signal stored in history\")\n                                except Exception as e:\n                                    st.warning(f\"Could not store signal: {str(e)}\")\n                        else:\n                            st.warning(\"⚠️ No signal generated. Market conditions may not meet criteria.\")\n                    \n                    else:\n                        st.error(\"Could not fetch market data\")\n                \n                except Exception as e:\n                    st.error(f\"Error generating signal: {str(e)}\")\n        \n        with col2:\n            st.subheader(\"📊 Model Info\")\n            \n            if model_info:\n                st.write(f\"**Model Type**: {model_info['type']}\")\n                st.write(f\"**Training Symbol**: {model_info['symbol']}\")\n                st.write(f\"**Timeframe**: {model_info['interval']}\")\n                st.write(f\"**Test Accuracy**: {model_info.get('test_r2', 0):.2%}\")\n                st.write(f\"**Created**: {model_info['created_at']}\")\n                \n                # Model performance indicator\n                accuracy = model_info.get('test_r2', 0)\n                if accuracy > 0.8:\n                    st.success(\"🟢 High Accuracy Model\")\n                elif accuracy > 0.6:\n                    st.warning(\"🟡 Medium Accuracy Model\")\n                else:\n                    st.error(\"🔴 Low Accuracy Model\")\n                \n                # Feature importance (if available)\n                if 'features' in model_info:\n                    st.subheader(\"🎯 Model Features\")\n                    for feature in model_info['features'][:5]:  # Show top 5 features\n                        st.write(f\"• {feature}\")\n    \n    with tab2:\n        st.subheader(\"📈 Signal History\")\n        \n        # Display recent signals\n        try:\n            # This would get signals from database\n            st.info(\"Signal history will be displayed here once signals are generated.\")\n            \n            # Placeholder for signal history table\n            col1, col2 = st.columns([3, 1])\n            \n            with col1:\n                st.write(\"Recent signals will appear in this table:\")\n                \n                # Example structure for when signals exist\n                sample_data = pd.DataFrame({\n                    'Timestamp': ['2024-01-01 10:00:00'],\n                    'Symbol': ['BTCUSDT'],\n                    'Signal': ['BUY'],\n                    'Confidence': ['75%'],\n                    'Entry Price': ['$45,000'],\n                    'Status': ['Pending']\n                })\n                \n                st.dataframe(sample_data, use_container_width=True)\n            \n            with col2:\n                st.subheader(\"📊 Signal Stats\")\n                st.metric(\"Total Signals\", \"0\")\n                st.metric(\"Win Rate\", \"0%\")\n                st.metric(\"Avg Confidence\", \"0%\")\n                \n        except Exception as e:\n            st.error(f\"Error loading signal history: {str(e)}\")\n    \n    with tab3:\n        st.subheader(\"⚙️ Signal Analysis\")\n        \n        col1, col2 = st.columns(2)\n        \n        with col1:\n            st.subheader(\"🎯 Signal Distribution\")\n            st.info(\"Signal type distribution charts will be displayed here.\")\n            \n            # Placeholder for signal distribution\n            sample_distribution = {\n                'BUY': 45,\n                'SELL': 35,\n                'HOLD': 20\n            }\n            \n            fig = go.Figure(data=[go.Pie(\n                labels=list(sample_distribution.keys()),\n                values=list(sample_distribution.values()),\n                hole=0.3\n            )])\n            \n            fig.update_layout(\n                title=\"Signal Type Distribution (Sample)\",\n                height=300\n            )\n            \n            st.plotly_chart(fig, use_container_width=True)\n        \n        with col2:\n            st.subheader(\"📈 Confidence Trends\")\n            st.info(\"Signal confidence trends over time will be shown here.\")\n            \n            # Placeholder for confidence trends\n            dates = pd.date_range(start='2024-01-01', periods=30, freq='D')\n            confidence_trend = np.random.uniform(0.6, 0.9, 30)\n            \n            fig = go.Figure()\n            fig.add_trace(go.Scatter(\n                x=dates,\n                y=confidence_trend,\n                mode='lines+markers',\n                name='Average Confidence',\n                line=dict(color='#00D4AA')\n            ))\n            \n            fig.update_layout(\n                title=\"Signal Confidence Trend (Sample)\",\n                xaxis_title=\"Date\",\n                yaxis_title=\"Confidence\",\n                height=300\n            )\n            \n            st.plotly_chart(fig, use_container_width=True)\n        \n        # Signal performance metrics\n        st.subheader(\"📊 Performance Metrics\")\n        \n        col1, col2, col3, col4 = st.columns(4)\n        \n        with col1:\n            st.metric(\"Signal Accuracy\", \"0%\", \"N/A\")\n        \n        with col2:\n            st.metric(\"Avg Hold Time\", \"0 hours\", \"N/A\")\n        \n        with col3:\n            st.metric(\"Best Signal\", \"+0%\", \"N/A\")\n        \n        with col4:\n            st.metric(\"Worst Signal\", \"0%\", \"N/A\")\n\nif __name__ == \"__main__\":\n    main()\n","size_bytes":15694},"pages/4_Backtesting.py":{"content":"import streamlit as st\nimport pandas as pd\nimport numpy as np\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom datetime import datetime, timedelta\nfrom utils.backtesting_engine import BacktestingEngine\nfrom utils.database import get_models, get_historical_data\nfrom utils.binance_client import BinanceClient\nfrom utils.data_processor import DataProcessor\nimport os\n\nst.set_page_config(page_title=\"Backtesting\", page_icon=\"🔄\", layout=\"wide\")\n\ndef main():\n    st.title(\"🔄 Strategy Backtesting\")\n    st.markdown(\"---\")\n    \n    # Sidebar for backtesting configuration\n    with st.sidebar:\n        st.header(\"⚙️ Backtest Configuration\")\n        \n        # Model selection\n        try:\n            models = get_models()\n            if models:\n                model_names = [model['name'] for model in models]\n                selected_model = st.selectbox(\n                    \"Select Model\",\n                    model_names,\n                    help=\"Choose a trained model for backtesting\"\n                )\n                \n                model_info = next((m for m in models if m['name'] == selected_model), None)\n                \n                if model_info:\n                    st.info(f\"**Type**: {model_info['type']}\")\n                    st.info(f\"**Symbol**: {model_info['symbol']}\")\n                    st.info(f\"**Accuracy**: {model_info.get('test_r2', 0):.2%}\")\n            else:\n                st.error(\"No trained models found. Please train a model first.\")\n                return\n                \n        except Exception as e:\n            st.error(f\"Error loading models: {str(e)}\")\n            return\n        \n        # Backtesting period\n        st.subheader(\"📅 Backtesting Period\")\n        \n        end_date = st.date_input(\n            \"End Date\",\n            value=datetime.now().date(),\n            max_value=datetime.now().date()\n        )\n        \n        backtest_days = st.slider(\n            \"Backtest Period (days)\",\n            7, 365, 90,\n            help=\"Number of days to backtest\"\n        )\n        \n        start_date = end_date - timedelta(days=backtest_days)\n        st.write(f\"Start Date: {start_date}\")\n        \n        # Trading parameters\n        st.subheader(\"💰 Trading Parameters\")\n        \n        initial_capital = st.number_input(\n            \"Initial Capital ($)\",\n            min_value=100,\n            max_value=1000000,\n            value=10000,\n            step=100\n        )\n        \n        position_size = st.slider(\n            \"Position Size (%)\",\n            1, 100, 10,\n            help=\"Percentage of capital per trade\"\n        )\n        \n        commission = st.slider(\n            \"Commission (%)\",\n            0.0, 1.0, 0.1,\n            step=0.01,\n            help=\"Trading commission percentage\"\n        )\n        \n        # Risk management\n        st.subheader(\"⚠️ Risk Management\")\n        \n        stop_loss = st.slider(\n            \"Stop Loss (%)\",\n            1, 20, 5,\n            help=\"Maximum loss per trade\"\n        )\n        \n        take_profit = st.slider(\n            \"Take Profit (%)\",\n            1, 50, 15,\n            help=\"Target profit per trade\"\n        )\n        \n        confidence_threshold = st.slider(\n            \"Min Confidence\",\n            0.5, 0.95, 0.7,\n            help=\"Minimum signal confidence\"\n        )\n    \n    # Main content area\n    tab1, tab2, tab3 = st.tabs([\"🚀 Run Backtest\", \"📊 Results Analysis\", \"📈 Performance Metrics\"])\n    \n    with tab1:\n        st.subheader(\"🚀 Backtest Execution\")\n        \n        col1, col2 = st.columns([2, 1])\n        \n        with col1:\n            # Backtest parameters summary\n            st.subheader(\"📋 Backtest Summary\")\n            \n            summary_data = {\n                'Parameter': [\n                    'Model', 'Symbol', 'Period', 'Initial Capital',\n                    'Position Size', 'Commission', 'Stop Loss', 'Take Profit'\n                ],\n                'Value': [\n                    selected_model,\n                    model_info['symbol'],\n                    f\"{start_date} to {end_date}\",\n                    f\"${initial_capital:,}\",\n                    f\"{position_size}%\",\n                    f\"{commission}%\",\n                    f\"{stop_loss}%\",\n                    f\"{take_profit}%\"\n                ]\n            }\n            \n            summary_df = pd.DataFrame(summary_data)\n            st.dataframe(summary_df, use_container_width=True, hide_index=True)\n            \n            # Run backtest button\n            if st.button(\"🔄 Run Backtest\", type=\"primary\"):\n                try:\n                    # Initialize components\n                    api_key = os.getenv(\"BINANCE_API_KEY\", \"\")\n                    api_secret = os.getenv(\"BINANCE_API_SECRET\", \"\")\n                    testnet = os.getenv(\"BINANCE_TESTNET\", \"true\").lower() == \"true\"\n                    \n                    if not api_key or not api_secret:\n                        st.error(\"Binance API credentials not found\")\n                        return\n                    \n                    client = BinanceClient(api_key, api_secret, testnet=testnet)\n                    backtest_engine = BacktestingEngine()\n                    \n                    # Progress tracking\n                    progress_bar = st.progress(0)\n                    status_text = st.empty()\n                    \n                    # Fetch historical data\n                    status_text.text(\"Fetching historical data...\")\n                    progress_bar.progress(10)\n                    \n                    symbol = model_info['symbol']\n                    interval = model_info['interval']\n                    \n                    # Calculate data points needed\n                    interval_minutes = {\n                        \"1h\": 60,\n                        \"4h\": 240,\n                        \"1d\": 1440\n                    }\n                    \n                    limit = min(1000, (backtest_days * 1440) // interval_minutes[interval])\n                    klines = client.get_klines(symbol, interval, limit)\n                    \n                    if not klines:\n                        st.error(\"Could not fetch historical data\")\n                        return\n                    \n                    df = pd.DataFrame(klines, columns=[\n                        'timestamp', 'open', 'high', 'low', 'close', 'volume',\n                        'close_time', 'quote_asset_volume', 'number_of_trades',\n                        'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'\n                    ])\n                    \n                    for col in ['open', 'high', 'low', 'close', 'volume']:\n                        df[col] = pd.to_numeric(df[col])\n                    \n                    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n                    df.set_index('timestamp', inplace=True)\n                    \n                    # Filter data to backtest period\n                    start_datetime = pd.to_datetime(start_date)\n                    end_datetime = pd.to_datetime(end_date)\n                    df = df[(df.index >= start_datetime) & (df.index <= end_datetime)]\n                    \n                    if len(df) < 10:\n                        st.error(\"Insufficient data for the selected period\")\n                        return\n                    \n                    status_text.text(\"Running backtest...\")\n                    progress_bar.progress(30)\n                    \n                    # Configure backtest parameters\n                    backtest_config = {\n                        'initial_capital': initial_capital,\n                        'position_size_pct': position_size / 100,\n                        'commission_pct': commission / 100,\n                        'stop_loss_pct': stop_loss / 100,\n                        'take_profit_pct': take_profit / 100,\n                        'confidence_threshold': confidence_threshold\n                    }\n                    \n                    # Run backtest\n                    results = backtest_engine.run_backtest(\n                        model_name=selected_model,\n                        data=df,\n                        config=backtest_config\n                    )\n                    \n                    progress_bar.progress(80)\n                    status_text.text(\"Analyzing results...\")\n                    \n                    if results:\n                        # Store results in session state\n                        st.session_state.backtest_results = results\n                        \n                        progress_bar.progress(100)\n                        status_text.text(\"Backtest completed!\")\n                        \n                        st.success(\"✅ Backtest completed successfully!\")\n                        \n                        # Display key metrics\n                        st.subheader(\"📊 Key Results\")\n                        \n                        final_value = results['portfolio_values'][-1]\n                        total_return = (final_value - initial_capital) / initial_capital * 100\n                        total_trades = len(results['trades'])\n                        \n                        col1, col2, col3, col4 = st.columns(4)\n                        \n                        with col1:\n                            st.metric(\n                                \"Final Portfolio Value\",\n                                f\"${final_value:,.2f}\",\n                                f\"{total_return:+.2f}%\"\n                            )\n                        \n                        with col2:\n                            st.metric(\n                                \"Total Trades\",\n                                total_trades\n                            )\n                        \n                        with col3:\n                            winning_trades = sum(1 for trade in results['trades'] if trade['pnl'] > 0)\n                            win_rate = (winning_trades / total_trades * 100) if total_trades > 0 else 0\n                            st.metric(\n                                \"Win Rate\",\n                                f\"{win_rate:.1f}%\"\n                            )\n                        \n                        with col4:\n                            max_drawdown = results.get('max_drawdown', 0) * 100\n                            st.metric(\n                                \"Max Drawdown\",\n                                f\"{max_drawdown:.2f}%\"\n                            )\n                        \n                        # Portfolio value chart\n                        st.subheader(\"📈 Portfolio Performance\")\n                        \n                        fig = go.Figure()\n                        \n                        portfolio_dates = pd.date_range(\n                            start=start_datetime,\n                            periods=len(results['portfolio_values']),\n                            freq='H' if interval == '1h' else 'D'\n                        )\n                        \n                        fig.add_trace(go.Scatter(\n                            x=portfolio_dates,\n                            y=results['portfolio_values'],\n                            mode='lines',\n                            name='Portfolio Value',\n                            line=dict(color='#00D4AA', width=2)\n                        ))\n                        \n                        # Add buy/sell markers\n                        for trade in results['trades']:\n                            color = 'green' if trade['type'] == 'BUY' else 'red'\n                            fig.add_trace(go.Scatter(\n                                x=[trade['timestamp']],\n                                y=[trade['price'] * initial_capital / df['close'].iloc[0]],  # Approximate portfolio value\n                                mode='markers',\n                                marker=dict(\n                                    color=color,\n                                    size=10,\n                                    symbol='triangle-up' if trade['type'] == 'BUY' else 'triangle-down'\n                                ),\n                                name=f\"{trade['type']} Signal\",\n                                showlegend=False\n                            ))\n                        \n                        fig.update_layout(\n                            title=\"Portfolio Value Over Time\",\n                            xaxis_title=\"Date\",\n                            yaxis_title=\"Portfolio Value ($)\",\n                            height=500\n                        )\n                        \n                        st.plotly_chart(fig, use_container_width=True)\n                    \n                    else:\n                        st.error(\"Backtest failed to produce results\")\n                \n                except Exception as e:\n                    st.error(f\"Backtest failed: {str(e)}\")\n                    progress_bar.progress(0)\n                    status_text.text(\"Backtest failed\")\n        \n        with col2:\n            st.subheader(\"📊 Expected Performance\")\n            \n            # Display model statistics\n            if model_info:\n                accuracy = model_info.get('test_r2', 0)\n                \n                st.write(f\"**Model Accuracy**: {accuracy:.2%}\")\n                \n                if accuracy > 0.8:\n                    st.success(\"🟢 High accuracy model - Strong backtest expected\")\n                elif accuracy > 0.6:\n                    st.warning(\"🟡 Medium accuracy model - Moderate performance expected\")\n                else:\n                    st.error(\"🔴 Low accuracy model - Use with caution\")\n                \n                # Risk assessment\n                st.subheader(\"⚠️ Risk Assessment\")\n                \n                risk_score = (position_size + stop_loss) / 2\n                \n                if risk_score > 15:\n                    st.error(\"🔴 High Risk Strategy\")\n                elif risk_score > 10:\n                    st.warning(\"🟡 Medium Risk Strategy\")\n                else:\n                    st.success(\"🟢 Low Risk Strategy\")\n                \n                st.write(f\"Risk Score: {risk_score:.1f}/25\")\n                \n                # Recommendations\n                st.subheader(\"💡 Recommendations\")\n                \n                recommendations = []\n                \n                if position_size > 20:\n                    recommendations.append(\"Consider reducing position size\")\n                \n                if stop_loss < 3:\n                    recommendations.append(\"Stop loss might be too tight\")\n                \n                if take_profit < stop_loss * 2:\n                    recommendations.append(\"Consider better risk/reward ratio\")\n                \n                if confidence_threshold < 0.7:\n                    recommendations.append(\"Higher confidence threshold may improve results\")\n                \n                if not recommendations:\n                    recommendations.append(\"Configuration looks balanced\")\n                \n                for rec in recommendations:\n                    st.write(f\"• {rec}\")\n    \n    with tab2:\n        st.subheader(\"📊 Detailed Results Analysis\")\n        \n        if 'backtest_results' in st.session_state:\n            results = st.session_state.backtest_results\n            \n            # Trade analysis\n            if results['trades']:\n                trades_df = pd.DataFrame(results['trades'])\n                \n                col1, col2 = st.columns(2)\n                \n                with col1:\n                    st.subheader(\"📋 Trade Log\")\n                    \n                    # Format trades for display\n                    display_trades = trades_df.copy()\n                    display_trades['PnL %'] = (display_trades['pnl'] / initial_capital * 100).round(2)\n                    display_trades['Timestamp'] = pd.to_datetime(display_trades['timestamp']).dt.strftime('%Y-%m-%d %H:%M')\n                    \n                    st.dataframe(\n                        display_trades[['Timestamp', 'type', 'price', 'confidence', 'PnL %']],\n                        use_container_width=True\n                    )\n                \n                with col2:\n                    st.subheader(\"📈 Trade Distribution\")\n                    \n                    # PnL distribution\n                    pnl_values = trades_df['pnl'].values\n                    \n                    fig = go.Figure(data=[go.Histogram(\n                        x=pnl_values,\n                        nbinsx=20,\n                        marker_color='#00D4AA'\n                    )])\n                    \n                    fig.update_layout(\n                        title=\"P&L Distribution\",\n                        xaxis_title=\"P&L ($)\",\n                        yaxis_title=\"Frequency\",\n                        height=300\n                    )\n                    \n                    st.plotly_chart(fig, use_container_width=True)\n            \n            else:\n                st.info(\"No trades were executed during the backtest period.\")\n        \n        else:\n            st.info(\"Run a backtest to see detailed results analysis.\")\n    \n    with tab3:\n        st.subheader(\"📈 Performance Metrics\")\n        \n        if 'backtest_results' in st.session_state:\n            results = st.session_state.backtest_results\n            \n            # Calculate comprehensive metrics\n            portfolio_values = np.array(results['portfolio_values'])\n            returns = np.diff(portfolio_values) / portfolio_values[:-1]\n            \n            # Risk metrics\n            col1, col2, col3 = st.columns(3)\n            \n            with col1:\n                st.subheader(\"📊 Return Metrics\")\n                \n                total_return = (portfolio_values[-1] - initial_capital) / initial_capital\n                annualized_return = (1 + total_return) ** (365 / backtest_days) - 1\n                \n                st.metric(\"Total Return\", f\"{total_return:.2%}\")\n                st.metric(\"Annualized Return\", f\"{annualized_return:.2%}\")\n                \n                if len(returns) > 0:\n                    avg_daily_return = np.mean(returns)\n                    st.metric(\"Avg Daily Return\", f\"{avg_daily_return:.4%}\")\n            \n            with col2:\n                st.subheader(\"⚠️ Risk Metrics\")\n                \n                max_drawdown = results.get('max_drawdown', 0)\n                st.metric(\"Max Drawdown\", f\"{max_drawdown:.2%}\")\n                \n                if len(returns) > 1:\n                    volatility = np.std(returns) * np.sqrt(252)  # Annualized\n                    st.metric(\"Volatility (Annual)\", f\"{volatility:.2%}\")\n                    \n                    if volatility > 0:\n                        sharpe_ratio = annualized_return / volatility\n                        st.metric(\"Sharpe Ratio\", f\"{sharpe_ratio:.2f}\")\n            \n            with col3:\n                st.subheader(\"🎯 Trade Metrics\")\n                \n                trades = results['trades']\n                if trades:\n                    total_trades = len(trades)\n                    winning_trades = sum(1 for trade in trades if trade['pnl'] > 0)\n                    win_rate = winning_trades / total_trades\n                    \n                    st.metric(\"Win Rate\", f\"{win_rate:.2%}\")\n                    st.metric(\"Total Trades\", total_trades)\n                    \n                    avg_win = np.mean([trade['pnl'] for trade in trades if trade['pnl'] > 0]) if winning_trades > 0 else 0\n                    avg_loss = np.mean([trade['pnl'] for trade in trades if trade['pnl'] < 0]) if (total_trades - winning_trades) > 0 else 0\n                    \n                    if avg_loss != 0:\n                        profit_factor = abs(avg_win / avg_loss)\n                        st.metric(\"Profit Factor\", f\"{profit_factor:.2f}\")\n            \n            # Performance comparison\n            st.subheader(\"📊 Performance Comparison\")\n            \n            # Compare with buy and hold\n            buy_hold_return = (df['close'].iloc[-1] - df['close'].iloc[0]) / df['close'].iloc[0]\n            \n            comparison_data = {\n                'Strategy': ['ML Trading', 'Buy & Hold'],\n                'Total Return': [f\"{total_return:.2%}\", f\"{buy_hold_return:.2%}\"],\n                'Annualized Return': [f\"{annualized_return:.2%}\", f\"{(1 + buy_hold_return) ** (365 / backtest_days) - 1:.2%}\"],\n                'Max Drawdown': [f\"{max_drawdown:.2%}\", \"N/A\"],\n                'Number of Trades': [len(trades), \"1\"]\n            }\n            \n            comparison_df = pd.DataFrame(comparison_data)\n            st.dataframe(comparison_df, use_container_width=True, hide_index=True)\n            \n            # Strategy vs benchmark chart\n            fig = go.Figure()\n            \n            # Normalize prices to start from same value\n            normalized_prices = df['close'].values / df['close'].values[0] * initial_capital\n            \n            portfolio_dates = pd.date_range(\n                start=pd.to_datetime(start_date),\n                periods=len(results['portfolio_values']),\n                freq='H' if model_info['interval'] == '1h' else 'D'\n            )\n            \n            benchmark_dates = df.index[:len(portfolio_dates)]\n            \n            fig.add_trace(go.Scatter(\n                x=portfolio_dates,\n                y=results['portfolio_values'],\n                mode='lines',\n                name='ML Strategy',\n                line=dict(color='#00D4AA', width=2)\n            ))\n            \n            fig.add_trace(go.Scatter(\n                x=benchmark_dates,\n                y=normalized_prices[:len(portfolio_dates)],\n                mode='lines',\n                name='Buy & Hold',\n                line=dict(color='orange', width=2)\n            ))\n            \n            fig.update_layout(\n                title=\"Strategy vs Buy & Hold Performance\",\n                xaxis_title=\"Date\",\n                yaxis_title=\"Portfolio Value ($)\",\n                height=500\n            )\n            \n            st.plotly_chart(fig, use_container_width=True)\n        \n        else:\n            st.info(\"Run a backtest to see performance metrics.\")\n\nif __name__ == \"__main__\":\n    main()\n","size_bytes":22430},"pages/5_Analytics.py":{"content":"import streamlit as st\nimport pandas as pd\nimport numpy as np\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom datetime import datetime, timedelta\nfrom utils.database import get_models, get_model_performance_history, get_trading_history\nimport sqlite3\n\nst.set_page_config(page_title=\"Analytics Dashboard\", page_icon=\"📊\", layout=\"wide\")\n\ndef main():\n    st.title(\"📊 Analytics Dashboard\")\n    st.markdown(\"---\")\n    \n    # Sidebar for analytics filters\n    with st.sidebar:\n        st.header(\"🔍 Analytics Filters\")\n        \n        # Time period selection\n        time_period = st.selectbox(\n            \"Time Period\",\n            [\"Last 7 Days\", \"Last 30 Days\", \"Last 90 Days\", \"Last Year\", \"All Time\"],\n            index=2\n        )\n        \n        # Model filter\n        try:\n            models = get_models()\n            if models:\n                model_names = [\"All Models\"] + [model['name'] for model in models]\n                selected_models = st.multiselect(\n                    \"Select Models\",\n                    model_names,\n                    default=[\"All Models\"]\n                )\n            else:\n                st.warning(\"No models found\")\n                selected_models = []\n        except Exception as e:\n            st.error(f\"Error loading models: {str(e)}\")\n            selected_models = []\n        \n        # Metric selection\n        st.subheader(\"📈 Metrics to Display\")\n        show_accuracy = st.checkbox(\"Model Accuracy\", value=True)\n        show_trading = st.checkbox(\"Trading Performance\", value=True)\n        show_risk = st.checkbox(\"Risk Metrics\", value=True)\n        show_signals = st.checkbox(\"Signal Analysis\", value=True)\n    \n    # Main dashboard\n    tab1, tab2, tab3, tab4 = st.tabs([\"📊 Overview\", \"🎯 Model Performance\", \"💹 Trading Analytics\", \"⚠️ Risk Analysis\"])\n    \n    with tab1:\n        st.subheader(\"📊 Platform Overview\")\n        \n        # Key metrics row\n        col1, col2, col3, col4, col5 = st.columns(5)\n        \n        with col1:\n            try:\n                total_models = len(get_models()) if get_models() else 0\n                st.metric(\"Total Models\", total_models, \"Active\")\n            except:\n                st.metric(\"Total Models\", \"0\", \"N/A\")\n        \n        with col2:\n            st.metric(\"Portfolio Value\", \"$10,000\", \"+2.5%\")\n        \n        with col3:\n            st.metric(\"Total Trades\", \"45\", \"+5 today\")\n        \n        with col4:\n            st.metric(\"Win Rate\", \"68.5%\", \"+3.2%\")\n        \n        with col5:\n            st.metric(\"Active Signals\", \"3\", \"2 pending\")\n        \n        st.markdown(\"---\")\n        \n        # Charts row\n        col1, col2 = st.columns(2)\n        \n        with col1:\n            st.subheader(\"📈 Portfolio Performance\")\n            \n            # Sample portfolio performance data\n            dates = pd.date_range(start='2024-01-01', periods=90, freq='D')\n            portfolio_values = 10000 * (1 + np.cumsum(np.random.normal(0.001, 0.02, 90)))\n            \n            fig = go.Figure()\n            fig.add_trace(go.Scatter(\n                x=dates,\n                y=portfolio_values,\n                mode='lines',\n                name='Portfolio Value',\n                line=dict(color='#00D4AA', width=2),\n                fill='tonexty'\n            ))\n            \n            fig.update_layout(\n                title=\"Portfolio Value Over Time\",\n                xaxis_title=\"Date\",\n                yaxis_title=\"Value ($)\",\n                height=350\n            )\n            \n            st.plotly_chart(fig, use_container_width=True)\n        \n        with col2:\n            st.subheader(\"🎯 Model Accuracy Trends\")\n            \n            # Sample model accuracy data\n            model_names = [\"LSTM_BTC\", \"RF_ETH\", \"SVM_ADA\"]\n            accuracies = [0.75, 0.68, 0.72]\n            \n            fig = go.Figure(data=[go.Bar(\n                x=model_names,\n                y=accuracies,\n                marker_color=['#00D4AA', '#FF6B6B', '#4ECDC4']\n            )])\n            \n            fig.update_layout(\n                title=\"Current Model Accuracies\",\n                xaxis_title=\"Models\",\n                yaxis_title=\"Accuracy\",\n                height=350\n            )\n            \n            st.plotly_chart(fig, use_container_width=True)\n        \n        # Recent activity\n        st.subheader(\"🕒 Recent Activity\")\n        \n        # Sample recent activity data\n        activity_data = {\n            'Time': ['10:30 AM', '09:45 AM', '09:15 AM', '08:30 AM'],\n            'Activity': [\n                'New BUY signal generated for BTCUSDT',\n                'Model LSTM_BTC_001 completed training',\n                'Trade executed: SELL ETHUSDT at $3,245.67',\n                'Backtest completed for RF_ETH_002'\n            ],\n            'Type': ['Signal', 'Training', 'Trade', 'Backtest'],\n            'Status': ['Active', 'Completed', 'Filled', 'Completed']\n        }\n        \n        activity_df = pd.DataFrame(activity_data)\n        st.dataframe(activity_df, use_container_width=True, hide_index=True)\n    \n    with tab2:\n        st.subheader(\"🎯 Model Performance Analysis\")\n        \n        if show_accuracy:\n            # Model comparison\n            col1, col2 = st.columns(2)\n            \n            with col1:\n                st.subheader(\"📊 Model Comparison\")\n                \n                # Sample model performance data\n                model_data = {\n                    'Model': ['LSTM_BTC_001', 'RF_ETH_002', 'SVM_ADA_003', 'LSTM_DOT_004'],\n                    'Type': ['LSTM', 'Random Forest', 'SVM', 'LSTM'],\n                    'Symbol': ['BTCUSDT', 'ETHUSDT', 'ADAUSDT', 'DOTUSDT'],\n                    'Accuracy': [0.847, 0.723, 0.689, 0.756],\n                    'Precision': [0.821, 0.698, 0.654, 0.732],\n                    'Recall': [0.789, 0.756, 0.723, 0.778],\n                    'F1-Score': [0.805, 0.726, 0.687, 0.755]\n                }\n                \n                model_df = pd.DataFrame(model_data)\n                st.dataframe(model_df, use_container_width=True, hide_index=True)\n            \n            with col2:\n                st.subheader(\"📈 Accuracy Over Time\")\n                \n                # Sample accuracy trend data\n                dates = pd.date_range(start='2024-01-01', periods=30, freq='D')\n                lstm_acc = 0.7 + 0.1 * np.sin(np.linspace(0, 4*np.pi, 30)) + np.random.normal(0, 0.02, 30)\n                rf_acc = 0.65 + 0.08 * np.sin(np.linspace(0, 3*np.pi, 30)) + np.random.normal(0, 0.015, 30)\n                \n                fig = go.Figure()\n                \n                fig.add_trace(go.Scatter(\n                    x=dates,\n                    y=lstm_acc,\n                    mode='lines+markers',\n                    name='LSTM Models',\n                    line=dict(color='#00D4AA')\n                ))\n                \n                fig.add_trace(go.Scatter(\n                    x=dates,\n                    y=rf_acc,\n                    mode='lines+markers',\n                    name='Random Forest',\n                    line=dict(color='#FF6B6B')\n                ))\n                \n                fig.update_layout(\n                    title=\"Model Accuracy Trends\",\n                    xaxis_title=\"Date\",\n                    yaxis_title=\"Accuracy\",\n                    height=350\n                )\n                \n                st.plotly_chart(fig, use_container_width=True)\n            \n            # Feature importance analysis\n            st.subheader(\"🎯 Feature Importance Analysis\")\n            \n            col1, col2 = st.columns(2)\n            \n            with col1:\n                # Feature importance for selected model\n                features = ['RSI', 'MACD', 'SMA_20', 'Volume', 'Price_Change', 'Bollinger_Bands', 'ATR', 'OBV']\n                importance = [0.18, 0.15, 0.14, 0.12, 0.11, 0.10, 0.08, 0.07]\n                \n                fig = go.Figure(data=[go.Bar(\n                    x=importance,\n                    y=features,\n                    orientation='h',\n                    marker_color='#00D4AA'\n                )])\n                \n                fig.update_layout(\n                    title=\"Feature Importance (LSTM_BTC_001)\",\n                    xaxis_title=\"Importance Score\",\n                    height=350\n                )\n                \n                st.plotly_chart(fig, use_container_width=True)\n            \n            with col2:\n                # Model prediction accuracy by market condition\n                conditions = ['Trending Up', 'Trending Down', 'Sideways', 'High Volatility']\n                accuracies = [0.82, 0.75, 0.68, 0.71]\n                \n                fig = go.Figure(data=[go.Bar(\n                    x=conditions,\n                    y=accuracies,\n                    marker_color=['#00D4AA', '#FF6B6B', '#FFE66D', '#4ECDC4']\n                )])\n                \n                fig.update_layout(\n                    title=\"Accuracy by Market Condition\",\n                    xaxis_title=\"Market Condition\",\n                    yaxis_title=\"Accuracy\",\n                    height=350\n                )\n                \n                st.plotly_chart(fig, use_container_width=True)\n    \n    with tab3:\n        st.subheader(\"💹 Trading Performance Analytics\")\n        \n        if show_trading:\n            # Trading metrics\n            col1, col2, col3, col4 = st.columns(4)\n            \n            with col1:\n                st.metric(\"Total P&L\", \"$1,247.32\", \"+12.47%\")\n            \n            with col2:\n                st.metric(\"Avg Trade Return\", \"2.8%\", \"+0.3%\")\n            \n            with col3:\n                st.metric(\"Best Trade\", \"$234.56\", \"BTCUSDT\")\n            \n            with col4:\n                st.metric(\"Worst Trade\", \"-$89.23\", \"ADAUSDT\")\n            \n            # Trading performance charts\n            col1, col2 = st.columns(2)\n            \n            with col1:\n                st.subheader(\"📊 P&L Distribution\")\n                \n                # Sample P&L data\n                pnl_data = np.random.normal(25, 50, 100)  # Average $25 profit, $50 std dev\n                \n                fig = go.Figure(data=[go.Histogram(\n                    x=pnl_data,\n                    nbinsx=20,\n                    marker_color='#00D4AA'\n                )])\n                \n                fig.update_layout(\n                    title=\"Trade P&L Distribution\",\n                    xaxis_title=\"P&L ($)\",\n                    yaxis_title=\"Frequency\",\n                    height=350\n                )\n                \n                st.plotly_chart(fig, use_container_width=True)\n            \n            with col2:\n                st.subheader(\"📈 Win Rate by Symbol\")\n                \n                symbols = ['BTCUSDT', 'ETHUSDT', 'ADAUSDT', 'DOTUSDT', 'LINKUSDT']\n                win_rates = [0.72, 0.68, 0.65, 0.71, 0.63]\n                \n                fig = go.Figure(data=[go.Bar(\n                    x=symbols,\n                    y=win_rates,\n                    marker_color='#00D4AA'\n                )])\n                \n                fig.update_layout(\n                    title=\"Win Rate by Trading Pair\",\n                    xaxis_title=\"Symbol\",\n                    yaxis_title=\"Win Rate\",\n                    height=350\n                )\n                \n                st.plotly_chart(fig, use_container_width=True)\n            \n            # Trading timeline\n            st.subheader(\"⏰ Trading Timeline\")\n            \n            # Sample trading data\n            trade_times = pd.date_range(start='2024-01-01', periods=20, freq='2D')\n            trade_pnl = np.random.normal(25, 40, 20)\n            trade_symbols = np.random.choice(['BTCUSDT', 'ETHUSDT', 'ADAUSDT'], 20)\n            \n            fig = go.Figure()\n            \n            colors = ['green' if pnl > 0 else 'red' for pnl in trade_pnl]\n            \n            fig.add_trace(go.Scatter(\n                x=trade_times,\n                y=trade_pnl,\n                mode='markers',\n                marker=dict(\n                    color=colors,\n                    size=10,\n                    line=dict(width=1, color='white')\n                ),\n                text=trade_symbols,\n                name='Trades'\n            ))\n            \n            fig.update_layout(\n                title=\"Trade P&L Timeline\",\n                xaxis_title=\"Date\",\n                yaxis_title=\"P&L ($)\",\n                height=400\n            )\n            \n            st.plotly_chart(fig, use_container_width=True)\n    \n    with tab4:\n        st.subheader(\"⚠️ Risk Analysis\")\n        \n        if show_risk:\n            # Risk metrics\n            col1, col2, col3, col4 = st.columns(4)\n            \n            with col1:\n                st.metric(\"Portfolio VaR (95%)\", \"$892.15\", \"Daily\")\n            \n            with col2:\n                st.metric(\"Max Drawdown\", \"8.7%\", \"-1.2%\")\n            \n            with col3:\n                st.metric(\"Sharpe Ratio\", \"1.85\", \"+0.15\")\n            \n            with col4:\n                st.metric(\"Beta\", \"0.72\", \"vs BTC\")\n            \n            # Risk analysis charts\n            col1, col2 = st.columns(2)\n            \n            with col1:\n                st.subheader(\"📉 Drawdown Analysis\")\n                \n                # Sample drawdown data\n                dates = pd.date_range(start='2024-01-01', periods=90, freq='D')\n                cumulative_returns = np.cumsum(np.random.normal(0.001, 0.02, 90))\n                running_max = np.maximum.accumulate(cumulative_returns)\n                drawdown = (cumulative_returns - running_max) * 100\n                \n                fig = go.Figure()\n                \n                fig.add_trace(go.Scatter(\n                    x=dates,\n                    y=drawdown,\n                    fill='tonexty',\n                    mode='lines',\n                    name='Drawdown',\n                    line=dict(color='red'),\n                    fillcolor='rgba(255, 0, 0, 0.3)'\n                ))\n                \n                fig.update_layout(\n                    title=\"Portfolio Drawdown\",\n                    xaxis_title=\"Date\",\n                    yaxis_title=\"Drawdown (%)\",\n                    height=350\n                )\n                \n                st.plotly_chart(fig, use_container_width=True)\n            \n            with col2:\n                st.subheader(\"📊 Risk Distribution\")\n                \n                # Risk by asset\n                assets = ['BTCUSDT', 'ETHUSDT', 'ADAUSDT', 'DOTUSDT', 'Others']\n                risk_contribution = [35, 28, 15, 12, 10]\n                \n                fig = go.Figure(data=[go.Pie(\n                    labels=assets,\n                    values=risk_contribution,\n                    hole=0.3\n                )])\n                \n                fig.update_layout(\n                    title=\"Risk Contribution by Asset\",\n                    height=350\n                )\n                \n                st.plotly_chart(fig, use_container_width=True)\n            \n            # Risk-Return Analysis\n            st.subheader(\"📈 Risk-Return Analysis\")\n            \n            # Sample data for different strategies/models\n            strategies = ['LSTM_BTC', 'RF_ETH', 'SVM_ADA', 'LSTM_DOT', 'Portfolio']\n            returns = [0.15, 0.12, 0.08, 0.10, 0.11]\n            volatilities = [0.25, 0.20, 0.15, 0.18, 0.19]\n            colors = ['#00D4AA', '#FF6B6B', '#4ECDC4', '#FFE66D', '#FF8C94']\n            \n            fig = go.Figure()\n            \n            for i, strategy in enumerate(strategies):\n                fig.add_trace(go.Scatter(\n                    x=[volatilities[i]],\n                    y=[returns[i]],\n                    mode='markers',\n                    marker=dict(\n                        color=colors[i],\n                        size=15,\n                        line=dict(width=2, color='white')\n                    ),\n                    name=strategy,\n                    text=strategy\n                ))\n            \n            fig.update_layout(\n                title=\"Risk-Return Profile\",\n                xaxis_title=\"Volatility (Risk)\",\n                yaxis_title=\"Return\",\n                height=400\n            )\n            \n            st.plotly_chart(fig, use_container_width=True)\n        \n        # Risk alerts\n        st.subheader(\"🚨 Risk Alerts\")\n        \n        # Sample risk alerts\n        alerts = [\n            {\"type\": \"Warning\", \"message\": \"Portfolio concentration above 30% in BTCUSDT\", \"severity\": \"Medium\"},\n            {\"type\": \"Info\", \"message\": \"Volatility increased 15% from last week\", \"severity\": \"Low\"},\n            {\"type\": \"Critical\", \"message\": \"Model accuracy dropped below 60% for SVM_ADA_003\", \"severity\": \"High\"}\n        ]\n        \n        for alert in alerts:\n            severity_color = {\n                \"Low\": \"info\",\n                \"Medium\": \"warning\", \n                \"High\": \"error\"\n            }\n            \n            getattr(st, severity_color[alert[\"severity\"]])(f\"**{alert['type']}**: {alert['message']}\")\n\nif __name__ == \"__main__\":\n    main()\n","size_bytes":17217},"pages/6_Model_Comparison.py":{"content":"import streamlit as st\nimport pandas as pd\nimport numpy as np\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom datetime import datetime, timedelta\nfrom utils.database import get_models, get_model_performance_history\nimport sqlite3\n\nst.set_page_config(page_title=\"Model Comparison\", page_icon=\"⚖️\", layout=\"wide\")\n\ndef main():\n    st.title(\"⚖️ Model Comparison & Evaluation\")\n    st.markdown(\"---\")\n    \n    # Sidebar for comparison settings\n    with st.sidebar:\n        st.header(\"🔧 Comparison Settings\")\n        \n        # Model selection for comparison\n        try:\n            models = get_models()\n            if models and len(models) >= 2:\n                model_names = [model['name'] for model in models]\n                \n                selected_models = st.multiselect(\n                    \"Select Models to Compare\",\n                    model_names,\n                    default=model_names[:min(3, len(model_names))],\n                    help=\"Select 2-5 models for comparison\"\n                )\n                \n                if len(selected_models) < 2:\n                    st.warning(\"Please select at least 2 models for comparison\")\n                    return\n                \n            else:\n                st.error(\"Need at least 2 trained models for comparison\")\n                return\n                \n        except Exception as e:\n            st.error(f\"Error loading models: {str(e)}\")\n            return\n        \n        # Comparison metrics\n        st.subheader(\"📊 Metrics to Compare\")\n        compare_accuracy = st.checkbox(\"Accuracy Metrics\", value=True)\n        compare_performance = st.checkbox(\"Trading Performance\", value=True)\n        compare_risk = st.checkbox(\"Risk Metrics\", value=True)\n        compare_efficiency = st.checkbox(\"Computational Efficiency\", value=True)\n        \n        # Time period for comparison\n        comparison_period = st.selectbox(\n            \"Comparison Period\",\n            [\"Last 30 Days\", \"Last 90 Days\", \"Last 6 Months\", \"All Time\"],\n            index=1\n        )\n        \n        # Sorting options\n        sort_by = st.selectbox(\n            \"Sort Models By\",\n            [\"Accuracy\", \"Trading Performance\", \"Risk-Adjusted Return\", \"Creation Date\"],\n            index=0\n        )\n    \n    # Filter selected models\n    selected_model_info = [model for model in models if model['name'] in selected_models]\n    \n    # Main comparison interface\n    tab1, tab2, tab3, tab4 = st.tabs([\"📊 Overview\", \"🎯 Performance Metrics\", \"📈 Trading Results\", \"⚙️ Technical Analysis\"])\n    \n    with tab1:\n        st.subheader(\"📊 Model Comparison Overview\")\n        \n        # Summary comparison table\n        if selected_model_info:\n            comparison_data = []\n            \n            for model in selected_model_info:\n                model_summary = {\n                    'Model Name': model['name'],\n                    'Type': model['type'],\n                    'Symbol': model['symbol'],\n                    'Timeframe': model['interval'],\n                    'Test Accuracy': f\"{model.get('test_r2', 0):.3f}\",\n                    'Test MSE': f\"{model.get('test_mse', 0):.6f}\",\n                    'Created': model['created_at'][:10] if isinstance(model['created_at'], str) else str(model['created_at'])[:10],\n                    'Features': len(model.get('features', [])),\n                    'Status': '🟢 Active'\n                }\n                comparison_data.append(model_summary)\n            \n            comparison_df = pd.DataFrame(comparison_data)\n            st.dataframe(comparison_df, use_container_width=True, hide_index=True)\n        \n        # Visual comparison charts\n        col1, col2 = st.columns(2)\n        \n        with col1:\n            st.subheader(\"🎯 Accuracy Comparison\")\n            \n            model_names = [model['name'] for model in selected_model_info]\n            accuracies = [model.get('test_r2', 0) for model in selected_model_info]\n            model_types = [model['type'] for model in selected_model_info]\n            \n            # Color mapping for model types\n            color_map = {\n                'LSTM': '#00D4AA',\n                'Random Forest': '#FF6B6B',\n                'SVM': '#4ECDC4',\n                'XGBoost': '#FFE66D'\n            }\n            \n            colors = [color_map.get(mt, '#888888') for mt in model_types]\n            \n            fig = go.Figure(data=[go.Bar(\n                x=model_names,\n                y=accuracies,\n                marker_color=colors,\n                text=[f\"{acc:.3f}\" for acc in accuracies],\n                textposition='auto'\n            )])\n            \n            fig.update_layout(\n                title=\"Model Accuracy (R² Score)\",\n                xaxis_title=\"Model\",\n                yaxis_title=\"R² Score\",\n                height=400,\n                xaxis_tickangle=-45\n            )\n            \n            st.plotly_chart(fig, use_container_width=True)\n        \n        with col2:\n            st.subheader(\"📊 Model Type Distribution\")\n            \n            type_counts = {}\n            for model in selected_model_info:\n                model_type = model['type']\n                type_counts[model_type] = type_counts.get(model_type, 0) + 1\n            \n            fig = go.Figure(data=[go.Pie(\n                labels=list(type_counts.keys()),\n                values=list(type_counts.values()),\n                hole=0.3,\n                marker_colors=[color_map.get(t, '#888888') for t in type_counts.keys()]\n            )])\n            \n            fig.update_layout(\n                title=\"Model Types in Comparison\",\n                height=400\n            )\n            \n            st.plotly_chart(fig, use_container_width=True)\n        \n        # Performance ranking\n        st.subheader(\"🏆 Model Rankings\")\n        \n        if sort_by == \"Accuracy\":\n            sorted_models = sorted(selected_model_info, key=lambda x: x.get('test_r2', 0), reverse=True)\n        else:\n            sorted_models = selected_model_info  # Default sorting\n        \n        for i, model in enumerate(sorted_models):\n            rank_emoji = [\"🥇\", \"🥈\", \"🥉\"] + [\"🔹\"] * (len(sorted_models) - 3)\n            \n            with st.expander(f\"{rank_emoji[i]} Rank {i+1}: {model['name']}\"):\n                col1, col2, col3 = st.columns(3)\n                \n                with col1:\n                    st.write(f\"**Type**: {model['type']}\")\n                    st.write(f\"**Symbol**: {model['symbol']}\")\n                    st.write(f\"**Timeframe**: {model['interval']}\")\n                \n                with col2:\n                    st.write(f\"**Accuracy**: {model.get('test_r2', 0):.3f}\")\n                    st.write(f\"**MSE**: {model.get('test_mse', 0):.6f}\")\n                    st.write(f\"**MAE**: {model.get('test_mae', 0):.6f}\")\n                \n                with col3:\n                    st.write(f\"**Features**: {len(model.get('features', []))}\")\n                    st.write(f\"**Created**: {str(model['created_at'])[:10]}\")\n                    \n                    # Hyperparameters\n                    if 'hyperparameters' in model:\n                        st.write(\"**Hyperparameters**:\")\n                        for key, value in model['hyperparameters'].items():\n                            st.write(f\"  • {key}: {value}\")\n    \n    with tab2:\n        st.subheader(\"🎯 Detailed Performance Metrics\")\n        \n        if compare_accuracy:\n            # Accuracy metrics comparison\n            st.subheader(\"📊 Accuracy Metrics\")\n            \n            metrics_data = []\n            for model in selected_model_info:\n                metrics = {\n                    'Model': model['name'],\n                    'R² Score': model.get('test_r2', 0),\n                    'MSE': model.get('test_mse', 0),\n                    'MAE': model.get('test_mae', 0),\n                    'Train R²': model.get('train_r2', 0),\n                    'Overfitting': abs(model.get('train_r2', 0) - model.get('test_r2', 0))\n                }\n                metrics_data.append(metrics)\n            \n            metrics_df = pd.DataFrame(metrics_data)\n            st.dataframe(metrics_df, use_container_width=True, hide_index=True)\n            \n            # Accuracy metrics visualization\n            fig = make_subplots(\n                rows=2, cols=2,\n                subplot_titles=('R² Score', 'MSE', 'MAE', 'Overfitting'),\n                specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n                       [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n            )\n            \n            model_names = [model['name'] for model in selected_model_info]\n            \n            # R² Score\n            fig.add_trace(go.Bar(\n                x=model_names,\n                y=[model.get('test_r2', 0) for model in selected_model_info],\n                name='R² Score',\n                marker_color='#00D4AA'\n            ), row=1, col=1)\n            \n            # MSE\n            fig.add_trace(go.Bar(\n                x=model_names,\n                y=[model.get('test_mse', 0) for model in selected_model_info],\n                name='MSE',\n                marker_color='#FF6B6B'\n            ), row=1, col=2)\n            \n            # MAE\n            fig.add_trace(go.Bar(\n                x=model_names,\n                y=[model.get('test_mae', 0) for model in selected_model_info],\n                name='MAE',\n                marker_color='#4ECDC4'\n            ), row=2, col=1)\n            \n            # Overfitting\n            overfitting = [abs(model.get('train_r2', 0) - model.get('test_r2', 0)) for model in selected_model_info]\n            fig.add_trace(go.Bar(\n                x=model_names,\n                y=overfitting,\n                name='Overfitting',\n                marker_color='#FFE66D'\n            ), row=2, col=2)\n            \n            fig.update_layout(\n                height=600,\n                showlegend=False,\n                title_text=\"Performance Metrics Comparison\"\n            )\n            \n            st.plotly_chart(fig, use_container_width=True)\n        \n        if compare_efficiency:\n            # Computational efficiency comparison\n            st.subheader(\"⚙️ Computational Efficiency\")\n            \n            # Sample efficiency data (in real implementation, this would come from training logs)\n            efficiency_data = []\n            for model in selected_model_info:\n                # Simulate efficiency metrics based on model type\n                if model['type'] == 'LSTM':\n                    training_time = np.random.uniform(300, 600)  # 5-10 minutes\n                    memory_usage = np.random.uniform(500, 1000)  # MB\n                    inference_time = np.random.uniform(0.1, 0.3)  # seconds\n                elif model['type'] == 'Random Forest':\n                    training_time = np.random.uniform(60, 180)  # 1-3 minutes\n                    memory_usage = np.random.uniform(200, 400)  # MB\n                    inference_time = np.random.uniform(0.01, 0.05)  # seconds\n                else:  # SVM\n                    training_time = np.random.uniform(120, 300)  # 2-5 minutes\n                    memory_usage = np.random.uniform(100, 300)  # MB\n                    inference_time = np.random.uniform(0.05, 0.1)  # seconds\n                \n                efficiency = {\n                    'Model': model['name'],\n                    'Training Time (min)': training_time / 60,\n                    'Memory Usage (MB)': memory_usage,\n                    'Inference Time (ms)': inference_time * 1000,\n                    'Efficiency Score': (1 / training_time) * (1 / memory_usage) * (1 / inference_time) * 1000000\n                }\n                efficiency_data.append(efficiency)\n            \n            efficiency_df = pd.DataFrame(efficiency_data)\n            st.dataframe(efficiency_df, use_container_width=True, hide_index=True)\n            \n            # Efficiency visualization\n            col1, col2 = st.columns(2)\n            \n            with col1:\n                fig = go.Figure(data=[go.Bar(\n                    x=[eff['Model'] for eff in efficiency_data],\n                    y=[eff['Training Time (min)'] for eff in efficiency_data],\n                    marker_color='#00D4AA'\n                )])\n                \n                fig.update_layout(\n                    title=\"Training Time Comparison\",\n                    xaxis_title=\"Model\",\n                    yaxis_title=\"Training Time (minutes)\",\n                    height=300\n                )\n                \n                st.plotly_chart(fig, use_container_width=True)\n            \n            with col2:\n                fig = go.Figure(data=[go.Bar(\n                    x=[eff['Model'] for eff in efficiency_data],\n                    y=[eff['Inference Time (ms)'] for eff in efficiency_data],\n                    marker_color='#FF6B6B'\n                )])\n                \n                fig.update_layout(\n                    title=\"Inference Time Comparison\",\n                    xaxis_title=\"Model\",\n                    yaxis_title=\"Inference Time (ms)\",\n                    height=300\n                )\n                \n                st.plotly_chart(fig, use_container_width=True)\n    \n    with tab3:\n        st.subheader(\"📈 Trading Performance Comparison\")\n        \n        if compare_performance:\n            # Simulated trading performance data\n            trading_performance = []\n            \n            for model in selected_model_info:\n                # Simulate trading metrics based on model accuracy\n                accuracy = model.get('test_r2', 0)\n                base_return = accuracy * 0.2  # Base return correlation with accuracy\n                \n                performance = {\n                    'Model': model['name'],\n                    'Total Return (%)': np.random.normal(base_return * 100, 5),\n                    'Win Rate (%)': np.random.normal(50 + accuracy * 30, 5),\n                    'Sharpe Ratio': np.random.normal(1.2 + accuracy, 0.3),\n                    'Max Drawdown (%)': np.random.normal(10 - accuracy * 5, 2),\n                    'Total Trades': np.random.randint(50, 200),\n                    'Avg Trade Return (%)': np.random.normal(2 + accuracy * 3, 1)\n                }\n                trading_performance.append(performance)\n            \n            trading_df = pd.DataFrame(trading_performance)\n            st.dataframe(trading_df, use_container_width=True, hide_index=True)\n            \n            # Trading performance visualization\n            fig = make_subplots(\n                rows=2, cols=2,\n                subplot_titles=('Total Return', 'Win Rate', 'Sharpe Ratio', 'Max Drawdown')\n            )\n            \n            model_names = [perf['Model'] for perf in trading_performance]\n            \n            # Total Return\n            fig.add_trace(go.Bar(\n                x=model_names,\n                y=[perf['Total Return (%)'] for perf in trading_performance],\n                name='Total Return',\n                marker_color='#00D4AA'\n            ), row=1, col=1)\n            \n            # Win Rate\n            fig.add_trace(go.Bar(\n                x=model_names,\n                y=[perf['Win Rate (%)'] for perf in trading_performance],\n                name='Win Rate',\n                marker_color='#4ECDC4'\n            ), row=1, col=2)\n            \n            # Sharpe Ratio\n            fig.add_trace(go.Bar(\n                x=model_names,\n                y=[perf['Sharpe Ratio'] for perf in trading_performance],\n                name='Sharpe Ratio',\n                marker_color='#FFE66D'\n            ), row=2, col=1)\n            \n            # Max Drawdown\n            fig.add_trace(go.Bar(\n                x=model_names,\n                y=[perf['Max Drawdown (%)'] for perf in trading_performance],\n                name='Max Drawdown',\n                marker_color='#FF6B6B'\n            ), row=2, col=2)\n            \n            fig.update_layout(\n                height=600,\n                showlegend=False,\n                title_text=\"Trading Performance Comparison\"\n            )\n            \n            st.plotly_chart(fig, use_container_width=True)\n            \n            # Risk-return scatter plot\n            st.subheader(\"📊 Risk-Return Analysis\")\n            \n            fig = go.Figure()\n            \n            for i, perf in enumerate(trading_performance):\n                fig.add_trace(go.Scatter(\n                    x=[perf['Max Drawdown (%)']],\n                    y=[perf['Total Return (%)']],\n                    mode='markers+text',\n                    marker=dict(\n                        size=15,\n                        color=colors[i % len(colors)] if 'colors' in locals() else '#00D4AA'\n                    ),\n                    text=perf['Model'],\n                    textposition=\"top center\",\n                    name=perf['Model']\n                ))\n            \n            fig.update_layout(\n                title=\"Risk vs Return Profile\",\n                xaxis_title=\"Max Drawdown (Risk) %\",\n                yaxis_title=\"Total Return %\",\n                height=500\n            )\n            \n            st.plotly_chart(fig, use_container_width=True)\n    \n    with tab4:\n        st.subheader(\"⚙️ Technical Model Analysis\")\n        \n        # Model architecture comparison\n        st.subheader(\"🏗️ Model Architecture\")\n        \n        architecture_data = []\n        for model in selected_model_info:\n            arch_info = {\n                'Model': model['name'],\n                'Type': model['type'],\n                'Input Features': len(model.get('features', [])),\n                'Parameters': 'N/A',  # Would be calculated from actual model\n                'Complexity': 'Medium'  # Would be determined by model analysis\n            }\n            \n            # Add type-specific information\n            if 'hyperparameters' in model:\n                params = model['hyperparameters']\n                if model['type'] == 'LSTM':\n                    arch_info['Units'] = params.get('units', 'N/A')\n                    arch_info['Dropout'] = params.get('dropout', 'N/A')\n                    arch_info['Complexity'] = 'High' if params.get('units', 0) > 128 else 'Medium'\n                elif model['type'] == 'Random Forest':\n                    arch_info['Trees'] = params.get('n_estimators', 'N/A')\n                    arch_info['Max Depth'] = params.get('max_depth', 'N/A')\n                    arch_info['Complexity'] = 'High' if params.get('n_estimators', 0) > 200 else 'Medium'\n                elif model['type'] == 'SVM':\n                    arch_info['Kernel'] = params.get('kernel', 'N/A')\n                    arch_info['C Parameter'] = params.get('C', 'N/A')\n                    arch_info['Complexity'] = 'Medium'\n            \n            architecture_data.append(arch_info)\n        \n        arch_df = pd.DataFrame(architecture_data)\n        st.dataframe(arch_df, use_container_width=True, hide_index=True)\n        \n        # Feature importance comparison\n        st.subheader(\"🎯 Feature Analysis\")\n        \n        col1, col2 = st.columns(2)\n        \n        with col1:\n            st.subheader(\"📊 Feature Count by Model\")\n            \n            feature_counts = [len(model.get('features', [])) for model in selected_model_info]\n            model_names = [model['name'] for model in selected_model_info]\n            \n            fig = go.Figure(data=[go.Bar(\n                x=model_names,\n                y=feature_counts,\n                marker_color='#00D4AA'\n            )])\n            \n            fig.update_layout(\n                title=\"Number of Input Features\",\n                xaxis_title=\"Model\",\n                yaxis_title=\"Feature Count\",\n                height=300\n            )\n            \n            st.plotly_chart(fig, use_container_width=True)\n        \n        with col2:\n            st.subheader(\"🔍 Common Features\")\n            \n            # Find common features across models\n            all_features = []\n            for model in selected_model_info:\n                all_features.extend(model.get('features', []))\n            \n            feature_frequency = {}\n            for feature in all_features:\n                feature_frequency[feature] = feature_frequency.get(feature, 0) + 1\n            \n            # Show most common features\n            common_features = sorted(feature_frequency.items(), key=lambda x: x[1], reverse=True)[:10]\n            \n            if common_features:\n                features, frequencies = zip(*common_features)\n                \n                fig = go.Figure(data=[go.Bar(\n                    y=features,\n                    x=frequencies,\n                    orientation='h',\n                    marker_color='#4ECDC4'\n                )])\n                \n                fig.update_layout(\n                    title=\"Most Common Features\",\n                    xaxis_title=\"Usage Count\",\n                    height=300\n                )\n                \n                st.plotly_chart(fig, use_container_width=True)\n            else:\n                st.info(\"No feature information available\")\n        \n        # Model recommendation\n        st.subheader(\"🎯 Model Recommendations\")\n        \n        # Calculate recommendation scores\n        recommendations = []\n        for model in selected_model_info:\n            accuracy = model.get('test_r2', 0)\n            overfitting = abs(model.get('train_r2', 0) - model.get('test_r2', 0))\n            \n            # Simple scoring system\n            score = accuracy * 0.6 - overfitting * 0.4\n            \n            recommendation = {\n                'model': model,\n                'score': score,\n                'accuracy': accuracy,\n                'overfitting': overfitting\n            }\n            recommendations.append(recommendation)\n        \n        # Sort by score\n        recommendations.sort(key=lambda x: x['score'], reverse=True)\n        \n        for i, rec in enumerate(recommendations):\n            model = rec['model']\n            score = rec['score']\n            \n            if i == 0:\n                st.success(f\"🏆 **Best Model**: {model['name']}\")\n                st.write(f\"   • Score: {score:.3f}\")\n                st.write(f\"   • Accuracy: {rec['accuracy']:.3f}\")\n                st.write(f\"   • Low overfitting: {rec['overfitting']:.3f}\")\n                st.write(f\"   • Recommendation: **Use for live trading**\")\n            elif i == 1:\n                st.info(f\"🥈 **Second Best**: {model['name']}\")\n                st.write(f\"   • Score: {score:.3f}\")\n                st.write(f\"   • Recommendation: **Good backup option**\")\n            else:\n                st.warning(f\"📊 **Consider Improvement**: {model['name']}\")\n                st.write(f\"   • Score: {score:.3f}\")\n                st.write(f\"   • Recommendation: **Retrain or optimize hyperparameters**\")\n\nif __name__ == \"__main__\":\n    main()\n","size_bytes":23064},"utils/backtesting_engine.py":{"content":"import pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nfrom typing import Dict, List, Tuple, Optional\nimport sqlite3\nfrom .database import get_model_by_name\nfrom .signal_generator import SignalGenerator\nfrom .data_processor import DataProcessor\n\nclass BacktestingEngine:\n    \"\"\"\n    Comprehensive backtesting engine for ML trading strategies\n    \"\"\"\n    \n    def __init__(self):\n        self.signal_generator = SignalGenerator()\n        self.data_processor = DataProcessor()\n        self.results = {}\n        \n    def run_backtest(self, model_name: str, data: pd.DataFrame, config: Dict) -> Dict:\n        \"\"\"\n        Run backtesting for a specific model and configuration\n        \n        Args:\n            model_name: Name of the ML model to use\n            data: Historical price data\n            config: Backtesting configuration\n            \n        Returns:\n            Dictionary containing backtest results\n        \"\"\"\n        try:\n            # Initialize backtesting parameters\n            initial_capital = config.get('initial_capital', 10000)\n            position_size_pct = config.get('position_size_pct', 0.1)\n            commission_pct = config.get('commission_pct', 0.001)\n            stop_loss_pct = config.get('stop_loss_pct', 0.05)\n            take_profit_pct = config.get('take_profit_pct', 0.15)\n            confidence_threshold = config.get('confidence_threshold', 0.7)\n            \n            # Initialize tracking variables\n            portfolio_value = initial_capital\n            cash = initial_capital\n            position = 0  # Number of shares/coins held\n            position_value = 0\n            \n            trades = []\n            portfolio_values = [initial_capital]\n            daily_returns = []\n            \n            # Process each data point\n            for i in range(60, len(data)):  # Start from 60 to have enough history\n                current_data = data.iloc[:i+1]\n                current_price = current_data['close'].iloc[-1]\n                \n                # Generate signal\n                signal_result = self._generate_signal_for_backtest(\n                    model_name, current_data, confidence_threshold\n                )\n                \n                if signal_result is None:\n                    # No signal, just update portfolio value\n                    position_value = position * current_price\n                    portfolio_value = cash + position_value\n                    portfolio_values.append(portfolio_value)\n                    continue\n                \n                signal_type = signal_result.get('signal_type', 'HOLD')\n                confidence = signal_result.get('confidence', 0)\n                \n                # Calculate position value\n                position_value = position * current_price\n                portfolio_value = cash + position_value\n                \n                # Execute trading logic\n                trade_executed = False\n                \n                if signal_type == 'BUY' and position == 0 and cash > 0:\n                    # Buy signal and not holding position\n                    trade_amount = min(cash * position_size_pct, cash)\n                    commission = trade_amount * commission_pct\n                    \n                    if trade_amount > commission:\n                        shares_to_buy = (trade_amount - commission) / current_price\n                        \n                        # Execute buy\n                        position = shares_to_buy\n                        cash -= trade_amount\n                        \n                        # Record trade\n                        trade = {\n                            'timestamp': current_data.index[-1],\n                            'type': 'BUY',\n                            'price': current_price,\n                            'quantity': shares_to_buy,\n                            'amount': trade_amount,\n                            'commission': commission,\n                            'confidence': confidence,\n                            'portfolio_value_before': portfolio_value,\n                            'stop_loss': current_price * (1 - stop_loss_pct),\n                            'take_profit': current_price * (1 + take_profit_pct),\n                            'pnl': 0  # Will be calculated when position is closed\n                        }\n                        trades.append(trade)\n                        trade_executed = True\n                \n                elif signal_type == 'SELL' and position > 0:\n                    # Sell signal and holding position\n                    sell_amount = position * current_price\n                    commission = sell_amount * commission_pct\n                    \n                    # Execute sell\n                    cash += (sell_amount - commission)\n                    \n                    # Calculate P&L\n                    last_buy_trade = None\n                    for trade in reversed(trades):\n                        if trade['type'] == 'BUY' and trade.get('pnl') == 0:\n                            last_buy_trade = trade\n                            break\n                    \n                    pnl = 0\n                    if last_buy_trade:\n                        buy_amount = last_buy_trade['amount']\n                        pnl = (sell_amount - commission) - buy_amount\n                        last_buy_trade['pnl'] = pnl\n                    \n                    # Record sell trade\n                    trade = {\n                        'timestamp': current_data.index[-1],\n                        'type': 'SELL',\n                        'price': current_price,\n                        'quantity': position,\n                        'amount': sell_amount,\n                        'commission': commission,\n                        'confidence': confidence,\n                        'portfolio_value_before': portfolio_value,\n                        'pnl': pnl\n                    }\n                    trades.append(trade)\n                    \n                    position = 0\n                    trade_executed = True\n                \n                # Check stop loss and take profit for existing positions\n                elif position > 0:\n                    last_buy_trade = None\n                    for trade in reversed(trades):\n                        if trade['type'] == 'BUY' and trade.get('pnl') == 0:\n                            last_buy_trade = trade\n                            break\n                    \n                    if last_buy_trade:\n                        stop_loss_price = last_buy_trade.get('stop_loss', 0)\n                        take_profit_price = last_buy_trade.get('take_profit', float('inf'))\n                        \n                        # Check stop loss\n                        if current_price <= stop_loss_price:\n                            sell_amount = position * current_price\n                            commission = sell_amount * commission_pct\n                            \n                            cash += (sell_amount - commission)\n                            \n                            # Calculate P&L\n                            buy_amount = last_buy_trade['amount']\n                            pnl = (sell_amount - commission) - buy_amount\n                            last_buy_trade['pnl'] = pnl\n                            \n                            # Record stop loss trade\n                            trade = {\n                                'timestamp': current_data.index[-1],\n                                'type': 'SELL_STOP_LOSS',\n                                'price': current_price,\n                                'quantity': position,\n                                'amount': sell_amount,\n                                'commission': commission,\n                                'confidence': 0,\n                                'portfolio_value_before': portfolio_value,\n                                'pnl': pnl\n                            }\n                            trades.append(trade)\n                            \n                            position = 0\n                            trade_executed = True\n                        \n                        # Check take profit\n                        elif current_price >= take_profit_price:\n                            sell_amount = position * current_price\n                            commission = sell_amount * commission_pct\n                            \n                            cash += (sell_amount - commission)\n                            \n                            # Calculate P&L\n                            buy_amount = last_buy_trade['amount']\n                            pnl = (sell_amount - commission) - buy_amount\n                            last_buy_trade['pnl'] = pnl\n                            \n                            # Record take profit trade\n                            trade = {\n                                'timestamp': current_data.index[-1],\n                                'type': 'SELL_TAKE_PROFIT',\n                                'price': current_price,\n                                'quantity': position,\n                                'amount': sell_amount,\n                                'commission': commission,\n                                'confidence': 0,\n                                'portfolio_value_before': portfolio_value,\n                                'pnl': pnl\n                            }\n                            trades.append(trade)\n                            \n                            position = 0\n                            trade_executed = True\n                \n                # Update portfolio value\n                position_value = position * current_price\n                portfolio_value = cash + position_value\n                portfolio_values.append(portfolio_value)\n                \n                # Calculate daily return\n                if len(portfolio_values) > 1:\n                    daily_return = (portfolio_values[-1] - portfolio_values[-2]) / portfolio_values[-2]\n                    daily_returns.append(daily_return)\n            \n            # Calculate performance metrics\n            results = self._calculate_performance_metrics(\n                initial_capital, portfolio_values, trades, daily_returns, data\n            )\n            \n            return results\n            \n        except Exception as e:\n            print(f\"Backtesting error: {e}\")\n            return {\n                'error': str(e),\n                'portfolio_values': [initial_capital],\n                'trades': [],\n                'final_value': initial_capital\n            }\n    \n    def _generate_signal_for_backtest(self, model_name: str, data: pd.DataFrame, \n                                    confidence_threshold: float) -> Optional[Dict]:\n        \"\"\"Generate signal for backtesting (simplified version)\"\"\"\n        try:\n            # Get model from database\n            model_info = get_model_by_name(model_name)\n            if not model_info:\n                return None\n            \n            # Use signal generator\n            signal = self.signal_generator.generate_signal(\n                model_name, data, confidence_threshold\n            )\n            \n            return signal\n            \n        except Exception as e:\n            print(f\"Error generating signal for backtest: {e}\")\n            return None\n    \n    def _calculate_performance_metrics(self, initial_capital: float, portfolio_values: List[float],\n                                     trades: List[Dict], daily_returns: List[float], \n                                     price_data: pd.DataFrame) -> Dict:\n        \"\"\"Calculate comprehensive performance metrics\"\"\"\n        try:\n            final_value = portfolio_values[-1]\n            total_return = (final_value - initial_capital) / initial_capital\n            \n            # Basic metrics\n            metrics = {\n                'initial_capital': initial_capital,\n                'final_value': final_value,\n                'total_return': total_return,\n                'total_return_pct': total_return * 100,\n                'portfolio_values': portfolio_values,\n                'trades': trades,\n                'total_trades': len(trades),\n                'daily_returns': daily_returns\n            }\n            \n            if len(trades) > 0:\n                # Trade analysis\n                winning_trades = [t for t in trades if t.get('pnl', 0) > 0]\n                losing_trades = [t for t in trades if t.get('pnl', 0) < 0]\n                \n                metrics['winning_trades'] = len(winning_trades)\n                metrics['losing_trades'] = len(losing_trades)\n                metrics['win_rate'] = len(winning_trades) / len([t for t in trades if 'pnl' in t and t['pnl'] != 0])\n                \n                # P&L analysis\n                total_pnl = sum([t.get('pnl', 0) for t in trades])\n                metrics['total_pnl'] = total_pnl\n                \n                if winning_trades:\n                    avg_win = np.mean([t['pnl'] for t in winning_trades])\n                    max_win = max([t['pnl'] for t in winning_trades])\n                    metrics['average_win'] = avg_win\n                    metrics['max_win'] = max_win\n                else:\n                    metrics['average_win'] = 0\n                    metrics['max_win'] = 0\n                \n                if losing_trades:\n                    avg_loss = np.mean([t['pnl'] for t in losing_trades])\n                    max_loss = min([t['pnl'] for t in losing_trades])\n                    metrics['average_loss'] = avg_loss\n                    metrics['max_loss'] = max_loss\n                else:\n                    metrics['average_loss'] = 0\n                    metrics['max_loss'] = 0\n                \n                # Profit factor\n                total_wins = sum([t['pnl'] for t in winning_trades])\n                total_losses = abs(sum([t['pnl'] for t in losing_trades]))\n                \n                if total_losses > 0:\n                    metrics['profit_factor'] = total_wins / total_losses\n                else:\n                    metrics['profit_factor'] = float('inf') if total_wins > 0 else 0\n            \n            else:\n                # No trades executed\n                metrics.update({\n                    'winning_trades': 0,\n                    'losing_trades': 0,\n                    'win_rate': 0,\n                    'total_pnl': 0,\n                    'average_win': 0,\n                    'max_win': 0,\n                    'average_loss': 0,\n                    'max_loss': 0,\n                    'profit_factor': 0\n                })\n            \n            # Risk metrics\n            if len(daily_returns) > 1:\n                returns_array = np.array(daily_returns)\n                \n                # Volatility (annualized)\n                volatility = np.std(returns_array) * np.sqrt(252)\n                metrics['volatility'] = volatility\n                \n                # Sharpe ratio (assuming risk-free rate = 0)\n                if volatility > 0:\n                    annualized_return = (1 + total_return) ** (252 / len(daily_returns)) - 1\n                    sharpe_ratio = annualized_return / volatility\n                    metrics['sharpe_ratio'] = sharpe_ratio\n                else:\n                    metrics['sharpe_ratio'] = 0\n                \n                # Maximum drawdown\n                peak = initial_capital\n                max_dd = 0\n                \n                for value in portfolio_values:\n                    if value > peak:\n                        peak = value\n                    drawdown = (peak - value) / peak\n                    if drawdown > max_dd:\n                        max_dd = drawdown\n                \n                metrics['max_drawdown'] = max_dd\n                \n                # Calmar ratio\n                if max_dd > 0:\n                    annualized_return = (1 + total_return) ** (252 / len(daily_returns)) - 1\n                    metrics['calmar_ratio'] = annualized_return / max_dd\n                else:\n                    metrics['calmar_ratio'] = float('inf') if total_return > 0 else 0\n            \n            else:\n                metrics.update({\n                    'volatility': 0,\n                    'sharpe_ratio': 0,\n                    'max_drawdown': 0,\n                    'calmar_ratio': 0\n                })\n            \n            # Benchmark comparison (Buy and Hold)\n            if len(price_data) > 0:\n                start_price = price_data['close'].iloc[0]\n                end_price = price_data['close'].iloc[-1]\n                buy_hold_return = (end_price - start_price) / start_price\n                \n                metrics['benchmark_return'] = buy_hold_return\n                metrics['benchmark_return_pct'] = buy_hold_return * 100\n                metrics['alpha'] = total_return - buy_hold_return\n                metrics['alpha_pct'] = metrics['alpha'] * 100\n            \n            return metrics\n            \n        except Exception as e:\n            print(f\"Error calculating performance metrics: {e}\")\n            return {\n                'error': str(e),\n                'portfolio_values': portfolio_values,\n                'trades': trades,\n                'final_value': portfolio_values[-1] if portfolio_values else initial_capital\n            }\n    \n    def run_walk_forward_analysis(self, model_name: str, data: pd.DataFrame, \n                                config: Dict, window_size: int = 252) -> Dict:\n        \"\"\"\n        Run walk-forward analysis for more robust backtesting\n        \n        Args:\n            model_name: Name of the ML model\n            data: Historical data\n            config: Backtesting configuration\n            window_size: Size of the rolling window in days\n            \n        Returns:\n            Walk-forward analysis results\n        \"\"\"\n        results = []\n        \n        for i in range(window_size, len(data), window_size // 4):\n            # Training window\n            train_data = data.iloc[max(0, i - window_size):i]\n            \n            # Test window\n            test_end = min(len(data), i + window_size // 4)\n            test_data = data.iloc[i:test_end]\n            \n            if len(test_data) < 10:\n                break\n            \n            # Run backtest on test window\n            window_result = self.run_backtest(model_name, test_data, config)\n            window_result['start_date'] = test_data.index[0]\n            window_result['end_date'] = test_data.index[-1]\n            \n            results.append(window_result)\n        \n        # Aggregate results\n        aggregated_results = self._aggregate_walk_forward_results(results)\n        \n        return {\n            'individual_windows': results,\n            'aggregated_metrics': aggregated_results\n        }\n    \n    def _aggregate_walk_forward_results(self, results: List[Dict]) -> Dict:\n        \"\"\"Aggregate walk-forward analysis results\"\"\"\n        if not results:\n            return {}\n        \n        # Calculate average metrics\n        total_returns = [r.get('total_return', 0) for r in results if 'error' not in r]\n        win_rates = [r.get('win_rate', 0) for r in results if 'error' not in r]\n        sharpe_ratios = [r.get('sharpe_ratio', 0) for r in results if 'error' not in r]\n        max_drawdowns = [r.get('max_drawdown', 0) for r in results if 'error' not in r]\n        \n        aggregated = {\n            'num_windows': len(results),\n            'successful_windows': len(total_returns),\n            'avg_return': np.mean(total_returns) if total_returns else 0,\n            'std_return': np.std(total_returns) if total_returns else 0,\n            'avg_win_rate': np.mean(win_rates) if win_rates else 0,\n            'avg_sharpe_ratio': np.mean(sharpe_ratios) if sharpe_ratios else 0,\n            'avg_max_drawdown': np.mean(max_drawdowns) if max_drawdowns else 0,\n            'consistency_score': len(total_returns) / len(results) if results else 0\n        }\n        \n        return aggregated\n    \n    def compare_strategies(self, models: List[str], data: pd.DataFrame, config: Dict) -> Dict:\n        \"\"\"\n        Compare multiple models/strategies\n        \n        Args:\n            models: List of model names to compare\n            data: Historical data\n            config: Backtesting configuration\n            \n        Returns:\n            Comparison results\n        \"\"\"\n        results = {}\n        \n        for model_name in models:\n            print(f\"Backtesting {model_name}...\")\n            model_result = self.run_backtest(model_name, data, config)\n            results[model_name] = model_result\n        \n        # Create comparison summary\n        comparison = self._create_strategy_comparison(results)\n        \n        return {\n            'individual_results': results,\n            'comparison_summary': comparison\n        }\n    \n    def _create_strategy_comparison(self, results: Dict) -> Dict:\n        \"\"\"Create strategy comparison summary\"\"\"\n        comparison_metrics = []\n        \n        for strategy_name, result in results.items():\n            if 'error' not in result:\n                metrics = {\n                    'strategy': strategy_name,\n                    'total_return': result.get('total_return', 0),\n                    'win_rate': result.get('win_rate', 0),\n                    'sharpe_ratio': result.get('sharpe_ratio', 0),\n                    'max_drawdown': result.get('max_drawdown', 0),\n                    'total_trades': result.get('total_trades', 0),\n                    'profit_factor': result.get('profit_factor', 0)\n                }\n                comparison_metrics.append(metrics)\n        \n        # Rank strategies\n        if comparison_metrics:\n            # Sort by Sharpe ratio (risk-adjusted return)\n            ranked_strategies = sorted(\n                comparison_metrics, \n                key=lambda x: x['sharpe_ratio'], \n                reverse=True\n            )\n            \n            return {\n                'ranked_strategies': ranked_strategies,\n                'best_strategy': ranked_strategies[0]['strategy'] if ranked_strategies else None,\n                'num_strategies': len(comparison_metrics)\n            }\n        \n        return {}\n","size_bytes":22331},"utils/binance_client.py":{"content":"import os\nimport time\nimport hmac\nimport hashlib\nimport requests\nfrom datetime import datetime\nimport websocket\nimport json\nimport threading\n\nclass BinanceClient:\n    \"\"\"\n    Binance API client for market data and trading operations\n    \"\"\"\n    \n    def __init__(self, api_key, api_secret, testnet=True):\n        self.api_key = api_key\n        self.api_secret = api_secret\n        self.testnet = testnet\n        \n        if testnet:\n            self.base_url = \"https://testnet.binance.vision\"\n            self.ws_base_url = \"wss://testnet.binance.vision/ws\"\n        else:\n            self.base_url = \"https://api.binance.com\"\n            self.ws_base_url = \"wss://stream.binance.com:9443/ws\"\n        \n        self.session = requests.Session()\n        self.session.headers.update({\n            'X-MBX-APIKEY': self.api_key\n        })\n    \n    def _generate_signature(self, data):\n        \"\"\"Generate HMAC SHA256 signature\"\"\"\n        return hmac.new(\n            self.api_secret.encode('utf-8'),\n            data.encode('utf-8'),\n            hashlib.sha256\n        ).hexdigest()\n    \n    def _make_request(self, method, endpoint, params=None, signed=False):\n        \"\"\"Make API request to Binance\"\"\"\n        url = f\"{self.base_url}{endpoint}\"\n        \n        if params is None:\n            params = {}\n        \n        if signed:\n            params['timestamp'] = int(time.time() * 1000)\n            query_string = '&'.join([f\"{k}={v}\" for k, v in params.items()])\n            params['signature'] = self._generate_signature(query_string)\n        \n        try:\n            if method == 'GET':\n                response = self.session.get(url, params=params, timeout=10)\n            elif method == 'POST':\n                response = self.session.post(url, params=params, timeout=10)\n            else:\n                raise ValueError(f\"Unsupported HTTP method: {method}\")\n            \n            response.raise_for_status()\n            return response.json()\n        \n        except requests.exceptions.RequestException as e:\n            print(f\"API request failed: {e}\")\n            return None\n        except Exception as e:\n            print(f\"Error in API request: {e}\")\n            return None\n    \n    def test_connection(self):\n        \"\"\"Test connection to Binance API\"\"\"\n        try:\n            result = self._make_request('GET', '/api/v3/ping')\n            return result is not None\n        except Exception as e:\n            print(f\"Connection test failed: {e}\")\n            return False\n    \n    def get_server_time(self):\n        \"\"\"Get server time\"\"\"\n        return self._make_request('GET', '/api/v3/time')\n    \n    def get_exchange_info(self):\n        \"\"\"Get exchange information\"\"\"\n        return self._make_request('GET', '/api/v3/exchangeInfo')\n    \n    def get_symbol_price(self, symbol):\n        \"\"\"Get current price for a symbol\"\"\"\n        params = {'symbol': symbol}\n        return self._make_request('GET', '/api/v3/ticker/price', params)\n    \n    def get_24hr_ticker(self, symbol=None):\n        \"\"\"Get 24hr ticker statistics\"\"\"\n        params = {}\n        if symbol:\n            params['symbol'] = symbol\n        return self._make_request('GET', '/api/v3/ticker/24hr', params)\n    \n    def get_klines(self, symbol, interval, limit=500, start_time=None, end_time=None):\n        \"\"\"\n        Get kline/candlestick data\n        \n        Args:\n            symbol: Trading pair symbol (e.g., 'BTCUSDT')\n            interval: Kline interval (1m, 3m, 5m, 15m, 30m, 1h, 2h, 4h, 6h, 8h, 12h, 1d, 3d, 1w, 1M)\n            limit: Number of klines to return (max 1000)\n            start_time: Start time in milliseconds\n            end_time: End time in milliseconds\n        \"\"\"\n        params = {\n            'symbol': symbol,\n            'interval': interval,\n            'limit': min(limit, 1000)\n        }\n        \n        if start_time:\n            params['startTime'] = start_time\n        if end_time:\n            params['endTime'] = end_time\n        \n        return self._make_request('GET', '/api/v3/klines', params)\n    \n    def get_orderbook(self, symbol, limit=100):\n        \"\"\"Get order book depth\"\"\"\n        params = {\n            'symbol': symbol,\n            'limit': limit\n        }\n        return self._make_request('GET', '/api/v3/depth', params)\n    \n    def get_recent_trades(self, symbol, limit=500):\n        \"\"\"Get recent trades\"\"\"\n        params = {\n            'symbol': symbol,\n            'limit': limit\n        }\n        return self._make_request('GET', '/api/v3/trades', params)\n    \n    def get_account_info(self):\n        \"\"\"Get account information\"\"\"\n        return self._make_request('GET', '/api/v3/account', signed=True)\n    \n    def get_open_orders(self, symbol=None):\n        \"\"\"Get open orders\"\"\"\n        params = {}\n        if symbol:\n            params['symbol'] = symbol\n        return self._make_request('GET', '/api/v3/openOrders', params, signed=True)\n    \n    def get_all_orders(self, symbol, limit=500):\n        \"\"\"Get all orders for a symbol\"\"\"\n        params = {\n            'symbol': symbol,\n            'limit': limit\n        }\n        return self._make_request('GET', '/api/v3/allOrders', params, signed=True)\n    \n    def place_order(self, symbol, side, order_type, quantity, price=None, time_in_force='GTC'):\n        \"\"\"\n        Place a new order\n        \n        Args:\n            symbol: Trading pair\n            side: 'BUY' or 'SELL'\n            order_type: 'LIMIT', 'MARKET', 'STOP_LOSS', etc.\n            quantity: Order quantity\n            price: Order price (required for LIMIT orders)\n            time_in_force: Time in force ('GTC', 'IOC', 'FOK')\n        \"\"\"\n        params = {\n            'symbol': symbol,\n            'side': side,\n            'type': order_type,\n            'quantity': quantity\n        }\n        \n        if order_type == 'LIMIT':\n            if price is None:\n                raise ValueError(\"Price is required for LIMIT orders\")\n            params['price'] = price\n            params['timeInForce'] = time_in_force\n        \n        return self._make_request('POST', '/api/v3/order', params, signed=True)\n    \n    def cancel_order(self, symbol, order_id):\n        \"\"\"Cancel an active order\"\"\"\n        params = {\n            'symbol': symbol,\n            'orderId': order_id\n        }\n        return self._make_request('DELETE', '/api/v3/order', params, signed=True)\n    \n    def get_trade_history(self, symbol, limit=500):\n        \"\"\"Get trade history\"\"\"\n        params = {\n            'symbol': symbol,\n            'limit': limit\n        }\n        return self._make_request('GET', '/api/v3/myTrades', params, signed=True)\n\nclass BinanceWebSocket:\n    \"\"\"\n    Binance WebSocket client for real-time data\n    \"\"\"\n    \n    def __init__(self, testnet=True):\n        self.testnet = testnet\n        self.ws = None\n        self.callbacks = {}\n        \n        if testnet:\n            self.ws_base_url = \"wss://testnet.binance.vision/ws\"\n        else:\n            self.ws_base_url = \"wss://stream.binance.com:9443/ws\"\n    \n    def on_message(self, ws, message):\n        \"\"\"Handle incoming WebSocket messages\"\"\"\n        try:\n            data = json.loads(message)\n            \n            if 'stream' in data:\n                stream = data['stream']\n                if stream in self.callbacks:\n                    self.callbacks[stream](data['data'])\n            \n        except Exception as e:\n            print(f\"Error processing WebSocket message: {e}\")\n    \n    def on_error(self, ws, error):\n        \"\"\"Handle WebSocket errors\"\"\"\n        print(f\"WebSocket error: {error}\")\n    \n    def on_close(self, ws):\n        \"\"\"Handle WebSocket close\"\"\"\n        print(\"WebSocket connection closed\")\n    \n    def subscribe_kline(self, symbol, interval, callback):\n        \"\"\"Subscribe to kline/candlestick streams\"\"\"\n        stream = f\"{symbol.lower()}@kline_{interval}\"\n        self.callbacks[stream] = callback\n        \n        ws_url = f\"{self.ws_base_url}/{stream}\"\n        \n        self.ws = websocket.WebSocketApp(\n            ws_url,\n            on_message=self.on_message,\n            on_error=self.on_error,\n            on_close=self.on_close\n        )\n        \n        # Run in a separate thread\n        ws_thread = threading.Thread(target=self.ws.run_forever)\n        ws_thread.daemon = True\n        ws_thread.start()\n        \n        return ws_thread\n    \n    def subscribe_ticker(self, symbol, callback):\n        \"\"\"Subscribe to 24hr ticker streams\"\"\"\n        stream = f\"{symbol.lower()}@ticker\"\n        self.callbacks[stream] = callback\n        \n        ws_url = f\"{self.ws_base_url}/{stream}\"\n        \n        self.ws = websocket.WebSocketApp(\n            ws_url,\n            on_message=self.on_message,\n            on_error=self.on_error,\n            on_close=self.on_close\n        )\n        \n        ws_thread = threading.Thread(target=self.ws.run_forever)\n        ws_thread.daemon = True\n        ws_thread.start()\n        \n        return ws_thread\n    \n    def close(self):\n        \"\"\"Close WebSocket connection\"\"\"\n        if self.ws:\n            self.ws.close()\n","size_bytes":9062},"utils/chart_utils.py":{"content":"import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport pandas as pd\nimport numpy as np\nimport ta\nfrom datetime import datetime, timedelta\n\ndef create_candlestick_chart(df: pd.DataFrame, symbol: str, height: int = 600) -> go.Figure:\n    \"\"\"\n    Create a professional TradingView-style candlestick chart\n    \n    Args:\n        df: DataFrame with OHLCV data\n        symbol: Trading pair symbol\n        height: Chart height in pixels\n        \n    Returns:\n        Plotly figure object\n    \"\"\"\n    \n    # Create subplots with secondary y-axis for volume\n    fig = make_subplots(\n        rows=2, cols=1,\n        shared_xaxes=True,\n        vertical_spacing=0.03,\n        subplot_titles=[f'{symbol} Price Chart', 'Volume'],\n        row_width=[0.2, 0.7]\n    )\n    \n    # Candlestick chart\n    fig.add_trace(\n        go.Candlestick(\n            x=df.index,\n            open=df['open'],\n            high=df['high'],\n            low=df['low'],\n            close=df['close'],\n            name=\"Price\",\n            increasing_line_color='#00D4AA',\n            decreasing_line_color='#FF4B4B',\n            increasing_fillcolor='#00D4AA',\n            decreasing_fillcolor='#FF4B4B'\n        ),\n        row=1, col=1\n    )\n    \n    # Volume bars\n    colors = ['#00D4AA' if close >= open else '#FF4B4B' \n              for close, open in zip(df['close'], df['open'])]\n    \n    fig.add_trace(\n        go.Bar(\n            x=df.index,\n            y=df['volume'],\n            name=\"Volume\",\n            marker_color=colors,\n            opacity=0.7\n        ),\n        row=2, col=1\n    )\n    \n    # Update layout for professional appearance\n    fig.update_layout(\n        title=f\"{symbol} Trading Chart\",\n        height=height,\n        template='plotly_dark',\n        showlegend=False,\n        xaxis_rangeslider_visible=False,\n        plot_bgcolor='rgba(0,0,0,0)',\n        paper_bgcolor='rgba(0,0,0,0)',\n        font=dict(color='white', size=12),\n        margin=dict(l=50, r=50, t=50, b=50)\n    )\n    \n    # Update x-axis\n    fig.update_xaxes(\n        showgrid=True,\n        gridwidth=1,\n        gridcolor='rgba(128, 128, 128, 0.3)',\n        showspikes=True,\n        spikecolor=\"white\",\n        spikesnap=\"cursor\",\n        spikemode=\"across\"\n    )\n    \n    # Update y-axis\n    fig.update_yaxes(\n        showgrid=True,\n        gridwidth=1,\n        gridcolor='rgba(128, 128, 128, 0.3)',\n        showspikes=True,\n        spikecolor=\"white\",\n        spikesnap=\"cursor\",\n        spikemode=\"across\"\n    )\n    \n    return fig\n\ndef add_technical_indicators(fig: go.Figure, df: pd.DataFrame, \n                           indicators: list = None) -> go.Figure:\n    \"\"\"\n    Add technical indicators to the chart\n    \n    Args:\n        fig: Existing plotly figure\n        df: DataFrame with OHLCV data\n        indicators: List of indicators to add\n        \n    Returns:\n        Updated plotly figure\n    \"\"\"\n    \n    if indicators is None:\n        indicators = ['sma_20', 'sma_50', 'bollinger', 'rsi']\n    \n    try:\n        # Moving Averages\n        if 'sma_20' in indicators:\n            sma_20 = ta.trend.sma_indicator(df['close'], window=20)\n            fig.add_trace(\n                go.Scatter(\n                    x=df.index,\n                    y=sma_20,\n                    mode='lines',\n                    name='SMA 20',\n                    line=dict(color='orange', width=1),\n                    opacity=0.8\n                ),\n                row=1, col=1\n            )\n        \n        if 'sma_50' in indicators:\n            sma_50 = ta.trend.sma_indicator(df['close'], window=50)\n            fig.add_trace(\n                go.Scatter(\n                    x=df.index,\n                    y=sma_50,\n                    mode='lines',\n                    name='SMA 50',\n                    line=dict(color='purple', width=1),\n                    opacity=0.8\n                ),\n                row=1, col=1\n            )\n        \n        # Bollinger Bands\n        if 'bollinger' in indicators:\n            bollinger = ta.volatility.BollingerBands(df['close'])\n            bb_high = bollinger.bollinger_hband()\n            bb_low = bollinger.bollinger_lband()\n            bb_mid = bollinger.bollinger_mavg()\n            \n            fig.add_trace(\n                go.Scatter(\n                    x=df.index,\n                    y=bb_high,\n                    mode='lines',\n                    name='BB Upper',\n                    line=dict(color='rgba(173, 204, 255, 0.8)', width=1),\n                    fill=None\n                ),\n                row=1, col=1\n            )\n            \n            fig.add_trace(\n                go.Scatter(\n                    x=df.index,\n                    y=bb_low,\n                    mode='lines',\n                    name='BB Lower',\n                    line=dict(color='rgba(173, 204, 255, 0.8)', width=1),\n                    fill='tonexty',\n                    fillcolor='rgba(173, 204, 255, 0.1)'\n                ),\n                row=1, col=1\n            )\n            \n            fig.add_trace(\n                go.Scatter(\n                    x=df.index,\n                    y=bb_mid,\n                    mode='lines',\n                    name='BB Mid',\n                    line=dict(color='rgba(173, 204, 255, 0.6)', width=1, dash='dash'),\n                ),\n                row=1, col=1\n            )\n        \n        # EMA\n        if 'ema_12' in indicators:\n            ema_12 = ta.trend.ema_indicator(df['close'], window=12)\n            fig.add_trace(\n                go.Scatter(\n                    x=df.index,\n                    y=ema_12,\n                    mode='lines',\n                    name='EMA 12',\n                    line=dict(color='yellow', width=1),\n                    opacity=0.8\n                ),\n                row=1, col=1\n            )\n        \n        if 'ema_26' in indicators:\n            ema_26 = ta.trend.ema_indicator(df['close'], window=26)\n            fig.add_trace(\n                go.Scatter(\n                    x=df.index,\n                    y=ema_26,\n                    mode='lines',\n                    name='EMA 26',\n                    line=dict(color='cyan', width=1),\n                    opacity=0.8\n                ),\n                row=1, col=1\n            )\n        \n    except Exception as e:\n        print(f\"Error adding technical indicators: {e}\")\n    \n    return fig\n\ndef create_rsi_chart(df: pd.DataFrame, height: int = 200) -> go.Figure:\n    \"\"\"Create RSI indicator chart\"\"\"\n    try:\n        rsi = ta.momentum.rsi(df['close'], window=14)\n        \n        fig = go.Figure()\n        \n        fig.add_trace(\n            go.Scatter(\n                x=df.index,\n                y=rsi,\n                mode='lines',\n                name='RSI',\n                line=dict(color='#FFD700', width=2)\n            )\n        )\n        \n        # Add overbought/oversold lines\n        fig.add_hline(y=70, line_dash=\"dash\", line_color=\"red\", opacity=0.5)\n        fig.add_hline(y=30, line_dash=\"dash\", line_color=\"green\", opacity=0.5)\n        fig.add_hline(y=50, line_dash=\"dot\", line_color=\"gray\", opacity=0.3)\n        \n        fig.update_layout(\n            title=\"RSI (14)\",\n            height=height,\n            template='plotly_dark',\n            showlegend=False,\n            yaxis=dict(range=[0, 100]),\n            plot_bgcolor='rgba(0,0,0,0)',\n            paper_bgcolor='rgba(0,0,0,0)',\n            font=dict(color='white', size=10)\n        )\n        \n        return fig\n        \n    except Exception as e:\n        print(f\"Error creating RSI chart: {e}\")\n        return go.Figure()\n\ndef create_macd_chart(df: pd.DataFrame, height: int = 200) -> go.Figure:\n    \"\"\"Create MACD indicator chart\"\"\"\n    try:\n        macd_indicator = ta.trend.MACD(df['close'])\n        macd = macd_indicator.macd()\n        macd_signal = macd_indicator.macd_signal()\n        macd_histogram = macd_indicator.macd_diff()\n        \n        fig = go.Figure()\n        \n        # MACD line\n        fig.add_trace(\n            go.Scatter(\n                x=df.index,\n                y=macd,\n                mode='lines',\n                name='MACD',\n                line=dict(color='#00D4AA', width=2)\n            )\n        )\n        \n        # Signal line\n        fig.add_trace(\n            go.Scatter(\n                x=df.index,\n                y=macd_signal,\n                mode='lines',\n                name='Signal',\n                line=dict(color='#FF4B4B', width=2)\n            )\n        )\n        \n        # Histogram\n        colors = ['green' if val >= 0 else 'red' for val in macd_histogram]\n        fig.add_trace(\n            go.Bar(\n                x=df.index,\n                y=macd_histogram,\n                name='Histogram',\n                marker_color=colors,\n                opacity=0.6\n            )\n        )\n        \n        fig.update_layout(\n            title=\"MACD\",\n            height=height,\n            template='plotly_dark',\n            showlegend=True,\n            plot_bgcolor='rgba(0,0,0,0)',\n            paper_bgcolor='rgba(0,0,0,0)',\n            font=dict(color='white', size=10)\n        )\n        \n        return fig\n        \n    except Exception as e:\n        print(f\"Error creating MACD chart: {e}\")\n        return go.Figure()\n\ndef create_volume_profile_chart(df: pd.DataFrame, height: int = 400) -> go.Figure:\n    \"\"\"Create volume profile chart\"\"\"\n    try:\n        # Calculate volume profile\n        price_bins = 50\n        price_range = df['high'].max() - df['low'].min()\n        bin_size = price_range / price_bins\n        \n        volume_profile = []\n        price_levels = []\n        \n        for i in range(price_bins):\n            price_level = df['low'].min() + (i * bin_size)\n            price_levels.append(price_level)\n            \n            # Calculate volume at this price level\n            mask = (\n                (df['low'] <= price_level) & \n                (df['high'] >= price_level)\n            )\n            volume_at_level = df.loc[mask, 'volume'].sum()\n            volume_profile.append(volume_at_level)\n        \n        # Create horizontal bar chart\n        fig = go.Figure()\n        \n        fig.add_trace(\n            go.Bar(\n                x=volume_profile,\n                y=price_levels,\n                orientation='h',\n                name='Volume Profile',\n                marker_color='rgba(0, 212, 170, 0.6)',\n                marker_line=dict(color='rgba(0, 212, 170, 1)', width=1)\n            )\n        )\n        \n        fig.update_layout(\n            title=\"Volume Profile\",\n            height=height,\n            template='plotly_dark',\n            showlegend=False,\n            xaxis_title=\"Volume\",\n            yaxis_title=\"Price\",\n            plot_bgcolor='rgba(0,0,0,0)',\n            paper_bgcolor='rgba(0,0,0,0)',\n            font=dict(color='white', size=10)\n        )\n        \n        return fig\n        \n    except Exception as e:\n        print(f\"Error creating volume profile chart: {e}\")\n        return go.Figure()\n\ndef add_support_resistance_levels(fig: go.Figure, df: pd.DataFrame, \n                                 window: int = 20) -> go.Figure:\n    \"\"\"Add support and resistance levels to chart\"\"\"\n    try:\n        # Calculate support and resistance\n        support_levels = df['low'].rolling(window=window, center=True).min()\n        resistance_levels = df['high'].rolling(window=window, center=True).max()\n        \n        # Get significant levels (local minima/maxima)\n        support_peaks = []\n        resistance_peaks = []\n        \n        for i in range(window, len(df) - window):\n            if support_levels.iloc[i] == df['low'].iloc[i]:\n                support_peaks.append((df.index[i], df['low'].iloc[i]))\n            \n            if resistance_levels.iloc[i] == df['high'].iloc[i]:\n                resistance_peaks.append((df.index[i], df['high'].iloc[i]))\n        \n        # Add support levels\n        for timestamp, level in support_peaks[-5:]:  # Last 5 support levels\n            fig.add_hline(\n                y=level,\n                line_dash=\"dot\",\n                line_color=\"green\",\n                opacity=0.5,\n                annotation_text=f\"Support: {level:.4f}\",\n                annotation_position=\"right\"\n            )\n        \n        # Add resistance levels\n        for timestamp, level in resistance_peaks[-5:]:  # Last 5 resistance levels\n            fig.add_hline(\n                y=level,\n                line_dash=\"dot\",\n                line_color=\"red\",\n                opacity=0.5,\n                annotation_text=f\"Resistance: {level:.4f}\",\n                annotation_position=\"right\"\n            )\n        \n        return fig\n        \n    except Exception as e:\n        print(f\"Error adding support/resistance levels: {e}\")\n        return fig\n\ndef create_multi_timeframe_chart(symbol: str, data_dict: dict) -> go.Figure:\n    \"\"\"Create multi-timeframe analysis chart\"\"\"\n    try:\n        fig = make_subplots(\n            rows=2, cols=2,\n            subplot_titles=[f'{symbol} - 1H', f'{symbol} - 4H', \n                           f'{symbol} - 1D', f'{symbol} - Volume Analysis'],\n            vertical_spacing=0.1,\n            horizontal_spacing=0.1\n        )\n        \n        timeframes = ['1h', '4h', '1d']\n        positions = [(1, 1), (1, 2), (2, 1)]\n        \n        for tf, pos in zip(timeframes, positions):\n            if tf in data_dict:\n                df = data_dict[tf]\n                \n                # Add candlestick\n                fig.add_trace(\n                    go.Candlestick(\n                        x=df.index,\n                        open=df['open'],\n                        high=df['high'],\n                        low=df['low'],\n                        close=df['close'],\n                        name=f\"{tf.upper()}\",\n                        increasing_line_color='#00D4AA',\n                        decreasing_line_color='#FF4B4B'\n                    ),\n                    row=pos[0], col=pos[1]\n                )\n                \n                # Add SMA\n                sma_20 = ta.trend.sma_indicator(df['close'], window=20)\n                fig.add_trace(\n                    go.Scatter(\n                        x=df.index,\n                        y=sma_20,\n                        mode='lines',\n                        name=f'SMA 20 {tf.upper()}',\n                        line=dict(color='orange', width=1),\n                        opacity=0.8\n                    ),\n                    row=pos[0], col=pos[1]\n                )\n        \n        # Add volume analysis in bottom right\n        if '1h' in data_dict:\n            df = data_dict['1h']\n            colors = ['#00D4AA' if close >= open else '#FF4B4B' \n                     for close, open in zip(df['close'], df['open'])]\n            \n            fig.add_trace(\n                go.Bar(\n                    x=df.index,\n                    y=df['volume'],\n                    name=\"Volume\",\n                    marker_color=colors,\n                    opacity=0.7\n                ),\n                row=2, col=2\n            )\n        \n        fig.update_layout(\n            height=800,\n            template='plotly_dark',\n            showlegend=False,\n            plot_bgcolor='rgba(0,0,0,0)',\n            paper_bgcolor='rgba(0,0,0,0)',\n            font=dict(color='white', size=10)\n        )\n        \n        # Remove range slider for all subplots\n        fig.update_xaxes(rangeslider_visible=False)\n        \n        return fig\n        \n    except Exception as e:\n        print(f\"Error creating multi-timeframe chart: {e}\")\n        return go.Figure()\n\ndef create_correlation_matrix(symbols: list, data_dict: dict) -> go.Figure:\n    \"\"\"Create correlation matrix heatmap\"\"\"\n    try:\n        # Prepare price data\n        price_data = {}\n        for symbol in symbols:\n            if symbol in data_dict:\n                price_data[symbol] = data_dict[symbol]['close']\n        \n        if not price_data:\n            return go.Figure()\n        \n        # Create correlation matrix\n        correlation_df = pd.DataFrame(price_data).corr()\n        \n        fig = go.Figure(data=go.Heatmap(\n            z=correlation_df.values,\n            x=correlation_df.columns,\n            y=correlation_df.columns,\n            colorscale='RdBu',\n            zmid=0,\n            text=correlation_df.values.round(2),\n            texttemplate=\"%{text}\",\n            textfont={\"size\": 12},\n            showscale=True\n        ))\n        \n        fig.update_layout(\n            title=\"Asset Correlation Matrix\",\n            template='plotly_dark',\n            height=400,\n            font=dict(color='white')\n        )\n        \n        return fig\n        \n    except Exception as e:\n        print(f\"Error creating correlation matrix: {e}\")\n        return go.Figure()\n\ndef add_trade_markers(fig: go.Figure, trades: list) -> go.Figure:\n    \"\"\"Add buy/sell trade markers to chart\"\"\"\n    try:\n        buy_trades = [t for t in trades if t['type'] in ['BUY', 'buy']]\n        sell_trades = [t for t in trades if t['type'] in ['SELL', 'sell']]\n        \n        if buy_trades:\n            buy_x = [t['timestamp'] for t in buy_trades]\n            buy_y = [t['price'] for t in buy_trades]\n            \n            fig.add_trace(\n                go.Scatter(\n                    x=buy_x,\n                    y=buy_y,\n                    mode='markers',\n                    name='Buy Orders',\n                    marker=dict(\n                        symbol='triangle-up',\n                        size=12,\n                        color='green',\n                        line=dict(color='white', width=2)\n                    )\n                )\n            )\n        \n        if sell_trades:\n            sell_x = [t['timestamp'] for t in sell_trades]\n            sell_y = [t['price'] for t in sell_trades]\n            \n            fig.add_trace(\n                go.Scatter(\n                    x=sell_x,\n                    y=sell_y,\n                    mode='markers',\n                    name='Sell Orders',\n                    marker=dict(\n                        symbol='triangle-down',\n                        size=12,\n                        color='red',\n                        line=dict(color='white', width=2)\n                    )\n                )\n            )\n        \n        return fig\n        \n    except Exception as e:\n        print(f\"Error adding trade markers: {e}\")\n        return fig\n\ndef create_portfolio_performance_chart(portfolio_history: list, \n                                     benchmark_data: pd.DataFrame = None) -> go.Figure:\n    \"\"\"Create portfolio performance comparison chart\"\"\"\n    try:\n        if not portfolio_history:\n            return go.Figure()\n        \n        # Extract portfolio data\n        dates = [p['timestamp'] for p in portfolio_history]\n        values = [p['total_value'] for p in portfolio_history]\n        \n        fig = go.Figure()\n        \n        # Portfolio performance\n        fig.add_trace(\n            go.Scatter(\n                x=dates,\n                y=values,\n                mode='lines',\n                name='Portfolio Value',\n                line=dict(color='#00D4AA', width=3)\n            )\n        )\n        \n        # Add benchmark if provided\n        if benchmark_data is not None and not benchmark_data.empty:\n            # Normalize benchmark to same starting value\n            start_value = values[0] if values else 10000\n            benchmark_normalized = (benchmark_data['close'] / benchmark_data['close'].iloc[0]) * start_value\n            \n            fig.add_trace(\n                go.Scatter(\n                    x=benchmark_data.index,\n                    y=benchmark_normalized,\n                    mode='lines',\n                    name='Benchmark (Buy & Hold)',\n                    line=dict(color='orange', width=2, dash='dash')\n                )\n            )\n        \n        fig.update_layout(\n            title=\"Portfolio Performance\",\n            height=400,\n            template='plotly_dark',\n            xaxis_title=\"Date\",\n            yaxis_title=\"Portfolio Value ($)\",\n            showlegend=True,\n            plot_bgcolor='rgba(0,0,0,0)',\n            paper_bgcolor='rgba(0,0,0,0)',\n            font=dict(color='white')\n        )\n        \n        return fig\n        \n    except Exception as e:\n        print(f\"Error creating portfolio performance chart: {e}\")\n        return go.Figure()\n","size_bytes":20339},"utils/data_processor.py":{"content":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\nfrom sklearn.model_selection import train_test_split\nimport ta\nfrom ta.utils import dropna\nimport warnings\nwarnings.filterwarnings('ignore')\n\nclass DataProcessor:\n    \"\"\"\n    Data processing utility for financial time series data\n    \"\"\"\n    \n    def __init__(self, scaler_type='standard'):\n        \"\"\"\n        Initialize data processor\n        \n        Args:\n            scaler_type: Type of scaler to use ('standard', 'minmax', 'robust')\n        \"\"\"\n        self.scaler_type = scaler_type\n        self.scaler = self._get_scaler()\n        self.feature_columns = []\n        self.target_column = None\n        \n    def _get_scaler(self):\n        \"\"\"Get the appropriate scaler\"\"\"\n        if self.scaler_type == 'standard':\n            return StandardScaler()\n        elif self.scaler_type == 'minmax':\n            return MinMaxScaler()\n        elif self.scaler_type == 'robust':\n            return RobustScaler()\n        else:\n            raise ValueError(f\"Unsupported scaler type: {self.scaler_type}\")\n    \n    def add_technical_indicators(self, df):\n        \"\"\"\n        Add technical indicators to the dataframe\n        \n        Args:\n            df: DataFrame with OHLCV data\n            \n        Returns:\n            DataFrame with technical indicators\n        \"\"\"\n        df_processed = df.copy()\n        \n        try:\n            # Clean data\n            df_processed = dropna(df_processed)\n            \n            # Price-based indicators\n            df_processed['sma_10'] = ta.trend.sma_indicator(df_processed['close'], window=10)\n            df_processed['sma_20'] = ta.trend.sma_indicator(df_processed['close'], window=20)\n            df_processed['sma_50'] = ta.trend.sma_indicator(df_processed['close'], window=50)\n            \n            df_processed['ema_10'] = ta.trend.ema_indicator(df_processed['close'], window=10)\n            df_processed['ema_20'] = ta.trend.ema_indicator(df_processed['close'], window=20)\n            \n            # Bollinger Bands\n            bollinger = ta.volatility.BollingerBands(df_processed['close'])\n            df_processed['bb_high'] = bollinger.bollinger_hband()\n            df_processed['bb_low'] = bollinger.bollinger_lband()\n            df_processed['bb_mid'] = bollinger.bollinger_mavg()\n            df_processed['bb_width'] = (df_processed['bb_high'] - df_processed['bb_low']) / df_processed['bb_mid']\n            df_processed['bb_position'] = (df_processed['close'] - df_processed['bb_low']) / (df_processed['bb_high'] - df_processed['bb_low'])\n            \n            # RSI\n            df_processed['rsi'] = ta.momentum.rsi(df_processed['close'], window=14)\n            df_processed['rsi_30'] = (df_processed['rsi'] < 30).astype(int)\n            df_processed['rsi_70'] = (df_processed['rsi'] > 70).astype(int)\n            \n            # MACD\n            macd = ta.trend.MACD(df_processed['close'])\n            df_processed['macd'] = macd.macd()\n            df_processed['macd_signal'] = macd.macd_signal()\n            df_processed['macd_histogram'] = macd.macd_diff()\n            df_processed['macd_bullish'] = (df_processed['macd'] > df_processed['macd_signal']).astype(int)\n            \n            # Stochastic Oscillator\n            stoch = ta.momentum.StochasticOscillator(df_processed['high'], df_processed['low'], df_processed['close'])\n            df_processed['stoch_k'] = stoch.stoch()\n            df_processed['stoch_d'] = stoch.stoch_signal()\n            df_processed['stoch_oversold'] = (df_processed['stoch_k'] < 20).astype(int)\n            df_processed['stoch_overbought'] = (df_processed['stoch_k'] > 80).astype(int)\n            \n            # Williams %R\n            df_processed['williams_r'] = ta.momentum.williams_r(df_processed['high'], df_processed['low'], df_processed['close'])\n            \n            # Average True Range (ATR)\n            df_processed['atr'] = ta.volatility.average_true_range(df_processed['high'], df_processed['low'], df_processed['close'])\n            \n            # Commodity Channel Index (CCI)\n            df_processed['cci'] = ta.trend.cci(df_processed['high'], df_processed['low'], df_processed['close'])\n            \n            # Volume indicators (if volume data is available)\n            if 'volume' in df_processed.columns:\n                # Volume SMA (manual calculation since ta.volume.volume_sma doesn't exist)\n                df_processed['volume_sma'] = df_processed['volume'].rolling(window=20).mean()\n                df_processed['volume_ratio'] = df_processed['volume'] / df_processed['volume_sma']\n                \n                # On Balance Volume (OBV)\n                df_processed['obv'] = ta.volume.on_balance_volume(df_processed['close'], df_processed['volume'])\n                \n                # Volume Price Trend (VPT)\n                df_processed['vpt'] = ta.volume.volume_price_trend(df_processed['close'], df_processed['volume'])\n                \n                # Money Flow Index (MFI)\n                df_processed['mfi'] = ta.volume.money_flow_index(df_processed['high'], df_processed['low'], \n                                                               df_processed['close'], df_processed['volume'])\n            \n            # Price action features\n            df_processed['price_change'] = df_processed['close'].pct_change()\n            df_processed['price_change_abs'] = np.abs(df_processed['price_change'])\n            \n            # High-Low spread\n            df_processed['hl_spread'] = (df_processed['high'] - df_processed['low']) / df_processed['close']\n            \n            # Open-Close spread  \n            df_processed['oc_spread'] = (df_processed['close'] - df_processed['open']) / df_processed['open']\n            \n            # Volatility measures\n            df_processed['volatility_10'] = df_processed['price_change'].rolling(window=10).std()\n            df_processed['volatility_20'] = df_processed['price_change'].rolling(window=20).std()\n            \n            # Support and resistance levels\n            df_processed['support_20'] = df_processed['low'].rolling(window=20).min()\n            df_processed['resistance_20'] = df_processed['high'].rolling(window=20).max()\n            df_processed['support_distance'] = (df_processed['close'] - df_processed['support_20']) / df_processed['close']\n            df_processed['resistance_distance'] = (df_processed['resistance_20'] - df_processed['close']) / df_processed['close']\n            \n            # Trend indicators\n            df_processed['trend_5'] = np.where(df_processed['close'] > df_processed['close'].shift(5), 1, 0)\n            df_processed['trend_10'] = np.where(df_processed['close'] > df_processed['close'].shift(10), 1, 0)\n            df_processed['trend_20'] = np.where(df_processed['close'] > df_processed['close'].shift(20), 1, 0)\n            \n        except Exception as e:\n            print(f\"Error adding technical indicators: {e}\")\n        \n        # Fill NaN values\n        df_processed = df_processed.fillna(method='ffill').fillna(method='bfill')\n        \n        return df_processed\n    \n    def add_lag_features(self, df, columns, lags=[1, 2, 3, 5, 10]):\n        \"\"\"\n        Add lagged features\n        \n        Args:\n            df: Input dataframe\n            columns: List of columns to create lags for\n            lags: List of lag periods\n            \n        Returns:\n            DataFrame with lag features\n        \"\"\"\n        df_lagged = df.copy()\n        \n        for col in columns:\n            if col in df_lagged.columns:\n                for lag in lags:\n                    df_lagged[f'{col}_lag_{lag}'] = df_lagged[col].shift(lag)\n        \n        return df_lagged\n    \n    def add_rolling_features(self, df, columns, windows=[5, 10, 20]):\n        \"\"\"\n        Add rolling statistical features\n        \n        Args:\n            df: Input dataframe\n            columns: List of columns to create rolling features for\n            windows: List of window sizes\n            \n        Returns:\n            DataFrame with rolling features\n        \"\"\"\n        df_rolling = df.copy()\n        \n        for col in columns:\n            if col in df_rolling.columns:\n                for window in windows:\n                    df_rolling[f'{col}_mean_{window}'] = df_rolling[col].rolling(window=window).mean()\n                    df_rolling[f'{col}_std_{window}'] = df_rolling[col].rolling(window=window).std()\n                    df_rolling[f'{col}_min_{window}'] = df_rolling[col].rolling(window=window).min()\n                    df_rolling[f'{col}_max_{window}'] = df_rolling[col].rolling(window=window).max()\n                    \n                    # Z-score features\n                    rolling_mean = df_rolling[col].rolling(window=window).mean()\n                    rolling_std = df_rolling[col].rolling(window=window).std()\n                    df_rolling[f'{col}_zscore_{window}'] = (df_rolling[col] - rolling_mean) / rolling_std\n        \n        return df_rolling\n    \n    def prepare_features(self, df, include_technical=True, include_volume=True, \n                        include_price_changes=True, include_lags=True, include_rolling=True):\n        \"\"\"\n        Prepare comprehensive feature set for ML models\n        \n        Args:\n            df: Input dataframe with OHLCV data\n            include_technical: Include technical indicators\n            include_volume: Include volume-based features\n            include_price_changes: Include price change features\n            include_lags: Include lagged features\n            include_rolling: Include rolling statistical features\n            \n        Returns:\n            DataFrame with prepared features\n        \"\"\"\n        df_features = df.copy()\n        \n        # Add technical indicators\n        if include_technical:\n            df_features = self.add_technical_indicators(df_features)\n        \n        # Add lagged features\n        if include_lags:\n            price_cols = ['close', 'high', 'low', 'open']\n            available_price_cols = [col for col in price_cols if col in df_features.columns]\n            if available_price_cols:\n                df_features = self.add_lag_features(df_features, available_price_cols, lags=[1, 2, 3, 5])\n        \n        # Add rolling features\n        if include_rolling:\n            feature_cols = ['close', 'volume'] if include_volume else ['close']\n            available_feature_cols = [col for col in feature_cols if col in df_features.columns]\n            if available_feature_cols:\n                df_features = self.add_rolling_features(df_features, available_feature_cols, windows=[5, 10])\n        \n        # Remove columns that shouldn't be features\n        columns_to_remove = []\n        if not include_volume and 'volume' in df_features.columns:\n            volume_cols = [col for col in df_features.columns if 'volume' in col.lower() or col in ['obv', 'vpt', 'mfi']]\n            columns_to_remove.extend(volume_cols)\n        \n        # Remove original OHLC columns except close (target)\n        ohlc_to_remove = ['open', 'high', 'low']\n        for col in ohlc_to_remove:\n            if col in df_features.columns:\n                columns_to_remove.append(col)\n        \n        # Remove timestamp if present\n        if 'timestamp' in df_features.columns:\n            columns_to_remove.append('timestamp')\n        \n        df_features = df_features.drop(columns=columns_to_remove, errors='ignore')\n        \n        # Handle infinite values and NaN\n        df_features = df_features.replace([np.inf, -np.inf], np.nan)\n        df_features = df_features.fillna(method='ffill').fillna(method='bfill')\n        df_features = df_features.fillna(0)\n        \n        return df_features\n    \n    def prepare_training_data(self, df, target_col='close', test_size=0.2, \n                            sequence_length=None, future_periods=1):\n        \"\"\"\n        Prepare data for training ML models\n        \n        Args:\n            df: Dataframe with features\n            target_col: Target column name\n            test_size: Proportion of data for testing\n            sequence_length: For LSTM models, length of sequences\n            future_periods: Number of periods to predict ahead\n            \n        Returns:\n            Tuple of (X_train, X_test, y_train, y_test, scaler)\n        \"\"\"\n        # Create target variable (future price)\n        df_processed = df.copy()\n        df_processed[f'{target_col}_target'] = df_processed[target_col].shift(-future_periods)\n        \n        # Remove rows with NaN target\n        df_processed = df_processed.dropna()\n        \n        if len(df_processed) < 50:\n            raise ValueError(\"Insufficient data after preprocessing\")\n        \n        # Separate features and target\n        feature_cols = [col for col in df_processed.columns if col != f'{target_col}_target']\n        \n        # Remove the original target column from features if it exists\n        if target_col in feature_cols:\n            feature_cols.remove(target_col)\n        \n        X = df_processed[feature_cols]\n        y = df_processed[f'{target_col}_target']\n        \n        self.feature_columns = feature_cols\n        self.target_column = target_col\n        \n        # Scale features\n        X_scaled = self.scaler.fit_transform(X)\n        \n        if sequence_length is not None:\n            # Prepare sequence data for LSTM\n            X_sequences = []\n            y_sequences = []\n            \n            for i in range(sequence_length, len(X_scaled)):\n                X_sequences.append(X_scaled[i-sequence_length:i])\n                y_sequences.append(y.iloc[i])\n            \n            X_sequences = np.array(X_sequences)\n            y_sequences = np.array(y_sequences)\n            \n            # Split data\n            split_idx = int(len(X_sequences) * (1 - test_size))\n            \n            X_train = X_sequences[:split_idx]\n            X_test = X_sequences[split_idx:]\n            y_train = y_sequences[:split_idx]\n            y_test = y_sequences[split_idx:]\n        \n        else:\n            # Traditional train-test split\n            X_train, X_test, y_train, y_test = train_test_split(\n                X_scaled, y.values, test_size=test_size, shuffle=False\n            )\n        \n        return X_train, X_test, y_train, y_test, self.scaler\n    \n    def transform_new_data(self, df):\n        \"\"\"\n        Transform new data using fitted scaler\n        \n        Args:\n            df: New dataframe to transform\n            \n        Returns:\n            Scaled feature array\n        \"\"\"\n        if not self.feature_columns:\n            raise ValueError(\"No feature columns defined. Run prepare_training_data first.\")\n        \n        # Prepare features the same way as training data\n        df_features = self.prepare_features(df)\n        \n        # Select only the features used in training\n        available_features = [col for col in self.feature_columns if col in df_features.columns]\n        \n        if len(available_features) != len(self.feature_columns):\n            missing_features = set(self.feature_columns) - set(available_features)\n            print(f\"Warning: Missing features: {missing_features}\")\n        \n        X = df_features[available_features]\n        X_scaled = self.scaler.transform(X)\n        \n        return X_scaled\n    \n    def create_sequences(self, data, sequence_length):\n        \"\"\"\n        Create sequences for LSTM models\n        \n        Args:\n            data: Input data array\n            sequence_length: Length of sequences\n            \n        Returns:\n            Array of sequences\n        \"\"\"\n        sequences = []\n        \n        for i in range(sequence_length, len(data)):\n            sequences.append(data[i-sequence_length:i])\n        \n        return np.array(sequences)\n    \n    def inverse_transform_target(self, y_scaled):\n        \"\"\"\n        Inverse transform target values if they were scaled\n        \n        Args:\n            y_scaled: Scaled target values\n            \n        Returns:\n            Original scale target values\n        \"\"\"\n        # If target was scaled separately, implement inverse transform here\n        # For now, assuming target is not scaled\n        return y_scaled\n    \n    def get_feature_names(self):\n        \"\"\"Get list of feature names\"\"\"\n        return self.feature_columns.copy()\n    \n    def calculate_feature_importance_correlation(self, df, target_col='close'):\n        \"\"\"\n        Calculate feature importance based on correlation with target\n        \n        Args:\n            df: Dataframe with features\n            target_col: Target column name\n            \n        Returns:\n            Dictionary of feature importance scores\n        \"\"\"\n        df_features = self.prepare_features(df)\n        \n        if target_col not in df_features.columns:\n            print(f\"Target column {target_col} not found\")\n            return {}\n        \n        feature_cols = [col for col in df_features.columns if col != target_col]\n        correlations = {}\n        \n        for col in feature_cols:\n            try:\n                corr = np.corrcoef(df_features[col], df_features[target_col])[0, 1]\n                if not np.isnan(corr):\n                    correlations[col] = abs(corr)\n            except:\n                correlations[col] = 0.0\n        \n        # Sort by importance\n        sorted_features = dict(sorted(correlations.items(), key=lambda x: x[1], reverse=True))\n        \n        return sorted_features\n","size_bytes":17507},"utils/database.py":{"content":"import sqlite3\nimport pandas as pd\nimport numpy as np\nimport pickle\nimport json\nimport os\nfrom datetime import datetime, timedelta\nfrom typing import Dict, List, Optional, Tuple, Any\nimport joblib\nimport tensorflow as tf\n\n# Database file path\nDB_PATH = \"trading_platform.db\"\n\ndef init_database():\n    \"\"\"Initialize the database with required tables\"\"\"\n    try:\n        conn = sqlite3.connect(DB_PATH)\n        cursor = conn.cursor()\n        \n        # Models table\n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS models (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                name TEXT UNIQUE NOT NULL,\n                type TEXT NOT NULL,\n                symbol TEXT NOT NULL,\n                interval TEXT NOT NULL,\n                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                train_mse REAL,\n                test_mse REAL,\n                train_mae REAL,\n                test_mae REAL,\n                train_r2 REAL,\n                test_r2 REAL,\n                features TEXT,\n                hyperparameters TEXT,\n                model_data BLOB,\n                scaler_data BLOB,\n                status TEXT DEFAULT 'active'\n            )\n        ''')\n        \n        # Market data table\n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS market_data (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                symbol TEXT NOT NULL,\n                timestamp TIMESTAMP NOT NULL,\n                open_price REAL NOT NULL,\n                high_price REAL NOT NULL,\n                low_price REAL NOT NULL,\n                close_price REAL NOT NULL,\n                volume REAL NOT NULL,\n                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                UNIQUE(symbol, timestamp)\n            )\n        ''')\n        \n        # Trading signals table\n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS trading_signals (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                model_name TEXT NOT NULL,\n                symbol TEXT NOT NULL,\n                signal_type TEXT NOT NULL,\n                confidence REAL NOT NULL,\n                current_price REAL NOT NULL,\n                predicted_price REAL NOT NULL,\n                position_size REAL,\n                stop_loss REAL,\n                take_profit REAL,\n                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                status TEXT DEFAULT 'active',\n                result TEXT,\n                actual_return REAL\n            )\n        ''')\n        \n        # Trading history table\n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS trading_history (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                symbol TEXT NOT NULL,\n                trade_type TEXT NOT NULL,\n                quantity REAL NOT NULL,\n                price REAL NOT NULL,\n                amount REAL NOT NULL,\n                commission REAL NOT NULL,\n                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                order_id TEXT,\n                status TEXT DEFAULT 'filled',\n                pnl REAL\n            )\n        ''')\n        \n        # Model performance tracking\n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS model_performance (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                model_name TEXT NOT NULL,\n                evaluation_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                accuracy_score REAL,\n                precision_score REAL,\n                recall_score REAL,\n                f1_score REAL,\n                mse REAL,\n                mae REAL,\n                r2_score REAL,\n                prediction_count INTEGER,\n                correct_predictions INTEGER\n            )\n        ''')\n        \n        # Portfolio tracking\n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS portfolio (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                total_value REAL NOT NULL,\n                cash_balance REAL NOT NULL,\n                positions TEXT,\n                daily_return REAL,\n                total_return REAL\n            )\n        ''')\n        \n        # Strategy results table\n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS strategy_results (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                strategy_name TEXT NOT NULL,\n                model_name TEXT NOT NULL,\n                symbol TEXT NOT NULL,\n                start_date TIMESTAMP NOT NULL,\n                end_date TIMESTAMP NOT NULL,\n                initial_capital REAL NOT NULL,\n                final_value REAL NOT NULL,\n                total_return REAL NOT NULL,\n                total_trades INTEGER,\n                winning_trades INTEGER,\n                losing_trades INTEGER,\n                win_rate REAL,\n                max_drawdown REAL,\n                sharpe_ratio REAL,\n                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n            )\n        ''')\n        \n        conn.commit()\n        print(\"Database initialized successfully\")\n        \n    except Exception as e:\n        print(f\"Error initializing database: {e}\")\n    finally:\n        conn.close()\n\ndef store_model(model_name: str, model: Any, scaler: Any, model_info: Dict):\n    \"\"\"Store a trained model in the database\"\"\"\n    try:\n        conn = sqlite3.connect(DB_PATH)\n        cursor = conn.cursor()\n        \n        # Serialize model and scaler\n        if model_info['type'] == 'LSTM':\n            # Save Keras model to temporary file and read as binary\n            temp_model_path = f\"temp_{model_name}_model.h5\"\n            model.model.save(temp_model_path)\n            \n            with open(temp_model_path, 'rb') as f:\n                model_data = f.read()\n            \n            # Clean up temporary file\n            os.remove(temp_model_path)\n            \n        else:\n            # For scikit-learn models\n            model_data = pickle.dumps(model.model)\n        \n        scaler_data = pickle.dumps(scaler) if scaler else None\n        features_json = json.dumps(model_info.get('features', []))\n        hyperparams_json = json.dumps(model_info.get('hyperparameters', {}))\n        \n        # Insert or update model\n        cursor.execute('''\n            INSERT OR REPLACE INTO models (\n                name, type, symbol, interval, train_mse, test_mse,\n                train_mae, test_mae, train_r2, test_r2, features,\n                hyperparameters, model_data, scaler_data\n            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n        ''', (\n            model_name,\n            model_info['type'],\n            model_info['symbol'],\n            model_info['interval'],\n            model_info.get('train_mse'),\n            model_info.get('test_mse'),\n            model_info.get('train_mae'),\n            model_info.get('test_mae'),\n            model_info.get('train_r2'),\n            model_info.get('test_r2'),\n            features_json,\n            hyperparams_json,\n            model_data,\n            scaler_data\n        ))\n        \n        conn.commit()\n        print(f\"Model {model_name} stored successfully\")\n        \n    except Exception as e:\n        print(f\"Error storing model: {e}\")\n    finally:\n        conn.close()\n\ndef get_models() -> List[Dict]:\n    \"\"\"Get all stored models\"\"\"\n    try:\n        conn = sqlite3.connect(DB_PATH)\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            SELECT name, type, symbol, interval, created_at,\n                   train_r2, test_r2, train_mse, test_mse,\n                   features, hyperparameters, status\n            FROM models WHERE status = 'active'\n            ORDER BY created_at DESC\n        ''')\n        \n        models = []\n        for row in cursor.fetchall():\n            features = json.loads(row[9]) if row[9] else []\n            hyperparams = json.loads(row[10]) if row[10] else {}\n            \n            model_info = {\n                'name': row[0],\n                'type': row[1],\n                'symbol': row[2],\n                'interval': row[3],\n                'created_at': row[4],\n                'train_r2': row[5],\n                'test_r2': row[6],\n                'train_mse': row[7],\n                'test_mse': row[8],\n                'features': features,\n                'hyperparameters': hyperparams,\n                'status': row[11]\n            }\n            models.append(model_info)\n        \n        return models\n        \n    except Exception as e:\n        print(f\"Error getting models: {e}\")\n        return []\n    finally:\n        conn.close()\n\ndef get_model_by_name(model_name: str) -> Optional[Dict]:\n    \"\"\"Get a specific model by name\"\"\"\n    try:\n        conn = sqlite3.connect(DB_PATH)\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            SELECT name, type, symbol, interval, created_at,\n                   train_r2, test_r2, train_mse, test_mse,\n                   features, hyperparameters, status\n            FROM models WHERE name = ? AND status = 'active'\n        ''', (model_name,))\n        \n        row = cursor.fetchone()\n        if row:\n            features = json.loads(row[9]) if row[9] else []\n            hyperparams = json.loads(row[10]) if row[10] else {}\n            \n            return {\n                'name': row[0],\n                'type': row[1],\n                'symbol': row[2],\n                'interval': row[3],\n                'created_at': row[4],\n                'train_r2': row[5],\n                'test_r2': row[6],\n                'train_mse': row[7],\n                'test_mse': row[8],\n                'features': features,\n                'hyperparameters': hyperparams,\n                'status': row[11]\n            }\n        \n        return None\n        \n    except Exception as e:\n        print(f\"Error getting model by name: {e}\")\n        return None\n    finally:\n        conn.close()\n\ndef load_model_from_db(model_name: str) -> Tuple[Any, Any]:\n    \"\"\"Load a model and scaler from database\"\"\"\n    try:\n        conn = sqlite3.connect(DB_PATH)\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            SELECT type, model_data, scaler_data FROM models \n            WHERE name = ? AND status = 'active'\n        ''', (model_name,))\n        \n        row = cursor.fetchone()\n        if not row:\n            return None, None\n        \n        model_type, model_data, scaler_data = row\n        \n        # Deserialize scaler\n        scaler = pickle.loads(scaler_data) if scaler_data else None\n        \n        # Deserialize model\n        if model_type == 'LSTM':\n            # Save binary data to temporary file and load Keras model\n            temp_model_path = f\"temp_{model_name}_load.h5\"\n            \n            with open(temp_model_path, 'wb') as f:\n                f.write(model_data)\n            \n            from .ml_models import LSTMModel\n            model_instance = LSTMModel(input_shape=(60, 1))  # Placeholder shape\n            model_instance.model = tf.keras.models.load_model(temp_model_path)\n            model_instance.is_trained = True\n            \n            # Clean up temporary file\n            os.remove(temp_model_path)\n            \n            model = model_instance\n        \n        else:\n            # For scikit-learn models\n            sklearn_model = pickle.loads(model_data)\n            \n            # Create appropriate model wrapper\n            if model_type == 'Random Forest':\n                from .ml_models import RandomForestModel\n                model = RandomForestModel()\n                model.model = sklearn_model\n                model.is_trained = True\n            elif model_type == 'SVM':\n                from .ml_models import SVMModel\n                model = SVMModel()\n                model.model = sklearn_model\n                model.scaler = scaler\n                model.is_trained = True\n            else:\n                model = sklearn_model\n        \n        return model, scaler\n        \n    except Exception as e:\n        print(f\"Error loading model from database: {e}\")\n        return None, None\n    finally:\n        conn.close()\n\ndef store_market_data(symbol: str, df: pd.DataFrame):\n    \"\"\"Store market data in database\"\"\"\n    try:\n        conn = sqlite3.connect(DB_PATH)\n        \n        # Prepare data for insertion\n        data_to_insert = []\n        for _, row in df.iterrows():\n            data_to_insert.append((\n                symbol,\n                row.name if hasattr(row, 'name') else row['timestamp'],\n                float(row['open']),\n                float(row['high']),\n                float(row['low']),\n                float(row['close']),\n                float(row['volume'])\n            ))\n        \n        # Insert data (ignore duplicates)\n        cursor = conn.cursor()\n        cursor.executemany('''\n            INSERT OR IGNORE INTO market_data \n            (symbol, timestamp, open_price, high_price, low_price, close_price, volume)\n            VALUES (?, ?, ?, ?, ?, ?, ?)\n        ''', data_to_insert)\n        \n        conn.commit()\n        \n    except Exception as e:\n        print(f\"Error storing market data: {e}\")\n    finally:\n        conn.close()\n\ndef get_historical_data(symbol: str, start_date: datetime = None, \n                       end_date: datetime = None) -> pd.DataFrame:\n    \"\"\"Get historical market data\"\"\"\n    try:\n        conn = sqlite3.connect(DB_PATH)\n        \n        query = '''\n            SELECT timestamp, open_price, high_price, low_price, close_price, volume\n            FROM market_data WHERE symbol = ?\n        '''\n        params = [symbol]\n        \n        if start_date:\n            query += ' AND timestamp >= ?'\n            params.append(start_date)\n        \n        if end_date:\n            query += ' AND timestamp <= ?'\n            params.append(end_date)\n        \n        query += ' ORDER BY timestamp'\n        \n        df = pd.read_sql_query(query, conn, params=params)\n        \n        if not df.empty:\n            df['timestamp'] = pd.to_datetime(df['timestamp'])\n            df.set_index('timestamp', inplace=True)\n            df.columns = ['open', 'high', 'low', 'close', 'volume']\n        \n        return df\n        \n    except Exception as e:\n        print(f\"Error getting historical data: {e}\")\n        return pd.DataFrame()\n    finally:\n        conn.close()\n\ndef store_signal(signal_data: Dict):\n    \"\"\"Store trading signal in database\"\"\"\n    try:\n        conn = sqlite3.connect(DB_PATH)\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            INSERT INTO trading_signals (\n                model_name, symbol, signal_type, confidence,\n                current_price, predicted_price, position_size,\n                stop_loss, take_profit, timestamp\n            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n        ''', (\n            signal_data['model_name'],\n            signal_data['symbol'],\n            signal_data['signal_type'],\n            signal_data['confidence'],\n            signal_data['current_price'],\n            signal_data['predicted_price'],\n            signal_data.get('position_size'),\n            signal_data.get('stop_loss'),\n            signal_data.get('take_profit'),\n            signal_data['timestamp']\n        ))\n        \n        conn.commit()\n        \n    except Exception as e:\n        print(f\"Error storing signal: {e}\")\n    finally:\n        conn.close()\n\ndef get_signals(model_name: str = None, symbol: str = None, \n               start_date: datetime = None, limit: int = 100) -> List[Dict]:\n    \"\"\"Get trading signals\"\"\"\n    try:\n        conn = sqlite3.connect(DB_PATH)\n        cursor = conn.cursor()\n        \n        query = 'SELECT * FROM trading_signals WHERE 1=1'\n        params = []\n        \n        if model_name:\n            query += ' AND model_name = ?'\n            params.append(model_name)\n        \n        if symbol:\n            query += ' AND symbol = ?'\n            params.append(symbol)\n        \n        if start_date:\n            query += ' AND timestamp >= ?'\n            params.append(start_date)\n        \n        query += ' ORDER BY timestamp DESC LIMIT ?'\n        params.append(limit)\n        \n        cursor.execute(query, params)\n        \n        columns = [description[0] for description in cursor.description]\n        signals = []\n        \n        for row in cursor.fetchall():\n            signal_dict = dict(zip(columns, row))\n            signals.append(signal_dict)\n        \n        return signals\n        \n    except Exception as e:\n        print(f\"Error getting signals: {e}\")\n        return []\n    finally:\n        conn.close()\n\ndef store_trade(trade_data: Dict):\n    \"\"\"Store trade execution in database\"\"\"\n    try:\n        conn = sqlite3.connect(DB_PATH)\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            INSERT INTO trading_history (\n                symbol, trade_type, quantity, price, amount,\n                commission, timestamp, order_id, status, pnl\n            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n        ''', (\n            trade_data['symbol'],\n            trade_data['trade_type'],\n            trade_data['quantity'],\n            trade_data['price'],\n            trade_data['amount'],\n            trade_data.get('commission', 0),\n            trade_data.get('timestamp', datetime.now()),\n            trade_data.get('order_id'),\n            trade_data.get('status', 'filled'),\n            trade_data.get('pnl')\n        ))\n        \n        conn.commit()\n        \n    except Exception as e:\n        print(f\"Error storing trade: {e}\")\n    finally:\n        conn.close()\n\ndef get_trading_history(symbol: str = None, start_date: datetime = None, \n                       limit: int = 100) -> List[Dict]:\n    \"\"\"Get trading history\"\"\"\n    try:\n        conn = sqlite3.connect(DB_PATH)\n        cursor = conn.cursor()\n        \n        query = 'SELECT * FROM trading_history WHERE 1=1'\n        params = []\n        \n        if symbol:\n            query += ' AND symbol = ?'\n            params.append(symbol)\n        \n        if start_date:\n            query += ' AND timestamp >= ?'\n            params.append(start_date)\n        \n        query += ' ORDER BY timestamp DESC LIMIT ?'\n        params.append(limit)\n        \n        cursor.execute(query, params)\n        \n        columns = [description[0] for description in cursor.description]\n        trades = []\n        \n        for row in cursor.fetchall():\n            trade_dict = dict(zip(columns, row))\n            trades.append(trade_dict)\n        \n        return trades\n        \n    except Exception as e:\n        print(f\"Error getting trading history: {e}\")\n        return []\n    finally:\n        conn.close()\n\ndef store_model_performance(model_name: str, performance_metrics: Dict):\n    \"\"\"Store model performance metrics\"\"\"\n    try:\n        conn = sqlite3.connect(DB_PATH)\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            INSERT INTO model_performance (\n                model_name, accuracy_score, precision_score, recall_score,\n                f1_score, mse, mae, r2_score, prediction_count, correct_predictions\n            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n        ''', (\n            model_name,\n            performance_metrics.get('accuracy_score'),\n            performance_metrics.get('precision_score'),\n            performance_metrics.get('recall_score'),\n            performance_metrics.get('f1_score'),\n            performance_metrics.get('mse'),\n            performance_metrics.get('mae'),\n            performance_metrics.get('r2_score'),\n            performance_metrics.get('prediction_count'),\n            performance_metrics.get('correct_predictions')\n        ))\n        \n        conn.commit()\n        \n    except Exception as e:\n        print(f\"Error storing model performance: {e}\")\n    finally:\n        conn.close()\n\ndef get_model_performance_history(model_name: str = None, days: int = 30) -> List[Dict]:\n    \"\"\"Get model performance history\"\"\"\n    try:\n        conn = sqlite3.connect(DB_PATH)\n        cursor = conn.cursor()\n        \n        start_date = datetime.now() - timedelta(days=days)\n        \n        query = '''\n            SELECT * FROM model_performance \n            WHERE evaluation_date >= ?\n        '''\n        params = [start_date]\n        \n        if model_name:\n            query += ' AND model_name = ?'\n            params.append(model_name)\n        \n        query += ' ORDER BY evaluation_date DESC'\n        \n        cursor.execute(query, params)\n        \n        columns = [description[0] for description in cursor.description]\n        performance_history = []\n        \n        for row in cursor.fetchall():\n            perf_dict = dict(zip(columns, row))\n            performance_history.append(perf_dict)\n        \n        return performance_history\n        \n    except Exception as e:\n        print(f\"Error getting model performance history: {e}\")\n        return []\n    finally:\n        conn.close()\n\ndef store_portfolio_snapshot(portfolio_data: Dict):\n    \"\"\"Store portfolio snapshot\"\"\"\n    try:\n        conn = sqlite3.connect(DB_PATH)\n        cursor = conn.cursor()\n        \n        positions_json = json.dumps(portfolio_data.get('positions', {}))\n        \n        cursor.execute('''\n            INSERT INTO portfolio (\n                total_value, cash_balance, positions, daily_return, total_return\n            ) VALUES (?, ?, ?, ?, ?)\n        ''', (\n            portfolio_data['total_value'],\n            portfolio_data['cash_balance'],\n            positions_json,\n            portfolio_data.get('daily_return'),\n            portfolio_data.get('total_return')\n        ))\n        \n        conn.commit()\n        \n    except Exception as e:\n        print(f\"Error storing portfolio snapshot: {e}\")\n    finally:\n        conn.close()\n\ndef get_portfolio_history(days: int = 30) -> List[Dict]:\n    \"\"\"Get portfolio history\"\"\"\n    try:\n        conn = sqlite3.connect(DB_PATH)\n        cursor = conn.cursor()\n        \n        start_date = datetime.now() - timedelta(days=days)\n        \n        cursor.execute('''\n            SELECT * FROM portfolio \n            WHERE timestamp >= ?\n            ORDER BY timestamp DESC\n        ''', (start_date,))\n        \n        columns = [description[0] for description in cursor.description]\n        portfolio_history = []\n        \n        for row in cursor.fetchall():\n            portfolio_dict = dict(zip(columns, row))\n            if portfolio_dict['positions']:\n                portfolio_dict['positions'] = json.loads(portfolio_dict['positions'])\n            portfolio_history.append(portfolio_dict)\n        \n        return portfolio_history\n        \n    except Exception as e:\n        print(f\"Error getting portfolio history: {e}\")\n        return []\n    finally:\n        conn.close()\n\ndef cleanup_old_data(days_to_keep: int = 90):\n    \"\"\"Clean up old data from database\"\"\"\n    try:\n        conn = sqlite3.connect(DB_PATH)\n        cursor = conn.cursor()\n        \n        cutoff_date = datetime.now() - timedelta(days=days_to_keep)\n        \n        # Clean up old market data\n        cursor.execute('''\n            DELETE FROM market_data \n            WHERE created_at < ?\n        ''', (cutoff_date,))\n        \n        # Clean up old signals\n        cursor.execute('''\n            DELETE FROM trading_signals \n            WHERE timestamp < ?\n        ''', (cutoff_date,))\n        \n        # Clean up old performance data\n        cursor.execute('''\n            DELETE FROM model_performance \n            WHERE evaluation_date < ?\n        ''', (cutoff_date,))\n        \n        conn.commit()\n        print(f\"Cleaned up data older than {days_to_keep} days\")\n        \n    except Exception as e:\n        print(f\"Error cleaning up old data: {e}\")\n    finally:\n        conn.close()\n","size_bytes":23789},"utils/ml_models.py":{"content":"import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nimport joblib\nimport os\nfrom datetime import datetime\n\nclass BaseModel:\n    \"\"\"Base class for all ML models\"\"\"\n    \n    def __init__(self):\n        self.model = None\n        self.scaler = None\n        self.is_trained = False\n        self.model_type = \"base\"\n        self.training_history = {}\n    \n    def prepare_data(self, X, y, test_size=0.2, sequence_length=None):\n        \"\"\"Prepare data for training\"\"\"\n        if sequence_length is not None:\n            # For sequence models like LSTM\n            return self._prepare_sequence_data(X, y, sequence_length, test_size)\n        else:\n            # For traditional ML models\n            from sklearn.model_selection import train_test_split\n            return train_test_split(X, y, test_size=test_size, shuffle=False)\n    \n    def _prepare_sequence_data(self, X, y, sequence_length, test_size):\n        \"\"\"Prepare sequence data for LSTM models\"\"\"\n        sequences_X = []\n        sequences_y = []\n        \n        for i in range(sequence_length, len(X)):\n            sequences_X.append(X[i-sequence_length:i])\n            sequences_y.append(y[i])\n        \n        sequences_X = np.array(sequences_X)\n        sequences_y = np.array(sequences_y)\n        \n        # Split data\n        split_idx = int(len(sequences_X) * (1 - test_size))\n        \n        X_train = sequences_X[:split_idx]\n        X_test = sequences_X[split_idx:]\n        y_train = sequences_y[:split_idx]\n        y_test = sequences_y[split_idx:]\n        \n        return X_train, X_test, y_train, y_test\n    \n    def save_model(self, filepath):\n        \"\"\"Save the trained model\"\"\"\n        raise NotImplementedError(\"Subclasses must implement save_model\")\n    \n    def load_model(self, filepath):\n        \"\"\"Load a trained model\"\"\"\n        raise NotImplementedError(\"Subclasses must implement load_model\")\n    \n    def get_feature_importance(self):\n        \"\"\"Get feature importance if available\"\"\"\n        return None\n\nclass LSTMModel(BaseModel):\n    \"\"\"LSTM model for time series prediction\"\"\"\n    \n    def __init__(self, input_shape, units=128, dropout_rate=0.2, learning_rate=0.001):\n        super().__init__()\n        self.input_shape = input_shape\n        self.units = units\n        self.dropout_rate = dropout_rate\n        self.learning_rate = learning_rate\n        self.model_type = \"LSTM\"\n        \n        self._build_model()\n    \n    def _build_model(self):\n        \"\"\"Build LSTM model architecture\"\"\"\n        self.model = Sequential([\n            LSTM(self.units, return_sequences=True, input_shape=self.input_shape),\n            Dropout(self.dropout_rate),\n            BatchNormalization(),\n            \n            LSTM(self.units // 2, return_sequences=True),\n            Dropout(self.dropout_rate),\n            BatchNormalization(),\n            \n            LSTM(self.units // 4, return_sequences=False),\n            Dropout(self.dropout_rate),\n            \n            Dense(50, activation='relu'),\n            Dropout(self.dropout_rate / 2),\n            \n            Dense(1, activation='linear')\n        ])\n        \n        self.model.compile(\n            optimizer=Adam(learning_rate=self.learning_rate),\n            loss='mse',\n            metrics=['mae']\n        )\n    \n    def train(self, X_train, y_train, validation_data=None, epochs=50, batch_size=32, verbose=1):\n        \"\"\"Train the LSTM model\"\"\"\n        callbacks = [\n            EarlyStopping(\n                monitor='val_loss' if validation_data else 'loss',\n                patience=10,\n                restore_best_weights=True\n            ),\n            ReduceLROnPlateau(\n                monitor='val_loss' if validation_data else 'loss',\n                factor=0.5,\n                patience=5,\n                min_lr=0.0001\n            )\n        ]\n        \n        history = self.model.fit(\n            X_train, y_train,\n            validation_data=validation_data,\n            epochs=epochs,\n            batch_size=batch_size,\n            callbacks=callbacks,\n            verbose=verbose\n        )\n        \n        self.is_trained = True\n        self.training_history = history.history\n        return history\n    \n    def predict(self, X):\n        \"\"\"Make predictions\"\"\"\n        if not self.is_trained:\n            raise ValueError(\"Model must be trained before making predictions\")\n        \n        return self.model.predict(X)\n    \n    def evaluate(self, X_test, y_test):\n        \"\"\"Evaluate model performance\"\"\"\n        predictions = self.predict(X_test)\n        \n        mse = mean_squared_error(y_test, predictions)\n        mae = mean_absolute_error(y_test, predictions)\n        r2 = r2_score(y_test, predictions)\n        \n        return {\n            'mse': mse,\n            'mae': mae,\n            'r2': r2,\n            'rmse': np.sqrt(mse)\n        }\n    \n    def save_model(self, filepath):\n        \"\"\"Save LSTM model\"\"\"\n        if not self.is_trained:\n            raise ValueError(\"Model must be trained before saving\")\n        \n        # Create directory if it doesn't exist\n        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n        \n        # Save Keras model\n        self.model.save(f\"{filepath}.h5\")\n        \n        # Save model metadata\n        metadata = {\n            'model_type': self.model_type,\n            'input_shape': self.input_shape,\n            'units': self.units,\n            'dropout_rate': self.dropout_rate,\n            'learning_rate': self.learning_rate,\n            'training_history': self.training_history\n        }\n        \n        joblib.dump(metadata, f\"{filepath}_metadata.pkl\")\n    \n    def load_model(self, filepath):\n        \"\"\"Load LSTM model\"\"\"\n        # Load Keras model\n        self.model = tf.keras.models.load_model(f\"{filepath}.h5\")\n        \n        # Load metadata\n        metadata = joblib.load(f\"{filepath}_metadata.pkl\")\n        \n        self.input_shape = metadata['input_shape']\n        self.units = metadata['units']\n        self.dropout_rate = metadata['dropout_rate']\n        self.learning_rate = metadata['learning_rate']\n        self.training_history = metadata.get('training_history', {})\n        self.is_trained = True\n\nclass RandomForestModel(BaseModel):\n    \"\"\"Random Forest model for price prediction\"\"\"\n    \n    def __init__(self, n_estimators=100, max_depth=15, min_samples_split=5, random_state=42):\n        super().__init__()\n        self.n_estimators = n_estimators\n        self.max_depth = max_depth\n        self.min_samples_split = min_samples_split\n        self.random_state = random_state\n        self.model_type = \"Random Forest\"\n        \n        self.model = RandomForestRegressor(\n            n_estimators=self.n_estimators,\n            max_depth=self.max_depth,\n            min_samples_split=self.min_samples_split,\n            random_state=self.random_state,\n            n_jobs=-1\n        )\n    \n    def train(self, X_train, y_train):\n        \"\"\"Train the Random Forest model\"\"\"\n        self.model.fit(X_train, y_train)\n        self.is_trained = True\n        \n        # Store training info\n        self.training_history = {\n            'n_samples': len(X_train),\n            'n_features': X_train.shape[1],\n            'training_score': self.model.score(X_train, y_train)\n        }\n    \n    def predict(self, X):\n        \"\"\"Make predictions\"\"\"\n        if not self.is_trained:\n            raise ValueError(\"Model must be trained before making predictions\")\n        \n        return self.model.predict(X)\n    \n    def evaluate(self, X_test, y_test):\n        \"\"\"Evaluate model performance\"\"\"\n        predictions = self.predict(X_test)\n        \n        mse = mean_squared_error(y_test, predictions)\n        mae = mean_absolute_error(y_test, predictions)\n        r2 = r2_score(y_test, predictions)\n        \n        return {\n            'mse': mse,\n            'mae': mae,\n            'r2': r2,\n            'rmse': np.sqrt(mse)\n        }\n    \n    def get_feature_importance(self):\n        \"\"\"Get feature importance\"\"\"\n        if not self.is_trained:\n            return None\n        \n        return self.model.feature_importances_\n    \n    def save_model(self, filepath):\n        \"\"\"Save Random Forest model\"\"\"\n        if not self.is_trained:\n            raise ValueError(\"Model must be trained before saving\")\n        \n        # Create directory if it doesn't exist\n        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n        \n        model_data = {\n            'model': self.model,\n            'model_type': self.model_type,\n            'n_estimators': self.n_estimators,\n            'max_depth': self.max_depth,\n            'min_samples_split': self.min_samples_split,\n            'random_state': self.random_state,\n            'training_history': self.training_history\n        }\n        \n        joblib.dump(model_data, f\"{filepath}.pkl\")\n    \n    def load_model(self, filepath):\n        \"\"\"Load Random Forest model\"\"\"\n        model_data = joblib.load(f\"{filepath}.pkl\")\n        \n        self.model = model_data['model']\n        self.n_estimators = model_data['n_estimators']\n        self.max_depth = model_data['max_depth']\n        self.min_samples_split = model_data['min_samples_split']\n        self.random_state = model_data['random_state']\n        self.training_history = model_data.get('training_history', {})\n        self.is_trained = True\n\nclass SVMModel(BaseModel):\n    \"\"\"Support Vector Machine model for price prediction\"\"\"\n    \n    def __init__(self, C=1.0, kernel='rbf', gamma='scale', epsilon=0.1):\n        super().__init__()\n        self.C = C\n        self.kernel = kernel\n        self.gamma = gamma\n        self.epsilon = epsilon\n        self.model_type = \"SVM\"\n        \n        self.model = SVR(\n            C=self.C,\n            kernel=self.kernel,\n            gamma=self.gamma,\n            epsilon=self.epsilon\n        )\n        \n        self.scaler = StandardScaler()\n    \n    def train(self, X_train, y_train):\n        \"\"\"Train the SVM model\"\"\"\n        # Scale features\n        X_train_scaled = self.scaler.fit_transform(X_train)\n        \n        # Train model\n        self.model.fit(X_train_scaled, y_train)\n        self.is_trained = True\n        \n        # Store training info\n        self.training_history = {\n            'n_samples': len(X_train),\n            'n_features': X_train.shape[1],\n            'n_support_vectors': len(self.model.support_),\n            'training_score': self.model.score(X_train_scaled, y_train)\n        }\n    \n    def predict(self, X):\n        \"\"\"Make predictions\"\"\"\n        if not self.is_trained:\n            raise ValueError(\"Model must be trained before making predictions\")\n        \n        X_scaled = self.scaler.transform(X)\n        return self.model.predict(X_scaled)\n    \n    def evaluate(self, X_test, y_test):\n        \"\"\"Evaluate model performance\"\"\"\n        predictions = self.predict(X_test)\n        \n        mse = mean_squared_error(y_test, predictions)\n        mae = mean_absolute_error(y_test, predictions)\n        r2 = r2_score(y_test, predictions)\n        \n        return {\n            'mse': mse,\n            'mae': mae,\n            'r2': r2,\n            'rmse': np.sqrt(mse)\n        }\n    \n    def save_model(self, filepath):\n        \"\"\"Save SVM model\"\"\"\n        if not self.is_trained:\n            raise ValueError(\"Model must be trained before saving\")\n        \n        # Create directory if it doesn't exist\n        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n        \n        model_data = {\n            'model': self.model,\n            'scaler': self.scaler,\n            'model_type': self.model_type,\n            'C': self.C,\n            'kernel': self.kernel,\n            'gamma': self.gamma,\n            'epsilon': self.epsilon,\n            'training_history': self.training_history\n        }\n        \n        joblib.dump(model_data, f\"{filepath}.pkl\")\n    \n    def load_model(self, filepath):\n        \"\"\"Load SVM model\"\"\"\n        model_data = joblib.load(f\"{filepath}.pkl\")\n        \n        self.model = model_data['model']\n        self.scaler = model_data['scaler']\n        self.C = model_data['C']\n        self.kernel = model_data['kernel']\n        self.gamma = model_data['gamma']\n        self.epsilon = model_data['epsilon']\n        self.training_history = model_data.get('training_history', {})\n        self.is_trained = True\n\ndef create_model(model_type, **kwargs):\n    \"\"\"Factory function to create ML models\"\"\"\n    if model_type.upper() == 'LSTM':\n        if 'input_shape' not in kwargs:\n            raise ValueError(\"input_shape is required for LSTM model\")\n        return LSTMModel(**kwargs)\n    elif model_type.upper() == 'RANDOM FOREST':\n        return RandomForestModel(**kwargs)\n    elif model_type.upper() == 'SVM':\n        return SVMModel(**kwargs)\n    else:\n        raise ValueError(f\"Unsupported model type: {model_type}\")\n\ndef evaluate_models(models, X_test, y_test):\n    \"\"\"Compare multiple models on test data\"\"\"\n    results = {}\n    \n    for name, model in models.items():\n        if model.is_trained:\n            results[name] = model.evaluate(X_test, y_test)\n        else:\n            results[name] = {'error': 'Model not trained'}\n    \n    return results\n","size_bytes":13583},"utils/pattern_recognition.py":{"content":"import numpy as np\nimport pandas as pd\nfrom typing import Dict, List, Tuple, Optional\nfrom scipy import stats\nimport ta\n\nclass PatternRecognizer:\n    \"\"\"\n    Advanced candlestick pattern recognition for trading signals.\n    Implements detection for channels, triangles, wedges, and other technical patterns.\n    \"\"\"\n    \n    def __init__(self, min_pattern_length: int = 20, confidence_threshold: float = 0.7):\n        self.min_pattern_length = min_pattern_length\n        self.confidence_threshold = confidence_threshold\n        \n    def detect_all_patterns(self, df: pd.DataFrame) -> Dict[str, Dict]:\n        \"\"\"Detect all supported patterns in the given dataframe.\"\"\"\n        patterns = {}\n        \n        if len(df) < self.min_pattern_length:\n            return patterns\n            \n        # Channel patterns\n        patterns.update(self._detect_channels(df))\n        \n        # Triangle patterns\n        patterns.update(self._detect_triangles(df))\n        \n        # Wedge patterns  \n        patterns.update(self._detect_wedges(df))\n        \n        # Support/Resistance levels\n        patterns['support_resistance'] = self._detect_support_resistance(df)\n        \n        return patterns\n    \n    def _detect_channels(self, df: pd.DataFrame) -> Dict[str, Dict]:\n        \"\"\"Detect ranging, uptrend, and downtrend channels.\"\"\"\n        patterns = {}\n        \n        # Get recent data for pattern analysis\n        recent_data = df.tail(50)\n        highs = recent_data['high'].values\n        lows = recent_data['low'].values\n        closes = recent_data['close'].values\n        \n        # Find swing highs and lows\n        swing_highs = self._find_swing_points(highs, type='high')\n        swing_lows = self._find_swing_points(lows, type='low')\n        \n        if len(swing_highs) >= 3 and len(swing_lows) >= 3:\n            # Calculate trend lines for highs and lows\n            high_trend = self._calculate_trend_line(swing_highs, highs)\n            low_trend = self._calculate_trend_line(swing_lows, lows)\n            \n            if high_trend and low_trend:\n                high_slope = high_trend['slope']\n                low_slope = low_trend['slope']\n                \n                # Classify channel type based on slopes\n                if abs(high_slope) < 0.1 and abs(low_slope) < 0.1:\n                    patterns['ranging_channel'] = {\n                        'type': 'Ranging Channel',\n                        'confidence': 0.8,\n                        'upper_line': high_trend,\n                        'lower_line': low_trend,\n                        'signal': 'NEUTRAL',\n                        'description': 'Price moving sideways between support and resistance'\n                    }\n                elif high_slope > 0.1 and low_slope > 0.1:\n                    patterns['uptrend_channel'] = {\n                        'type': 'Uptrend Channel',\n                        'confidence': 0.85,\n                        'upper_line': high_trend,\n                        'lower_line': low_trend,\n                        'signal': 'BULLISH',\n                        'description': 'Rising channel - buy on lower line, sell on upper line'\n                    }\n                elif high_slope < -0.1 and low_slope < -0.1:\n                    patterns['downtrend_channel'] = {\n                        'type': 'Downtrend Channel',\n                        'confidence': 0.85,\n                        'upper_line': high_trend,\n                        'lower_line': low_trend,\n                        'signal': 'BEARISH',\n                        'description': 'Falling channel - sell on upper line, cover on lower line'\n                    }\n        \n        return patterns\n    \n    def _detect_triangles(self, df: pd.DataFrame) -> Dict[str, Dict]:\n        \"\"\"Detect ascending, descending, and expanding triangles.\"\"\"\n        patterns = {}\n        \n        recent_data = df.tail(40)\n        highs = recent_data['high'].values\n        lows = recent_data['low'].values\n        \n        swing_highs = self._find_swing_points(highs, type='high')\n        swing_lows = self._find_swing_points(lows, type='low')\n        \n        if len(swing_highs) >= 3 and len(swing_lows) >= 3:\n            high_trend = self._calculate_trend_line(swing_highs, highs)\n            low_trend = self._calculate_trend_line(swing_lows, lows)\n            \n            if high_trend and low_trend:\n                high_slope = high_trend['slope']\n                low_slope = low_trend['slope']\n                \n                # Ascending Triangle: flat resistance, rising support\n                if abs(high_slope) < 0.05 and low_slope > 0.1:\n                    patterns['ascending_triangle'] = {\n                        'type': 'Ascending Triangle',\n                        'confidence': 0.8,\n                        'upper_line': high_trend,\n                        'lower_line': low_trend,\n                        'signal': 'BULLISH',\n                        'description': 'Bullish pattern - expect upward breakout'\n                    }\n                \n                # Descending Triangle: falling resistance, flat support\n                elif high_slope < -0.1 and abs(low_slope) < 0.05:\n                    patterns['descending_triangle'] = {\n                        'type': 'Descending Triangle',\n                        'confidence': 0.8,\n                        'upper_line': high_trend,\n                        'lower_line': low_trend,\n                        'signal': 'BEARISH',\n                        'description': 'Bearish pattern - expect downward breakout'\n                    }\n                \n                # Expanding Triangle: diverging lines\n                elif high_slope > 0.05 and low_slope < -0.05:\n                    patterns['expanding_triangle'] = {\n                        'type': 'Expanding Triangle',\n                        'confidence': 0.75,\n                        'upper_line': high_trend,\n                        'lower_line': low_trend,\n                        'signal': 'VOLATILE',\n                        'description': 'High volatility pattern - trade breakouts carefully'\n                    }\n        \n        return patterns\n    \n    def _detect_wedges(self, df: pd.DataFrame) -> Dict[str, Dict]:\n        \"\"\"Detect rising and falling wedge patterns.\"\"\"\n        patterns = {}\n        \n        recent_data = df.tail(35)\n        highs = recent_data['high'].values\n        lows = recent_data['low'].values\n        \n        swing_highs = self._find_swing_points(highs, type='high')\n        swing_lows = self._find_swing_points(lows, type='low')\n        \n        if len(swing_highs) >= 3 and len(swing_lows) >= 3:\n            high_trend = self._calculate_trend_line(swing_highs, highs)\n            low_trend = self._calculate_trend_line(swing_lows, lows)\n            \n            if high_trend and low_trend:\n                high_slope = high_trend['slope']\n                low_slope = low_trend['slope']\n                \n                # Rising Wedge: both lines rising, but upper line rises faster\n                if high_slope > 0.1 and low_slope > 0.05 and high_slope > low_slope * 1.5:\n                    patterns['rising_wedge'] = {\n                        'type': 'Rising Wedge',\n                        'confidence': 0.75,\n                        'upper_line': high_trend,\n                        'lower_line': low_trend,\n                        'signal': 'BEARISH',\n                        'description': 'Bearish reversal pattern - expect downward breakout'\n                    }\n                \n                # Falling Wedge: both lines falling, but lower line falls faster  \n                elif high_slope < -0.05 and low_slope < -0.1 and abs(low_slope) > abs(high_slope) * 1.5:\n                    patterns['falling_wedge'] = {\n                        'type': 'Falling Wedge',\n                        'confidence': 0.75,\n                        'upper_line': high_trend,\n                        'lower_line': low_trend,\n                        'signal': 'BULLISH',\n                        'description': 'Bullish reversal pattern - expect upward breakout'\n                    }\n        \n        return patterns\n    \n    def _find_swing_points(self, data: np.ndarray, type: str = 'high', window: int = 5) -> List[Tuple[int, float]]:\n        \"\"\"Find swing highs or lows in price data.\"\"\"\n        swing_points = []\n        \n        for i in range(window, len(data) - window):\n            if type == 'high':\n                is_swing = all(data[i] >= data[i-j] for j in range(1, window+1)) and \\\n                          all(data[i] >= data[i+j] for j in range(1, window+1))\n            else:  # low\n                is_swing = all(data[i] <= data[i-j] for j in range(1, window+1)) and \\\n                          all(data[i] <= data[i+j] for j in range(1, window+1))\n            \n            if is_swing:\n                swing_points.append((i, data[i]))\n        \n        return swing_points\n    \n    def _calculate_trend_line(self, swing_points: List[Tuple[int, float]], data: np.ndarray) -> Optional[Dict]:\n        \"\"\"Calculate trend line from swing points.\"\"\"\n        if len(swing_points) < 2:\n            return None\n            \n        x_coords = [point[0] for point in swing_points]\n        y_coords = [point[1] for point in swing_points]\n        \n        # Linear regression for trend line\n        slope, intercept, r_value, _, _ = stats.linregress(x_coords, y_coords)\n        \n        return {\n            'slope': slope,\n            'intercept': intercept,\n            'r_squared': r_value ** 2,\n            'start_point': (x_coords[0], y_coords[0]),\n            'end_point': (x_coords[-1], y_coords[-1]),\n            'points': swing_points\n        }\n    \n    def _detect_support_resistance(self, df: pd.DataFrame, window: int = 20) -> Dict:\n        \"\"\"Detect key support and resistance levels.\"\"\"\n        recent_data = df.tail(100)\n        highs = recent_data['high']\n        lows = recent_data['low']\n        closes = recent_data['close']\n        \n        # Calculate support and resistance levels\n        resistance_levels = []\n        support_levels = []\n        \n        # Rolling max/min for dynamic levels\n        for i in range(window, len(recent_data)):\n            local_high = highs.iloc[i-window:i].max()\n            local_low = lows.iloc[i-window:i].min()\n            \n            # Check if current price is near these levels\n            current_price = closes.iloc[i]\n            \n            if abs(current_price - local_high) / current_price < 0.01:\n                resistance_levels.append(local_high)\n            if abs(current_price - local_low) / current_price < 0.01:\n                support_levels.append(local_low)\n        \n        return {\n            'resistance_levels': list(set(resistance_levels))[-3:],  # Top 3 recent\n            'support_levels': list(set(support_levels))[-3:],       # Top 3 recent\n            'current_price': float(closes.iloc[-1])\n        }\n    \n    def get_trading_signals(self, patterns: Dict) -> List[Dict]:\n        \"\"\"Generate trading signals based on detected patterns.\"\"\"\n        signals = []\n        \n        for pattern_name, pattern_data in patterns.items():\n            if pattern_name == 'support_resistance':\n                continue\n                \n            signal_strength = pattern_data.get('confidence', 0.5)\n            signal_type = pattern_data.get('signal', 'NEUTRAL')\n            \n            if signal_strength >= self.confidence_threshold:\n                signals.append({\n                    'pattern': pattern_data['type'],\n                    'signal': signal_type,\n                    'strength': signal_strength,\n                    'description': pattern_data['description'],\n                    'timestamp': pd.Timestamp.now()\n                })\n        \n        return signals","size_bytes":11820},"utils/signal_generator.py":{"content":"import pandas as pd\nimport numpy as np\nfrom datetime import datetime\nfrom typing import Dict, Optional, List\nimport joblib\nimport os\nfrom .database import get_model_by_name, load_model_from_db\nfrom .data_processor import DataProcessor\n\nclass SignalGenerator:\n    \"\"\"\n    AI-powered trading signal generator\n    \"\"\"\n    \n    def __init__(self):\n        self.data_processor = DataProcessor()\n        self.confidence_threshold = 0.7\n        \n    def generate_signal(self, model_name: str, data: pd.DataFrame, \n                       confidence_threshold: float = 0.7) -> Optional[Dict]:\n        \"\"\"\n        Generate trading signal using ML model\n        \n        Args:\n            model_name: Name of the trained model\n            data: Recent market data\n            confidence_threshold: Minimum confidence for signal generation\n            \n        Returns:\n            Dictionary containing signal information or None\n        \"\"\"\n        try:\n            # Load model information\n            model_info = get_model_by_name(model_name)\n            if not model_info:\n                raise ValueError(f\"Model {model_name} not found\")\n            \n            # Load the actual model\n            model, scaler = load_model_from_db(model_name)\n            if model is None:\n                raise ValueError(f\"Could not load model {model_name}\")\n            \n            # Prepare data for prediction\n            features = self._prepare_prediction_data(data, model_info, scaler)\n            \n            if features is None:\n                return None\n            \n            # Make prediction\n            prediction = self._make_prediction(model, features, model_info['type'])\n            \n            if prediction is None:\n                return None\n            \n            # Generate signal based on prediction\n            signal_result = self._analyze_prediction(\n                prediction, data, model_info, confidence_threshold\n            )\n            \n            return signal_result\n            \n        except Exception as e:\n            print(f\"Error generating signal: {e}\")\n            return None\n    \n    def _prepare_prediction_data(self, data: pd.DataFrame, model_info: Dict, \n                               scaler) -> Optional[np.ndarray]:\n        \"\"\"Prepare data for model prediction\"\"\"\n        try:\n            # Get the latest data point for prediction\n            if len(data) < 60:  # Need sufficient history for features\n                return None\n            \n            # Prepare features using the same process as training\n            df_features = self.data_processor.prepare_features(\n                data, \n                include_technical=True, \n                include_volume=True,\n                include_price_changes=True\n            )\n            \n            if len(df_features) == 0:\n                return None\n            \n            # Get model features\n            model_features = model_info.get('features', [])\n            \n            # Select only the features used in training\n            available_features = [col for col in model_features if col in df_features.columns]\n            \n            if len(available_features) == 0:\n                print(\"No matching features found for prediction\")\n                return None\n            \n            # Get the latest data point\n            feature_data = df_features[available_features].iloc[-1:].values\n            \n            # Scale features\n            if scaler is not None:\n                feature_data = scaler.transform(feature_data)\n            \n            # Handle LSTM sequence requirements\n            if model_info['type'] == 'LSTM':\n                sequence_length = 60  # Default sequence length\n                \n                if len(df_features) >= sequence_length:\n                    # Create sequence\n                    sequence_data = df_features[available_features].iloc[-sequence_length:].values\n                    if scaler is not None:\n                        sequence_data = scaler.transform(sequence_data)\n                    \n                    # Reshape for LSTM\n                    feature_data = sequence_data.reshape(1, sequence_length, len(available_features))\n                else:\n                    return None\n            \n            return feature_data\n            \n        except Exception as e:\n            print(f\"Error preparing prediction data: {e}\")\n            return None\n    \n    def _make_prediction(self, model, features: np.ndarray, model_type: str) -> Optional[float]:\n        \"\"\"Make price prediction using the model\"\"\"\n        try:\n            if model_type == 'LSTM':\n                # Keras/TensorFlow model\n                prediction = model.predict(features, verbose=0)\n                return float(prediction[0][0])\n            \n            else:\n                # Scikit-learn model\n                prediction = model.predict(features)\n                return float(prediction[0])\n                \n        except Exception as e:\n            print(f\"Error making prediction: {e}\")\n            return None\n    \n    def _analyze_prediction(self, predicted_price: float, data: pd.DataFrame, \n                          model_info: Dict, confidence_threshold: float) -> Dict:\n        \"\"\"Analyze prediction and generate trading signal\"\"\"\n        try:\n            current_price = float(data['close'].iloc[-1])\n            \n            # Calculate price change\n            price_change = predicted_price - current_price\n            price_change_pct = (price_change / current_price) * 100\n            \n            # Calculate prediction confidence based on model accuracy and market conditions\n            base_confidence = model_info.get('test_r2', 0.5)\n            \n            # Adjust confidence based on market volatility\n            recent_volatility = data['close'].pct_change().rolling(20).std().iloc[-1]\n            volatility_factor = max(0.5, 1 - (recent_volatility * 10))  # Reduce confidence in high volatility\n            \n            # Adjust confidence based on prediction magnitude\n            magnitude_factor = min(1.0, abs(price_change_pct) / 5)  # Higher confidence for larger moves\n            \n            confidence = base_confidence * volatility_factor * magnitude_factor\n            confidence = max(0.0, min(1.0, confidence))  # Clamp between 0 and 1\n            \n            # Generate signal based on prediction and confidence\n            signal_type = 'HOLD'\n            \n            if confidence >= confidence_threshold:\n                if price_change_pct > 2:  # Minimum 2% move for BUY signal\n                    signal_type = 'BUY'\n                elif price_change_pct < -2:  # Minimum 2% drop for SELL signal\n                    signal_type = 'SELL'\n            \n            # Additional technical analysis for signal confirmation\n            signal_strength = self._calculate_signal_strength(data, signal_type, confidence)\n            \n            # Prepare signal result\n            signal_result = {\n                'signal_type': signal_type,\n                'confidence': confidence,\n                'predicted_price': predicted_price,\n                'current_price': current_price,\n                'price_change': price_change,\n                'price_change_pct': price_change_pct,\n                'signal_strength': signal_strength,\n                'model_name': model_info['name'],\n                'model_type': model_info['type'],\n                'timestamp': datetime.now(),\n                'technical_factors': self._get_technical_factors(data)\n            }\n            \n            return signal_result\n            \n        except Exception as e:\n            print(f\"Error analyzing prediction: {e}\")\n            return {\n                'signal_type': 'HOLD',\n                'confidence': 0.0,\n                'predicted_price': predicted_price,\n                'current_price': data['close'].iloc[-1],\n                'error': str(e)\n            }\n    \n    def _calculate_signal_strength(self, data: pd.DataFrame, signal_type: str, confidence: float) -> str:\n        \"\"\"Calculate signal strength based on technical analysis\"\"\"\n        try:\n            # Get recent price data\n            close_prices = data['close']\n            volumes = data.get('volume', pd.Series([1] * len(close_prices)))\n            \n            strength_score = confidence\n            \n            # Volume confirmation\n            avg_volume = volumes.rolling(20).mean().iloc[-1]\n            current_volume = volumes.iloc[-1]\n            volume_ratio = current_volume / avg_volume if avg_volume > 0 else 1\n            \n            if volume_ratio > 1.5:\n                strength_score += 0.1\n            elif volume_ratio < 0.5:\n                strength_score -= 0.1\n            \n            # Trend confirmation\n            sma_20 = close_prices.rolling(20).mean().iloc[-1]\n            current_price = close_prices.iloc[-1]\n            \n            if signal_type == 'BUY' and current_price > sma_20:\n                strength_score += 0.1\n            elif signal_type == 'SELL' and current_price < sma_20:\n                strength_score += 0.1\n            \n            # RSI confirmation\n            rsi = self._calculate_rsi(close_prices)\n            if len(rsi) > 0:\n                current_rsi = rsi.iloc[-1]\n                \n                if signal_type == 'BUY' and current_rsi < 30:  # Oversold\n                    strength_score += 0.15\n                elif signal_type == 'SELL' and current_rsi > 70:  # Overbought\n                    strength_score += 0.15\n            \n            # Classify strength\n            if strength_score >= 0.8:\n                return 'Strong'\n            elif strength_score >= 0.6:\n                return 'Medium'\n            else:\n                return 'Weak'\n                \n        except Exception as e:\n            print(f\"Error calculating signal strength: {e}\")\n            return 'Weak'\n    \n    def _get_technical_factors(self, data: pd.DataFrame) -> Dict:\n        \"\"\"Get technical analysis factors\"\"\"\n        try:\n            close_prices = data['close']\n            \n            # Moving averages\n            sma_20 = close_prices.rolling(20).mean().iloc[-1]\n            sma_50 = close_prices.rolling(50).mean().iloc[-1] if len(close_prices) >= 50 else sma_20\n            current_price = close_prices.iloc[-1]\n            \n            # RSI\n            rsi = self._calculate_rsi(close_prices)\n            current_rsi = rsi.iloc[-1] if len(rsi) > 0 else 50\n            \n            # MACD\n            macd, macd_signal = self._calculate_macd(close_prices)\n            macd_value = macd.iloc[-1] if len(macd) > 0 else 0\n            macd_signal_value = macd_signal.iloc[-1] if len(macd_signal) > 0 else 0\n            \n            # Support and resistance\n            recent_highs = close_prices.rolling(20).max().iloc[-1]\n            recent_lows = close_prices.rolling(20).min().iloc[-1]\n            \n            technical_factors = {\n                'price_vs_sma20': 'Above' if current_price > sma_20 else 'Below',\n                'price_vs_sma50': 'Above' if current_price > sma_50 else 'Below',\n                'rsi': current_rsi,\n                'rsi_condition': 'Overbought' if current_rsi > 70 else 'Oversold' if current_rsi < 30 else 'Neutral',\n                'macd_bullish': macd_value > macd_signal_value,\n                'near_resistance': abs(current_price - recent_highs) / current_price < 0.02,\n                'near_support': abs(current_price - recent_lows) / current_price < 0.02\n            }\n            \n            return technical_factors\n            \n        except Exception as e:\n            print(f\"Error getting technical factors: {e}\")\n            return {}\n    \n    def _calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:\n        \"\"\"Calculate RSI indicator\"\"\"\n        try:\n            delta = prices.diff()\n            gain = delta.where(delta > 0, 0)\n            loss = -delta.where(delta < 0, 0)\n            \n            avg_gain = gain.rolling(window=period).mean()\n            avg_loss = loss.rolling(window=period).mean()\n            \n            rs = avg_gain / avg_loss\n            rsi = 100 - (100 / (1 + rs))\n            \n            return rsi\n            \n        except Exception as e:\n            print(f\"Error calculating RSI: {e}\")\n            return pd.Series([50] * len(prices))\n    \n    def _calculate_macd(self, prices: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9) -> tuple:\n        \"\"\"Calculate MACD indicator\"\"\"\n        try:\n            ema_fast = prices.ewm(span=fast).mean()\n            ema_slow = prices.ewm(span=slow).mean()\n            \n            macd = ema_fast - ema_slow\n            macd_signal = macd.ewm(span=signal).mean()\n            \n            return macd, macd_signal\n            \n        except Exception as e:\n            print(f\"Error calculating MACD: {e}\")\n            return pd.Series([0] * len(prices)), pd.Series([0] * len(prices))\n    \n    def generate_batch_signals(self, model_names: List[str], data: pd.DataFrame, \n                             confidence_threshold: float = 0.7) -> Dict:\n        \"\"\"Generate signals for multiple models\"\"\"\n        signals = {}\n        \n        for model_name in model_names:\n            signal = self.generate_signal(model_name, data, confidence_threshold)\n            signals[model_name] = signal\n        \n        # Consensus analysis\n        consensus = self._analyze_signal_consensus(signals)\n        \n        return {\n            'individual_signals': signals,\n            'consensus': consensus\n        }\n    \n    def _analyze_signal_consensus(self, signals: Dict) -> Dict:\n        \"\"\"Analyze consensus among multiple signals\"\"\"\n        valid_signals = {k: v for k, v in signals.items() if v is not None and 'error' not in v}\n        \n        if not valid_signals:\n            return {'consensus_signal': 'HOLD', 'agreement': 0, 'confidence': 0}\n        \n        # Count signal types\n        signal_counts = {'BUY': 0, 'SELL': 0, 'HOLD': 0}\n        total_confidence = 0\n        \n        for signal in valid_signals.values():\n            signal_type = signal.get('signal_type', 'HOLD')\n            confidence = signal.get('confidence', 0)\n            \n            signal_counts[signal_type] += 1\n            total_confidence += confidence\n        \n        # Determine consensus\n        total_signals = len(valid_signals)\n        consensus_signal = max(signal_counts, key=signal_counts.get)\n        agreement = signal_counts[consensus_signal] / total_signals\n        avg_confidence = total_confidence / total_signals\n        \n        return {\n            'consensus_signal': consensus_signal,\n            'agreement': agreement,\n            'confidence': avg_confidence,\n            'signal_distribution': signal_counts,\n            'total_models': total_signals\n        }\n    \n    def validate_signal_quality(self, signal: Dict) -> Dict:\n        \"\"\"Validate and score signal quality\"\"\"\n        quality_score = 0\n        quality_factors = []\n        \n        # Confidence check\n        confidence = signal.get('confidence', 0)\n        if confidence >= 0.8:\n            quality_score += 30\n            quality_factors.append('High confidence')\n        elif confidence >= 0.6:\n            quality_score += 20\n            quality_factors.append('Medium confidence')\n        else:\n            quality_score += 5\n            quality_factors.append('Low confidence')\n        \n        # Signal strength check\n        strength = signal.get('signal_strength', 'Weak')\n        if strength == 'Strong':\n            quality_score += 25\n            quality_factors.append('Strong technical confirmation')\n        elif strength == 'Medium':\n            quality_score += 15\n            quality_factors.append('Medium technical confirmation')\n        else:\n            quality_score += 5\n            quality_factors.append('Weak technical confirmation')\n        \n        # Price change magnitude\n        price_change_pct = abs(signal.get('price_change_pct', 0))\n        if price_change_pct >= 5:\n            quality_score += 20\n            quality_factors.append('Significant price target')\n        elif price_change_pct >= 2:\n            quality_score += 10\n            quality_factors.append('Moderate price target')\n        else:\n            quality_score += 2\n            quality_factors.append('Small price target')\n        \n        # Technical factors check\n        technical_factors = signal.get('technical_factors', {})\n        if technical_factors:\n            quality_score += 15\n            quality_factors.append('Technical analysis available')\n        \n        # Final quality assessment\n        if quality_score >= 80:\n            quality_rating = 'Excellent'\n        elif quality_score >= 60:\n            quality_rating = 'Good'\n        elif quality_score >= 40:\n            quality_rating = 'Fair'\n        else:\n            quality_rating = 'Poor'\n        \n        return {\n            'quality_score': quality_score,\n            'quality_rating': quality_rating,\n            'quality_factors': quality_factors,\n            'recommendation': 'Trade' if quality_score >= 60 else 'Monitor' if quality_score >= 40 else 'Skip'\n        }\n","size_bytes":17229}}}